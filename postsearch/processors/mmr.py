import numpy as np
import asyncio
from typing import List, Dict, Any, Optional
from ..interfaces import PostSearchInterface
import logging
from engineconfig.post_search_config import get_processor_config



logger = logging.getLogger(__name__)

class MMRProcessor(PostSearchInterface):
    """MMRå¤šæ ·æ€§å¤„ç†å™¨ - æœ€å¤§åŒ–è¾¹é™…ç›¸å…³æ€§ï¼Œå¢åŠ ç»“æœå¤šæ ·æ€§"""
    def __init__(self, **kwargs):
        """
        åˆå§‹åŒ– MMR å¤„ç†å™¨
        
        Args:
            **kwargs: å…¶ä»–å‚æ•°
        """
        pass

    def process(self, results: List[Dict[str, Any]], **kwargs) -> List[Dict[str, Any]]:
        """åŒæ­¥å¤„ç†æ–¹æ³•ï¼Œä¿æŒå‘åå…¼å®¹"""
        # è°ƒç”¨å¼‚æ­¥ç‰ˆæœ¬
        return asyncio.run(self._process_async(results, **kwargs))
    
    async def _process_async(self, results: List[Dict[str, Any]], **kwargs) -> List[Dict[str, Any]]:
        # ä»get_config_schemaè·å–é»˜è®¤å‚æ•°ï¼Œkwargsä¸­çš„å‚æ•°ä¼˜å…ˆçº§æ›´é«˜
        schema = self.get_config_schema()
        lambda_param = kwargs.get('lambda_param', schema['lambda_param']['default'])
        select_n = kwargs.get('select_n', schema['select_n']['default'])
        enable_mmr = kwargs.get('enable_mmr', schema['enable_mmr']['default'])
        min_text_length = kwargs.get('min_text_length', schema['min_text_length']['default'])
        # é›¶å‘é‡ä¿æŠ¤å‚æ•°
        zero_vector_protection = kwargs.get('zero_vector_protection', schema['zero_vector_protection']['default'])
        zero_vector_strategy = kwargs.get('zero_vector_strategy', schema['zero_vector_strategy']['default'])
        min_norm_threshold = kwargs.get('min_norm_threshold', schema['min_norm_threshold']['default'])
        use_cache_optimization = kwargs.get('use_cache_optimization', schema['use_cache_optimization']['default'])
        output_order = kwargs.get('output_order', schema['output_order']['default'])
        reverse_order = kwargs.get('reverse_order', schema['reverse_order']['default'])
        query_info = kwargs.get('query_info', {})
        # éªŒè¯é…ç½®
        process_config = {
            'lambda_param': lambda_param,
            'select_n': select_n,
            'enable_mmr': enable_mmr,
            'min_text_length': min_text_length,
            'zero_vector_protection': zero_vector_protection,
            'zero_vector_strategy': zero_vector_strategy,
            'min_norm_threshold': min_norm_threshold,
            'use_cache_optimization': use_cache_optimization,
            'output_order': output_order,
            'reverse_order': reverse_order
        }
        is_valid, errors = self.validate_config(process_config)
        if not is_valid:
            logger.warning(f"MMRProcessoré…ç½®éªŒè¯å¤±è´¥: {errors}")
            # ä½¿ç”¨é…ç½®æ–‡ä»¶ä¸­çš„é»˜è®¤å€¼ç»§ç»­å¤„ç†
            lambda_param = schema['lambda_param']['default']
            select_n = schema['select_n']['default']
            enable_mmr = schema['enable_mmr']['default']
            min_text_length = schema['min_text_length']['default']
            zero_vector_protection = schema['zero_vector_protection']['default']
            zero_vector_strategy = schema['zero_vector_strategy']['default']
            min_norm_threshold = schema['min_norm_threshold']['default']
            use_cache_optimization = schema['use_cache_optimization']['default']
            output_order = schema['output_order']['default']
            reverse_order = schema['reverse_order']['default']
        
        if not results or not enable_mmr:
            logger.info(f"MMRå¤„ç†è·³è¿‡ - resultsæ•°é‡: {len(results) if results else 0}, enable_mmr: {enable_mmr}")
            return results
        
        # ğŸ”´ ç¬¬ä¸€é˜¶æ®µï¼šScoreæ ‡å‡†åŒ–å¤„ç†ï¼ˆè§£å†³æ•°å€¼ç©ºé—´ä¸ä¸€è‡´é—®é¢˜ï¼‰
        enable_normalization = kwargs.get('enable_score_normalization', schema['enable_score_normalization']['default'])
        normalization_method = kwargs.get('normalization_method', schema['normalization_method']['default'])
        
        if enable_normalization:
            logger.info(f"å¼€å§‹Scoreæ ‡å‡†åŒ–å¤„ç†ï¼Œæ–¹æ³•: {normalization_method}")
            results = self._normalize_score_for_filtering(results, normalization_method)
            logger.info(f"Scoreæ ‡å‡†åŒ–å®Œæˆï¼Œæ·»åŠ normalized_scoreå­—æ®µ")
        else:
            logger.info("Scoreæ ‡å‡†åŒ–å·²ç¦ç”¨ï¼Œè·³è¿‡æ ‡å‡†åŒ–å¤„ç†")
        
        # ğŸ”´ ç¬¬äºŒé˜¶æ®µï¼šç›¸å…³æ€§è¿‡æ»¤ï¼ˆä½¿ç”¨æ ‡å‡†åŒ–åçš„æ£€ç´¢åˆ†æ•°ï¼‰
        relevance_threshold = kwargs.get('relevance_threshold', schema['relevance_threshold']['default'])
        enable_filter = kwargs.get('enable_relevance_filter', schema['enable_relevance_filter']['default'])
        
        if enable_filter:
            logger.info(f"å¯ç”¨ç›¸å…³æ€§è¿‡æ»¤ï¼Œé˜ˆå€¼: {relevance_threshold}")
            results = self._apply_relevance_filter(results, enable_filter, relevance_threshold)
            if not results:
                logger.warning("ç›¸å…³æ€§è¿‡æ»¤åæ— ç»“æœï¼Œè¿”å›ç©ºåˆ—è¡¨")
                return []
        else:
            logger.info("ç›¸å…³æ€§è¿‡æ»¤å·²ç¦ç”¨")
        
        logger.info("å¼€å§‹å¤„ç†query embedding:")
        logger.info(f"query_info: {query_info}")
        
        # è·å– embedding_model å®ä¾‹
        logger.info("å°è¯•è·å–embedding_modelå®ä¾‹...")
        embedding_model_instance = kwargs.get('embedding_model')
        
        if not embedding_model_instance:
            logger.warning("embedding_model_instanceä¸ºç©ºï¼Œè¿”å›åŸå§‹ç»“æœ")
            return results
            
        logger.info("å¼€å§‹æå–query_text...")
        query_text = self._extract_query_text(results, query_info)
        logger.info(f"æå–çš„query_text: {query_text}")
        logger.info(f"query_texté•¿åº¦: {len(query_text) if query_text else 0}")
        
        if not query_text:
            logger.warning("query_textä¸ºç©ºï¼Œåº”ç”¨ç®€å•é€‰æ‹©é€»è¾‘è¿”å›ç»“æœ")
            # å³ä½¿æ²¡æœ‰query_textï¼Œä¹Ÿè¦éµå®ˆselect_nå‚æ•°
            select_n = kwargs.get('select_n', schema['select_n']['default'])
            if len(results) > select_n:
                logger.info(f"æ— queryæƒ…å†µä¸‹ï¼Œé™åˆ¶ç»“æœæ•°é‡: {len(results)} -> {select_n}")
                return results[:select_n]
            return results
            
        # è·å–query embedding
        logger.info("å¼€å§‹è·å–query embedding...")
        query_emb = await self._get_embedding_async(query_text, embedding_model_instance)
        logger.info(f"query_embç±»å‹: {type(query_emb)}")
        logger.info(f"query_embé•¿åº¦: {len(query_emb) if query_emb else 0}")
        
        if query_emb is None:
            logger.warning("query_embè·å–å¤±è´¥ï¼Œè¿”å›åŸå§‹ç»“æœ")
            return results
        
        # ğŸ”´ ç¬¬ä¸‰é˜¶æ®µï¼šTop-Né¢„é€‰å’ŒåŠ¨æ€Î»è°ƒæ•´
        max_candidates = kwargs.get('max_candidates', schema['max_candidates']['default'])
        dynamic_lambda = kwargs.get('dynamic_lambda', schema['dynamic_lambda']['default'])
        use_optimized_mmr = kwargs.get('use_optimized_mmr', schema['use_optimized_mmr']['default'])
        
        # Top-Né¢„é€‰ï¼šé™åˆ¶å€™é€‰æ–‡æ¡£æ•°é‡ï¼Œé¿å…å†…å­˜å¼€é”€è¿‡å¤§
        if len(results) > max_candidates:
            logger.info(f"å€™é€‰æ–‡æ¡£æ•°é‡({len(results)})è¶…è¿‡é™åˆ¶({max_candidates})ï¼Œè¿›è¡ŒTop-Né¢„é€‰")
            # æŒ‰æ ‡å‡†åŒ–åçš„scoreæ’åºï¼Œé€‰æ‹©å‰Nä¸ª
            sorted_results = sorted(results, key=lambda x: x.get('normalized_score', x.get('score', 0)), reverse=True)
            results = sorted_results[:max_candidates]
            logger.info(f"Top-Né¢„é€‰å®Œæˆï¼Œä¿ç•™å‰{max_candidates}ä¸ªæ–‡æ¡£")
        
        # åŠ¨æ€Î»è°ƒæ•´ï¼šæ ¹æ®queryé•¿åº¦è‡ªåŠ¨è°ƒæ•´MMRå‚æ•°
        if dynamic_lambda:
            original_lambda = lambda_param
            lambda_param = self._calculate_dynamic_lambda(query_text)
            if lambda_param != original_lambda:
                logger.info(f"åŠ¨æ€Î»è°ƒæ•´: {original_lambda:.3f} -> {lambda_param:.3f} (queryé•¿åº¦: {len(query_text)})")
        else:
            logger.info(f"ä½¿ç”¨å›ºå®šÎ»å‚æ•°: {lambda_param:.3f}")
            
        # è·å–doc embeddings
        logger.info("å¼€å§‹å¤„ç†æ–‡æ¡£embeddings...")
        logger.info(f"min_text_length: {min_text_length}")
        
        # æ”¶é›†æœ‰æ•ˆçš„æ–‡æœ¬å’Œç»“æœ
        valid_texts = []
        valid_results = []
        for i, r in enumerate(results):
            text = r.get('text', '')
            if text and len(text.strip()) >= min_text_length:
                valid_texts.append(text)
                valid_results.append(r)
                logger.info(f"ç»“æœ {i+1} æœ‰æ•ˆï¼Œtexté•¿åº¦: {len(text)}")
            else:
                logger.info(f"ç»“æœ {i+1} è·³è¿‡ - textä¸ºç©ºæˆ–é•¿åº¦ä¸è¶³")
        
        logger.info(f"æ–‡æ¡£embeddingå¤„ç†å‡†å¤‡:")
        logger.info(f"  - æ€»ç»“æœæ•°: {len(results)}")
        logger.info(f"  - æœ‰æ•ˆç»“æœæ•°: {len(valid_results)}")
        logger.info(f"  - æœ‰æ•ˆæ–‡æœ¬æ•°: {len(valid_texts)}")
        
        if not valid_texts:
            logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„æ–‡æœ¬ï¼Œè¿”å›åŸå§‹ç»“æœ")
            return results
        
        # æ‰¹é‡å¼‚æ­¥è·å–embeddings
        logger.info("å¼€å§‹æ‰¹é‡å¼‚æ­¥è·å–æ–‡æ¡£embeddings...")
        doc_embs = await self._get_embeddings_batch_async(valid_texts, embedding_model_instance)
        
        # è¿‡æ»¤æˆåŠŸçš„embeddings
        successful_embeddings = []
        successful_results = []
        for i, (emb, result) in enumerate(zip(doc_embs, valid_results)):
            if emb is not None:
                successful_embeddings.append(emb)
                successful_results.append(result)
                logger.info(f"ç»“æœ {i+1} embeddingè·å–æˆåŠŸï¼Œé•¿åº¦: {len(emb)}")
            else:
                logger.warning(f"ç»“æœ {i+1} embeddingè·å–å¤±è´¥")
        
        logger.info(f"æ‰¹é‡embeddingå¤„ç†å®Œæˆ:")
        logger.info(f"  - æˆåŠŸè·å–embeddingæ•°: {len(successful_embeddings)}")
        logger.info(f"  - æˆåŠŸç»“æœæ•°: {len(successful_results)}")
        
        if not successful_embeddings:
            logger.warning("æ²¡æœ‰æˆåŠŸè·å–çš„embeddingsï¼Œè¿”å›åŸå§‹ç»“æœ")
            return results
        
        doc_texts = valid_texts[:len(successful_embeddings)]
        doc_embs = successful_embeddings
        valid_results = successful_results
        
        if not doc_embs:
            logger.warning("æ²¡æœ‰æœ‰æ•ˆçš„æ–‡æ¡£embeddingsï¼Œè¿”å›åŸå§‹ç»“æœ")
            return results
            
        logger.info("å¼€å§‹è½¬æ¢ä¸ºnumpyæ•°ç»„...")
        doc_embs = np.array(doc_embs)
        query_emb = np.array(query_emb)
        logger.info(f"doc_embsæ•°ç»„å½¢çŠ¶: {doc_embs.shape}")
        logger.info(f"query_embæ•°ç»„å½¢çŠ¶: {query_emb.shape}")
        
        # MMR selection
        logger.info("å¼€å§‹MMRé€‰æ‹©...")
        logger.info(f"use_cache_optimization: {use_cache_optimization}")
        logger.info(f"use_optimized_mmr: {use_optimized_mmr}")
        logger.info(f"lambda_param: {lambda_param}")
        logger.info(f"select_n: {select_n}")
        logger.info(f"å®é™…select_n: {min(select_n, len(doc_embs))}")
        
        # ğŸ”´ ç¬¬ä¸‰é˜¶æ®µï¼šé€‰æ‹©ä¼˜åŒ–çš„MMRç®—æ³•
        if use_optimized_mmr:
            logger.info("ä½¿ç”¨ä¼˜åŒ–çš„MMRé€‰æ‹©ç®—æ³•ï¼ˆé¿å…é‡å¤è®¡ç®—ï¼‰...")
            selected_indices = self._mmr_selection_optimized(
                results, doc_embs, lambda_param, min(select_n, len(doc_embs))
            )
        elif use_cache_optimization:
            logger.info("ä½¿ç”¨ç¼“å­˜ä¼˜åŒ–çš„MMRé€‰æ‹©...")
            selected_indices = self._mmr_selection_with_ordering(
                query_emb, doc_embs, 
                top_k=len(doc_embs), 
                lambda_param=lambda_param, 
                select_n=min(select_n, len(doc_embs)),
                zero_vector_protection=zero_vector_protection,
                zero_vector_strategy=zero_vector_strategy,
                min_norm_threshold=min_norm_threshold,
                output_order=output_order,
                reverse_order=reverse_order
            )
        else:
            logger.info("ä½¿ç”¨æ ‡å‡†MMRé€‰æ‹©...")
            selected_indices = self._mmr_selection(
                query_emb, doc_embs, 
                top_k=len(doc_embs), 
                lambda_param=lambda_param, 
                select_n=min(select_n, len(doc_embs)),
                zero_vector_protection=zero_vector_protection,
                zero_vector_strategy=zero_vector_strategy,
                min_norm_threshold=min_norm_threshold,
                output_order=output_order,
                reverse_order=reverse_order
            )
        
        logger.info(f"MMRé€‰æ‹©å®Œæˆï¼Œselected_indices: {selected_indices}")
        logger.info(f"selected_indicesç±»å‹: {type(selected_indices)}")
        logger.info(f"selected_indicesé•¿åº¦: {len(selected_indices) if selected_indices else 0}")
        
        final_results = [valid_results[idx] for idx in selected_indices]
        logger.info(f"æœ€ç»ˆç»“æœæ•°é‡: {len(final_results)}")
        
        # ğŸ”´ ç¬¬å››é˜¶æ®µï¼šå›é€€æœºåˆ¶å’Œç¨³å®šæ€§å¢å¼º
        min_results_threshold = kwargs.get('min_results_threshold', schema['min_results_threshold']['default'])
        fallback_strategy = kwargs.get('fallback_strategy', schema['fallback_strategy']['default'])
        fallback_levels = kwargs.get('fallback_levels', schema['fallback_levels']['default'])
        enable_fallback_monitoring = kwargs.get('enable_fallback_monitoring', schema['enable_fallback_monitoring']['default'])
        
        # ğŸ”´ å…³é”®ä¿®å¤ï¼šselect_n ä¼˜å…ˆçº§é«˜äº min_results_threshold
        # å¦‚æœç”¨æˆ·æ˜ç¡®è®¾ç½®äº† select_nï¼Œå›é€€æœºåˆ¶ä¸åº”è¯¥è¶…è¿‡è¿™ä¸ªé™åˆ¶
        user_select_n = kwargs.get('select_n')
        if user_select_n is not None and min_results_threshold > user_select_n:
            logger.info(f"ç”¨æˆ·è®¾ç½®select_n={user_select_n}ï¼Œè°ƒæ•´min_results_threshold: {min_results_threshold} -> {user_select_n}")
            min_results_threshold = user_select_n
        
        # æ£€æŸ¥æ˜¯å¦éœ€è¦å›é€€
        if len(final_results) < min_results_threshold:
            logger.warning(f"MMRç»“æœæ•°é‡({len(final_results)})ä½äºæœ€å°é˜ˆå€¼({min_results_threshold})ï¼Œè§¦å‘å›é€€æœºåˆ¶")
            
            # è®°å½•å›é€€å‰çš„çŠ¶æ€
            original_count = len(final_results)
            
            # åº”ç”¨å›é€€æœºåˆ¶
            final_results = self._ensure_minimum_results(
                final_results, min_results_threshold, fallback_strategy, fallback_levels
            )
            
            # ç›‘æ§å›é€€ä½¿ç”¨æƒ…å†µ
            if enable_fallback_monitoring:
                self._monitor_fallback_usage(
                    original_count, len(final_results), fallback_strategy, 0
                )
            
            logger.info(f"å›é€€æœºåˆ¶å®Œæˆï¼Œæœ€ç»ˆç»“æœæ•°é‡: {len(final_results)}")
        else:
            logger.info(f"ç»“æœæ•°é‡({len(final_results)})æ»¡è¶³æœ€å°é˜ˆå€¼({min_results_threshold})ï¼Œæ— éœ€å›é€€")
        
        logger.info("MMRå¤„ç†å®Œæˆï¼Œè¿”å›ç»“æœ")
        return final_results

    def _extract_query_text(self, results: List[Dict[str, Any]], query_info: Dict[str, Any]) -> str:
        if isinstance(query_info, dict) and 'text' in query_info:
            return query_info['text']
        if results and 'query' in results[0]:
            return results[0]['query']
        for key in ['original_query', 'query', 'text']:
            if key in query_info:
                return query_info[key]
        return ''

    def _get_embedding(self, text: str, embedding_model_instance) -> Optional[List[float]]:
        """åŒæ­¥è·å–embeddingæ–¹æ³•ï¼Œä¿æŒå‘åå…¼å®¹"""
        # è°ƒç”¨å¼‚æ­¥ç‰ˆæœ¬
        return asyncio.run(self._get_embedding_async(text, embedding_model_instance))
    
    async def _get_embedding_async(self, text: str, embedding_model_instance) -> Optional[List[float]]:
        """
        è·å–æ–‡æœ¬çš„ embedding å‘é‡
        
        Args:
            text: è¾“å…¥æ–‡æœ¬
            embedding_model_instance: embedding æ¨¡å‹å®ä¾‹
            
        Returns:
            embedding å‘é‡åˆ—è¡¨ï¼Œå¤±è´¥æ—¶è¿”å› None
        """
        logger.info(f"_get_embeddingè¢«è°ƒç”¨:")
        logger.info(f"  - texté•¿åº¦: {len(text) if text else 0}")
        logger.info(f"  - textå‰100å­—ç¬¦: {text[:100] if text else 'None'}...")
        logger.info(f"  - embedding_model_instanceç±»å‹: {type(embedding_model_instance)}")
        logger.info(f"  - embedding_model_instance: {embedding_model_instance}")
        
        try:
            if not embedding_model_instance or not text:
                logger.warning(f"_get_embeddingå‚æ•°æ£€æŸ¥å¤±è´¥ - embedding_model_instance: {bool(embedding_model_instance)}, text: {bool(text)}")
                return None
            
            logger.info("è°ƒç”¨embedding_model_instance.get_embedding...")
            result = embedding_model_instance.get_embedding(text)
            logger.info(f"get_embeddingè°ƒç”¨æˆåŠŸï¼Œè¿”å›ç±»å‹: {type(result)}")
            logger.info(f"get_embeddingè¿”å›é•¿åº¦: {len(result) if result else 0}")
            return result
            
        except Exception as e:
            logger.error(f"MMRProcessor embeddingå¤±è´¥: {e}")
            logger.error(f"å¼‚å¸¸ç±»å‹: {type(e)}")
            import traceback
            logger.error(f"å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
            return None
    
    async def _get_embeddings_batch_async(self, texts: List[str], embedding_model_instance) -> List[Optional[List[float]]]:
        """
        æ‰¹é‡å¼‚æ­¥è·å–æ–‡æœ¬çš„embeddingå‘é‡
        
        Args:
            texts: è¾“å…¥æ–‡æœ¬åˆ—è¡¨
            embedding_model_instance: embeddingæ¨¡å‹å®ä¾‹
            
        Returns:
            embeddingå‘é‡åˆ—è¡¨ï¼Œå¤±è´¥æ—¶å¯¹åº”ä½ç½®ä¸ºNone
        """
        logger.info(f"å¼€å§‹æ‰¹é‡å¼‚æ­¥è·å– {len(texts)} ä¸ªæ–‡æœ¬çš„embeddings...")
        
        # åˆ›å»ºå¼‚æ­¥ä»»åŠ¡åˆ—è¡¨
        tasks = []
        for i, text in enumerate(texts):
            task = self._get_embedding_async(text, embedding_model_instance)
            tasks.append(task)
            logger.info(f"åˆ›å»ºä»»åŠ¡ {i+1}: texté•¿åº¦={len(text)}")
        
        # å¹¶å‘æ‰§è¡Œæ‰€æœ‰ä»»åŠ¡
        logger.info("å¼€å§‹å¹¶å‘æ‰§è¡Œæ‰€æœ‰embeddingä»»åŠ¡...")
        start_time = asyncio.get_event_loop().time()
        
        try:
            embeddings = await asyncio.gather(*tasks, return_exceptions=True)
            end_time = asyncio.get_event_loop().time()
            total_time = end_time - start_time
            
            logger.info(f"æ‰¹é‡embeddingè·å–å®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.2f}ç§’")
            
            # å¤„ç†ç»“æœï¼Œå°†å¼‚å¸¸è½¬æ¢ä¸ºNone
            processed_embeddings = []
            for i, result in enumerate(embeddings):
                if isinstance(result, Exception):
                    logger.error(f"ä»»åŠ¡ {i+1} æ‰§è¡Œå¤±è´¥: {result}")
                    processed_embeddings.append(None)
                else:
                    processed_embeddings.append(result)
                    logger.info(f"ä»»åŠ¡ {i+1} æ‰§è¡ŒæˆåŠŸï¼Œembeddingé•¿åº¦: {len(result) if result else 0}")
            
            return processed_embeddings
            
        except Exception as e:
            logger.error(f"æ‰¹é‡embeddingè·å–è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            # è¿”å›Noneåˆ—è¡¨
            return [None] * len(texts)

    def _safe_normalize(self, vectors: np.ndarray, strategy: str = 'return_zero', min_threshold: float = 1e-8) -> np.ndarray:
        """
        å®‰å…¨çš„å‘é‡å½’ä¸€åŒ–ï¼Œå¤„ç†é›¶å‘é‡æƒ…å†µ
        
        Args:
            vectors: è¾“å…¥å‘é‡æ•°ç»„
            strategy: é›¶å‘é‡å¤„ç†ç­–ç•¥ ('return_zero', 'return_unit', 'skip', 'log_only')
            min_threshold: æœ€å°èŒƒæ•°é˜ˆå€¼
            
        Returns:
            å½’ä¸€åŒ–åçš„å‘é‡æ•°ç»„
        """
        if vectors.size == 0:
            return vectors
            
        # è®¡ç®—æ¯ä¸ªå‘é‡çš„L2èŒƒæ•°
        norms = np.linalg.norm(vectors, axis=-1, keepdims=True)
        
        # æ£€æŸ¥é›¶å‘é‡
        zero_mask = norms < min_threshold
        
        if np.any(zero_mask):
            zero_count = np.sum(zero_mask)
            logger.warning(f"MMRProcessor: å‘ç° {zero_count} ä¸ªé›¶å‘é‡ (èŒƒæ•° < {min_threshold})")
            
            if strategy == 'log_only':
                # åªè®°å½•æ—¥å¿—ï¼Œç»§ç»­ä½¿ç”¨åŸå§‹å‘é‡
                pass
            elif strategy == 'skip':
                # è·³è¿‡é›¶å‘é‡ï¼Œè¿”å›Noneæˆ–æ ‡è®°
                logger.warning("MMRProcessor: é›¶å‘é‡ç­–ç•¥ä¸º'skip'ï¼Œä½†å½“å‰å®ç°ä¸æ”¯æŒè·³è¿‡ï¼Œä½¿ç”¨'return_zero'ç­–ç•¥")
                strategy = 'return_zero'
            elif strategy == 'return_unit':
                # è¿”å›å•ä½å‘é‡
                unit_vector = np.ones_like(vectors[0]) / np.sqrt(vectors.shape[-1])
                vectors = vectors.copy()
                vectors[zero_mask.flatten()] = unit_vector
                logger.info(f"MMRProcessor: å°† {zero_count} ä¸ªé›¶å‘é‡æ›¿æ¢ä¸ºå•ä½å‘é‡")
            elif strategy == 'return_zero':
                # è¿”å›é›¶å‘é‡ï¼ˆé»˜è®¤è¡Œä¸ºï¼‰
                logger.info(f"MMRProcessor: ä¿æŒ {zero_count} ä¸ªé›¶å‘é‡ä¸å˜")
            else:
                logger.warning(f"MMRProcessor: æœªçŸ¥çš„é›¶å‘é‡ç­–ç•¥ '{strategy}'ï¼Œä½¿ç”¨'return_zero'")
                strategy = 'return_zero'
        
        # æ‰§è¡Œå½’ä¸€åŒ–ï¼ˆé›¶å‘é‡ä¿æŒä¸ºé›¶ï¼‰
        safe_norms = np.where(zero_mask, 1.0, norms)
        return vectors / safe_norms

    def _mmr_selection(self, query_embedding: np.ndarray, doc_embeddings: np.ndarray, top_k: int, lambda_param: float, select_n: int, zero_vector_protection: bool, zero_vector_strategy: str, min_norm_threshold: float, output_order: str = 'mmr_score', reverse_order: bool = False) -> List[int]:
        # å¤„ç†è¾¹ç•Œæƒ…å†µ
        if len(doc_embeddings) == 0:
            return []
        
        # è·å–é›¶å‘é‡ä¿æŠ¤é…ç½®
        # schema = self.get_config_schema() # This line is removed as per the edit hint
        # zero_protection = schema['zero_vector_protection']['default'] # This line is removed as per the edit hint
        # zero_strategy = schema['zero_vector_strategy']['default'] # This line is removed as per the edit hint
        # min_threshold = schema['min_norm_threshold']['default'] # This line is removed as per the edit hint
        
        # ä½¿ç”¨å®‰å…¨çš„å½’ä¸€åŒ–å‡½æ•°
        if zero_vector_protection:
            q_norm = self._safe_normalize(query_embedding, zero_vector_strategy, min_norm_threshold)
            docs_norm = self._safe_normalize(doc_embeddings, zero_vector_strategy, min_norm_threshold)
        else:
            # åŸæœ‰çš„ç®€å•å½’ä¸€åŒ–ï¼ˆå‘åå…¼å®¹ï¼‰
            def normalize(x):
                norm = np.linalg.norm(x, axis=-1, keepdims=True)
                norm = np.where(norm == 0, 1, norm)
                return x / norm
            q_norm = normalize(query_embedding)
            docs_norm = normalize(doc_embeddings)
        
        sim_to_query = docs_norm.dot(q_norm)
        top_indices = np.argsort(sim_to_query)[-top_k:][::-1]
        selected = []
        
        for _ in range(min(select_n, len(top_indices))):
            mmr_scores = []
            for idx in top_indices:
                if idx in selected:
                    continue
                rel = sim_to_query[idx]
                if selected:
                    sim_to_selected = docs_norm[idx].dot(docs_norm[selected].T)
                    div = np.max(sim_to_selected)
                else:
                    div = 0
                mmr_score = lambda_param * rel - (1 - lambda_param) * div
                mmr_scores.append((idx, mmr_score))
            if not mmr_scores:
                break
            best_idx, _ = max(mmr_scores, key=lambda x: x[1])
            selected.append(best_idx)
        return selected

    def _mmr_selection_with_cache(self, query_embedding: np.ndarray, doc_embeddings: np.ndarray, top_k: int, lambda_param: float, select_n: int, zero_vector_protection: bool, zero_vector_strategy: str, min_norm_threshold: float, output_order: str = 'mmr_score', reverse_order: bool = False) -> List[int]:
        """
        å¸¦ç¼“å­˜ä¼˜åŒ–çš„MMRé€‰æ‹©ç®—æ³•
        
        Args:
            query_embedding: æŸ¥è¯¢å‘é‡
            doc_embeddings: æ–‡æ¡£å‘é‡æ•°ç»„
            top_k: å€™é€‰æ–‡æ¡£æ•°é‡
            lambda_param: MMRå‚æ•°
            select_n: é€‰æ‹©æ–‡æ¡£æ•°é‡
            zero_vector_protection: æ˜¯å¦å¯ç”¨é›¶å‘é‡ä¿æŠ¤
            zero_vector_strategy: é›¶å‘é‡å¤„ç†ç­–ç•¥
            min_norm_threshold: æœ€å°èŒƒæ•°é˜ˆå€¼
            
        Returns:
            é€‰æ‹©çš„æ–‡æ¡£ç´¢å¼•åˆ—è¡¨
        """
        if len(doc_embeddings) == 0:
            return []
        
        # ä½¿ç”¨å®‰å…¨çš„å½’ä¸€åŒ–å‡½æ•°
        if zero_vector_protection:
            q_norm = self._safe_normalize(query_embedding, zero_vector_strategy, min_norm_threshold)
            docs_norm = self._safe_normalize(doc_embeddings, zero_vector_strategy, min_norm_threshold)
        else:
            # åŸæœ‰çš„ç®€å•å½’ä¸€åŒ–ï¼ˆå‘åå…¼å®¹ï¼‰
            def normalize(x):
                norm = np.linalg.norm(x, axis=-1, keepdims=True)
                norm = np.where(norm == 0, 1, norm)
                return x / norm
            q_norm = normalize(query_embedding)
            docs_norm = normalize(doc_embeddings)
        
        sim_to_query = docs_norm.dot(q_norm)
        top_indices = np.argsort(sim_to_query)[-top_k:][::-1]
        
        selected = []
        selected_set = set()  # ä½¿ç”¨setæé«˜æŸ¥æ‰¾æ•ˆç‡
        
        # ç¼“å­˜æ¯ä¸ªå€™é€‰ä¸å·²é€‰æ–‡æ¡£çš„æœ€å¤§ç›¸ä¼¼åº¦
        max_sim_cache = np.zeros(len(top_indices))
        
        for _ in range(min(select_n, len(top_indices))):
            mmr_scores = []
            for i, idx in enumerate(top_indices):
                if idx in selected_set:  # ä½¿ç”¨setæŸ¥æ‰¾ï¼ŒO(1)å¤æ‚åº¦
                    continue
                rel = sim_to_query[idx]
                div = max_sim_cache[i]  # ä½¿ç”¨ç¼“å­˜çš„æœ€å¤§ç›¸ä¼¼åº¦
                mmr_score = lambda_param * rel - (1 - lambda_param) * div
                mmr_scores.append((idx, mmr_score))
            
            if not mmr_scores:
                break
            best_idx, _ = max(mmr_scores, key=lambda x: x[1])
            selected.append(best_idx)
            selected_set.add(best_idx)
            
            # æ›´æ–°ç¼“å­˜ï¼šæ–°é€‰æ–‡æ¡£ä¸æ‰€æœ‰å€™é€‰çš„ç›¸ä¼¼åº¦
            if selected:
                new_sims = docs_norm[best_idx].dot(docs_norm[top_indices].T)
                max_sim_cache = np.maximum(max_sim_cache, new_sims)
        
        return selected

    def _mmr_selection_with_ordering(self, query_embedding: np.ndarray, doc_embeddings: np.ndarray, top_k: int, lambda_param: float, select_n: int, zero_vector_protection: bool, zero_vector_strategy: str, min_norm_threshold: float, output_order: str = 'mmr_score', reverse_order: bool = False) -> List[int]:
        """
        å¸¦è¾“å‡ºé¡ºåºä¼˜åŒ–çš„MMRé€‰æ‹©ç®—æ³•
        
        Args:
            query_embedding: æŸ¥è¯¢å‘é‡
            doc_embeddings: æ–‡æ¡£å‘é‡æ•°ç»„
            top_k: å€™é€‰æ–‡æ¡£æ•°é‡
            lambda_param: MMRå‚æ•°
            select_n: é€‰æ‹©æ–‡æ¡£æ•°é‡
            zero_vector_protection: æ˜¯å¦å¯ç”¨é›¶å‘é‡ä¿æŠ¤
            zero_vector_strategy: é›¶å‘é‡å¤„ç†ç­–ç•¥
            min_norm_threshold: æœ€å°èŒƒæ•°é˜ˆå€¼
            output_order: è¾“å‡ºæ’åºæ–¹å¼ ('mmr_score', 'relevance', 'diversity')
            reverse_order: æ˜¯å¦é€†åºæ’åˆ—
            
        Returns:
            é€‰æ‹©çš„æ–‡æ¡£ç´¢å¼•åˆ—è¡¨
        """
        # ä½¿ç”¨ç¼“å­˜ä¼˜åŒ–çš„MMRé€‰æ‹©
        selected = self._mmr_selection_with_cache(
            query_embedding, doc_embeddings, top_k, lambda_param, select_n,
            zero_vector_protection, zero_vector_strategy, min_norm_threshold,
            output_order=output_order, reverse_order=reverse_order
        )
        
        if not selected:
            return []
        
        # æ ¹æ®æŒ‡å®šæ–¹å¼é‡æ–°æ’åº
        if output_order == 'relevance':
            # ä½¿ç”¨å®‰å…¨çš„å½’ä¸€åŒ–å‡½æ•°
            if zero_vector_protection:
                q_norm = self._safe_normalize(query_embedding, zero_vector_strategy, min_norm_threshold)
                docs_norm = self._safe_normalize(doc_embeddings, zero_vector_strategy, min_norm_threshold)
            else:
                def normalize(x):
                    norm = np.linalg.norm(x, axis=-1, keepdims=True)
                    norm = np.where(norm == 0, 1, norm)
                    return x / norm
                q_norm = normalize(query_embedding)
                docs_norm = normalize(doc_embeddings)
            
            # æŒ‰ç›¸å…³æ€§æ’åº
            sim_to_query = docs_norm.dot(q_norm)
            selected_sims = sim_to_query[selected]
            sorted_indices = np.argsort(selected_sims)
            if not reverse_order:
                sorted_indices = sorted_indices[::-1]  # é™åº
            return [selected[i] for i in sorted_indices]
            
        elif output_order == 'diversity':
            # ä½¿ç”¨å®‰å…¨çš„å½’ä¸€åŒ–å‡½æ•°
            if zero_vector_protection:
                docs_norm = self._safe_normalize(doc_embeddings, zero_vector_strategy, min_norm_threshold)
            else:
                def normalize(x):
                    norm = np.linalg.norm(x, axis=-1, keepdims=True)
                    norm = np.where(norm == 0, 1, norm)
                    return x / norm
                docs_norm = normalize(doc_embeddings)
            
            # æŒ‰å¤šæ ·æ€§æ’åºï¼ˆä¸å·²é€‰æ–‡æ¡£çš„å¹³å‡ç›¸ä¼¼åº¦ï¼‰
            diversity_scores = []
            for idx in selected:
                sim_to_others = docs_norm[idx].dot(docs_norm[selected].T)
                diversity = 1 - np.mean(sim_to_others)
                diversity_scores.append(diversity)
            sorted_indices = np.argsort(diversity_scores)
            if not reverse_order:
                sorted_indices = sorted_indices[::-1]  # é™åº
            return [selected[i] for i in sorted_indices]
            
        else:
            # ä¿æŒMMRé€‰æ‹©é¡ºåº
            if reverse_order:
                return selected[::-1]
            return selected

    def get_name(self) -> str:
        return 'mmr'
    
    # ğŸ”´ ç¬¬ä¸€é˜¶æ®µï¼šScoreæ ‡å‡†åŒ–åŸºç¡€è®¾æ–½æ–¹æ³•
    
    def _normalize_score_for_filtering(self, results: List[Dict], normalization_method: str = 'log_minmax') -> List[Dict]:
        """
        æ ¹æ®æ ‡å‡†åŒ–æ–¹æ³•å¤„ç†scoreï¼Œç¡®ä¿æ•°å€¼ç©ºé—´ä¸€è‡´
        
        Args:
            results: æ£€ç´¢ç»“æœåˆ—è¡¨
            normalization_method: æ ‡å‡†åŒ–æ–¹æ³•
            
        Returns:
            æ ‡å‡†åŒ–åçš„ç»“æœåˆ—è¡¨ï¼ŒåŒ…å«normalized_scoreå­—æ®µ
        """
        if not results:
            return results
        
        # è‡ªåŠ¨æ£€æµ‹æœç´¢å¼•æ“ç±»å‹
        search_type = self._detect_search_type(results)
        logger.info(f"æ£€æµ‹åˆ°æœç´¢å¼•æ“ç±»å‹: {search_type}")
        
        # æ ¹æ®æœç´¢å¼•æ“ç±»å‹è¿›è¡Œæ ‡å‡†åŒ–
        if search_type == 'dense':
            return self._normalize_dense_scores(results)
        elif search_type == 'hybrid':
            return self._normalize_hybrid_scores(results)
        elif search_type == 'sparse':
            return self._normalize_sparse_scores(results)
        else:
            # æœªçŸ¥ç±»å‹ï¼Œä½¿ç”¨é€šç”¨æ ‡å‡†åŒ–
            return self._normalize_generic_scores(results)
    
    def _detect_search_type(self, results: List[Dict]) -> str:
        """è‡ªåŠ¨æ£€æµ‹æœç´¢å¼•æ“ç±»å‹"""
        if not results:
            return 'unknown'
        
        # æå–æ‰€æœ‰æœ‰æ•ˆçš„scoreå€¼
        scores = []
        for result in results:
            if 'score' in result and result['score'] is not None:
                scores.append(result['score'])
        
        if not scores:
            return 'unknown'
        
        # åˆ†æscoreç‰¹å¾åˆ¤æ–­ç±»å‹
        min_score = min(scores)
        max_score = max(scores)
        
        # å¦‚æœscoreåœ¨[0,1]èŒƒå›´å†…ï¼Œå¯èƒ½æ˜¯dense search
        if 0 <= min_score <= max_score <= 1:
            return 'dense'
        # å¦‚æœscoreåœ¨[-1,1]èŒƒå›´å†…ï¼Œå¯èƒ½æ˜¯cosineç›¸ä¼¼åº¦
        elif -1 <= min_score <= max_score <= 1:
            return 'dense'
        # å¦‚æœscoreæœ‰æå€¼ï¼ˆè´Ÿå€¼æˆ–è¶…å‡ºæ­£å¸¸èŒƒå›´ï¼‰ï¼Œå¯èƒ½æ˜¯hybrid search
        elif min_score < -100 or max_score > 100:
            return 'hybrid'
        # å¦‚æœscoreéƒ½æ˜¯æ­£å€¼ä½†ä¸åœ¨[0,1]èŒƒå›´ï¼Œå¯èƒ½æ˜¯sparse search (BM25)
        elif min_score >= 0 and max_score > 1:
            return 'sparse'
        # å…¶ä»–æƒ…å†µ
        else:
            return 'unknown'
    
    def _normalize_dense_scores(self, results: List[Dict]) -> List[Dict]:
        """æ ‡å‡†åŒ–dense searchçš„score"""
        if not results:
            return results
        
        # ä»é…ç½®è·å–é»˜è®¤å€¼
        default_score = get_processor_config('mmr').get('default_normalized_score', 0.5)
        
        # Dense searchçš„scoreé€šå¸¸å·²ç»åœ¨[0,1]èŒƒå›´å†…ï¼Œä½†éœ€è¦éªŒè¯å’Œå¾®è°ƒ
        for result in results:
            if 'score' in result and result['score'] is not None:
                score = result['score']
                # ç¡®ä¿scoreåœ¨[0,1]èŒƒå›´å†…
                normalized_score = max(0.0, min(1.0, score))
                result['normalized_score'] = normalized_score
                result['original_score'] = score
            else:
                # å¦‚æœæ²¡æœ‰scoreå­—æ®µï¼Œä½¿ç”¨é…ç½®çš„é»˜è®¤å€¼
                result['normalized_score'] = default_score
                result['original_score'] = 0.0
        
        return results
    
    def _normalize_hybrid_scores(self, results: List[Dict]) -> List[Dict]:
        """æ ‡å‡†åŒ–hybrid searchçš„scoreï¼ˆé€‚ç”¨äºæç«¯å¼‚å¸¸å€¼ï¼‰"""
        if not results:
            return results
        
        # ä»é…ç½®è·å–é»˜è®¤å€¼
        default_score = get_processor_config('mmr').get('default_normalized_score', 0.5)
        
        # æå–æ‰€æœ‰æœ‰æ•ˆçš„scoreå€¼
        scores = []
        for result in results:
            if 'score' in result and result['score'] is not None:
                scores.append(result['score'])
        
        if not scores:
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆscoreï¼Œä½¿ç”¨é…ç½®çš„é»˜è®¤å€¼
            for result in results:
                result['normalized_score'] = default_score
                result['original_score'] = 0.0
            return results
        
        # ä½¿ç”¨å¯¹æ•°å˜æ¢ + Min-Maxæ ‡å‡†åŒ–å¤„ç†æç«¯å¼‚å¸¸å€¼
        normalized_scores = self._apply_log_minmax_normalization(scores)
        
        # å°†æ ‡å‡†åŒ–åçš„scoreèµ‹å€¼ç»™ç»“æœ
        score_index = 0
        for result in results:
            if 'score' in result and result['score'] is not None:
                result['normalized_score'] = normalized_scores[score_index]
                result['original_score'] = result['score']
                score_index += 1
            else:
                result['normalized_score'] = default_score
                result['original_score'] = 0.0
        
        return results
    
    def _normalize_sparse_scores(self, results: List[Dict]) -> List[Dict]:
        """æ ‡å‡†åŒ–sparse searchçš„score"""
        if not results:
            return results
        
        # ä»é…ç½®è·å–é»˜è®¤å€¼
        default_score = get_processor_config('mmr').get('default_normalized_score', 0.5)
        
        # æå–æ‰€æœ‰æœ‰æ•ˆçš„scoreå€¼
        scores = []
        for result in results:
            if 'score' in result and result['score'] is not None:
                scores.append(result['score'])
        
        if not scores:
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆscoreï¼Œä½¿ç”¨é…ç½®çš„é»˜è®¤å€¼
            for result in results:
                result['normalized_score'] = default_score
                result['original_score'] = 0.0
            return results
        
        # Sparse searché€šå¸¸ä½¿ç”¨Min-Maxæ ‡å‡†åŒ–
        min_score = min(scores)
        max_score = max(scores)
        
        if max_score > min_score:
            for result in results:
                if 'score' in result and result['score'] is not None:
                    # Min-Maxæ ‡å‡†åŒ–åˆ°[0,1]
                    normalized_score = (result['score'] - min_score) / (max_score - min_score)
                    result['normalized_score'] = normalized_score
                    result['original_score'] = result['score']
                else:
                    result['normalized_score'] = default_score
                    result['original_score'] = 0.0
        else:
            # æ‰€æœ‰scoreç›¸åŒçš„æƒ…å†µ
            for result in results:
                if 'score' in result and result['score'] is not None:
                    result['normalized_score'] = default_score
                    result['original_score'] = result['score']
                else:
                    result['normalized_score'] = default_score
                    result['original_score'] = 0.0
        
        return results
    
    def _normalize_generic_scores(self, results: List[Dict]) -> List[Dict]:
        """é€šç”¨æ ‡å‡†åŒ–æ–¹æ³•"""
        if not results:
            return results
        
        # ä»é…ç½®è·å–é»˜è®¤å€¼
        default_score = get_processor_config('mmr').get('default_normalized_score', 0.5)
        
        # æå–æ‰€æœ‰æœ‰æ•ˆçš„scoreå€¼
        scores = []
        for result in results:
            if 'score' in result and result['score'] is not None:
                scores.append(result['score'])
        
        if not scores:
            # å¦‚æœæ²¡æœ‰æœ‰æ•ˆscoreï¼Œä½¿ç”¨é…ç½®çš„é»˜è®¤å€¼
            for result in results:
                result['normalized_score'] = default_score
                result['original_score'] = 0.0
            return results
        
        # ä½¿ç”¨å¯¹æ•°å˜æ¢ + Min-Maxæ ‡å‡†åŒ–ä½œä¸ºé€šç”¨æ–¹æ³•
        normalized_scores = self._apply_log_minmax_normalization(scores)
        
        # å°†æ ‡å‡†åŒ–åçš„scoreèµ‹å€¼ç»™ç»“æœ
        score_index = 0
        for result in results:
            if 'score' in result and result['score'] is not None:
                result['normalized_score'] = normalized_scores[score_index]
                result['original_score'] = result['score']
                score_index += 1
            else:
                result['normalized_score'] = default_score
                result['original_score'] = 0.0
        
        return results
    
    # ğŸ”´ ç¬¬äºŒé˜¶æ®µï¼šç›¸å…³æ€§è¿‡æ»¤ä¼˜åŒ–
    
    def _apply_relevance_filter(self, results: List[Dict], enable_filter: bool, relevance_threshold: float) -> List[Dict]:
        """
        ä½¿ç”¨æ ‡å‡†åŒ–åçš„æ£€ç´¢åˆ†æ•°è¿›è¡Œç›¸å…³æ€§è¿‡æ»¤
        
        Args:
            results: æ£€ç´¢ç»“æœåˆ—è¡¨ï¼ˆå·²æ ‡å‡†åŒ–ï¼‰
            enable_filter: æ˜¯å¦å¯ç”¨è¿‡æ»¤
            relevance_threshold: ç›¸å…³æ€§é˜ˆå€¼ï¼ˆåŸºäºæ ‡å‡†åŒ–åçš„åˆ†æ•°ï¼‰
            
        Returns:
            è¿‡æ»¤åçš„ç»“æœåˆ—è¡¨
        """
        if not enable_filter:
            logger.info("ç›¸å…³æ€§è¿‡æ»¤å·²ç¦ç”¨ï¼Œè·³è¿‡è¿‡æ»¤å¤„ç†")
            return results
            
        if not results:
            logger.warning("ç©ºç»“æœåˆ—è¡¨ï¼Œæ— æ³•è¿›è¡Œç›¸å…³æ€§è¿‡æ»¤")
            return results
        
        # ç»Ÿè®¡è¿‡æ»¤å‰çš„ç»“æœ
        original_count = len(results)
        logger.info(f"å¼€å§‹ç›¸å…³æ€§è¿‡æ»¤ï¼ŒåŸå§‹ç»“æœæ•°: {original_count}ï¼Œé˜ˆå€¼: {relevance_threshold}")
        
        # ä½¿ç”¨æ ‡å‡†åŒ–åçš„scoreè¿›è¡Œè¿‡æ»¤
        # ä¼˜å…ˆä½¿ç”¨normalized_scoreï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨åŸå§‹score
        filtered_results = []
        score_stats = []
        
        for i, result in enumerate(results):
            # ä¼˜å…ˆä½¿ç”¨æ ‡å‡†åŒ–åçš„åˆ†æ•°
            score_to_check = result.get('normalized_score', result.get('score', 0))
            score_stats.append(score_to_check)
            
            if score_to_check >= relevance_threshold:
                filtered_results.append(result)
                logger.debug(f"ç»“æœ {i+1} é€šè¿‡è¿‡æ»¤ï¼Œscore: {score_to_check:.4f}")
            else:
                logger.debug(f"ç»“æœ {i+1} è¢«è¿‡æ»¤ï¼Œscore: {score_to_check:.4f} < {relevance_threshold}")
        
        # è¿‡æ»¤åçš„ç»Ÿè®¡ä¿¡æ¯
        filtered_count = len(filtered_results)
        filter_ratio = filtered_count / original_count if original_count > 0 else 0
        
        # åˆ†æscoreåˆ†å¸ƒ
        if score_stats:
            min_score = min(score_stats)
            max_score = max(score_stats)
            avg_score = sum(score_stats) / len(score_stats)
            
            logger.info(f"Scoreåˆ†å¸ƒ - èŒƒå›´: [{min_score:.4f}, {max_score:.4f}], å‡å€¼: {avg_score:.4f}")
        
        # æ ¹æ®è¿‡æ»¤æ•ˆæœç»™å‡ºä¸åŒçº§åˆ«çš„æ—¥å¿—
        if filtered_count == 0:
            logger.error(f"ç›¸å…³æ€§è¿‡æ»¤åæ— ç»“æœï¼Œé˜ˆå€¼å¯èƒ½è¿‡é«˜: {relevance_threshold}")
            logger.error(f"å»ºè®®é™ä½é˜ˆå€¼æˆ–æ£€æŸ¥scoreæ ‡å‡†åŒ–æ˜¯å¦æ­£ç¡®")
        elif filter_ratio < 0.3:
            logger.warning(f"ç›¸å…³æ€§è¿‡æ»¤è¾ƒä¸¥æ ¼: {original_count} -> {filtered_count} (ä¿ç•™ {filter_ratio:.1%})")
            logger.warning(f"å»ºè®®è€ƒè™‘é™ä½é˜ˆå€¼ä» {relevance_threshold} åˆ° {relevance_threshold * 0.8:.2f}")
        elif filter_ratio < 0.7:
            logger.info(f"ç›¸å…³æ€§è¿‡æ»¤é€‚ä¸­: {original_count} -> {filtered_count} (ä¿ç•™ {filter_ratio:.1%})")
        else:
            logger.info(f"ç›¸å…³æ€§è¿‡æ»¤å®½æ¾: {original_count} -> {filtered_count} (ä¿ç•™ {filter_ratio:.1%})")
            if filter_ratio > 0.9:
                logger.info(f"å»ºè®®è€ƒè™‘æé«˜é˜ˆå€¼ä» {relevance_threshold} åˆ° {relevance_threshold * 1.2:.2f}")
        
        logger.info(f"ç›¸å…³æ€§è¿‡æ»¤å®Œæˆ: {original_count} -> {filtered_count}")
        return filtered_results
    
    # ğŸ”´ ç¬¬ä¸‰é˜¶æ®µï¼šMMRç®—æ³•æ ¸å¿ƒä¼˜åŒ–
    
    def _mmr_selection_optimized(self, results: List[Dict], doc_embs: np.ndarray, 
                                lambda_param: float, select_n: int) -> List[int]:
        """
        ä¼˜åŒ–çš„MMRé€‰æ‹©ç®—æ³•
        
        Args:
            results: æ£€ç´¢ç»“æœåˆ—è¡¨ï¼ˆåŒ…å«scoreå­—æ®µï¼‰
            doc_embs: æ–‡æ¡£embeddingçŸ©é˜µ
            lambda_param: MMR lambdaå‚æ•°
            select_n: é€‰æ‹©æ•°é‡
            
        Returns:
            é€‰æ‹©çš„æ–‡æ¡£ç´¢å¼•åˆ—è¡¨
        """
        if len(results) == 0:
            return []
        
        # 1. ç›´æ¥ä½¿ç”¨æ£€ç´¢åˆ†æ•°ï¼Œé¿å…é‡å¤è®¡ç®—
        relevance_scores = np.array([r.get('normalized_score', r.get('score', 0)) for r in results])
        
        # 2. é¢„è®¡ç®—æ–‡æ¡£é—´ç›¸ä¼¼åº¦çŸ©é˜µï¼ˆä»…è®¡ç®—ä¸€æ¬¡ï¼‰
        # æ³¨æ„ï¼šå¿…é¡»å…ˆå¯¹doc_embsåšL2å½’ä¸€åŒ–ï¼Œå¦åˆ™ä¸æ˜¯æ ‡å‡†cosineç›¸ä¼¼åº¦
        doc_embs_normalized = self._safe_normalize(doc_embs, 'return_unit', 1e-8)
        doc_doc_sim = np.dot(doc_embs_normalized, doc_embs_normalized.T)
        
        # 3. MMRé€‰æ‹©é€»è¾‘
        selected = []
        for _ in range(min(select_n, len(results))):
            mmr_scores = []
            for i, result in enumerate(results):
                if i in selected:
                    continue
                
                # ä½¿ç”¨æ£€ç´¢åˆ†æ•°ä½œä¸ºç›¸å…³æ€§
                rel = relevance_scores[i]
                
                # è®¡ç®—å¤šæ ·æ€§ï¼ˆä¸å·²é€‰æ–‡æ¡£çš„æœ€å¤§ç›¸ä¼¼åº¦ï¼‰
                if selected:
                    div = max(doc_doc_sim[i, selected])
                else:
                    div = 0
                
                mmr_score = lambda_param * rel - (1 - lambda_param) * div
                mmr_scores.append((i, mmr_score))
            
            if not mmr_scores:
                break
            best_idx, _ = max(mmr_scores, key=lambda x: x[1])
            selected.append(best_idx)
        
        return selected
    
    # ğŸ”´ ç¬¬å››é˜¶æ®µï¼šå›é€€æœºåˆ¶å’Œç¨³å®šæ€§å¢å¼º
    
    def _ensure_minimum_results(self, results: List[Dict], min_threshold: int, 
                               fallback_strategy: str, fallback_levels: int = None) -> List[Dict]:
        """
        ç¡®ä¿è¿”å›æœ€å°æ•°é‡çš„ç»“æœï¼Œå®ç°å¤šå±‚å›é€€æœºåˆ¶
        
        Args:
            results: å½“å‰ç»“æœåˆ—è¡¨
            min_threshold: æœ€å°ç»“æœæ•°é‡é˜ˆå€¼
            fallback_strategy: å›é€€ç­–ç•¥
            fallback_levels: å¤šçº§å›é€€çš„çº§åˆ«æ•°é‡
            
        Returns:
            ç¡®ä¿æ»¡è¶³æœ€å°æ•°é‡çš„ç»“æœåˆ—è¡¨
        """
        # ä»é…ç½®è·å–é»˜è®¤å€¼
        if fallback_levels is None:
            fallback_levels = get_processor_config('mmr').get('fallback_levels', 3)
        
        original_count = len(results)
        
        if original_count >= min_threshold:
            logger.info(f"ç»“æœæ•°é‡({original_count})å·²æ»¡è¶³æœ€å°é˜ˆå€¼({min_threshold})ï¼Œæ— éœ€å›é€€")
            return results
        
        logger.warning(f"ç»“æœæ•°é‡({original_count})ä½äºæœ€å°é˜ˆå€¼({min_threshold})ï¼Œè§¦å‘å›é€€æœºåˆ¶")
        logger.info(f"ä½¿ç”¨å›é€€ç­–ç•¥: {fallback_strategy}")
        
        # æ‰§è¡Œå›é€€ç­–ç•¥
        if fallback_strategy == 'multi_level':
            fallback_results = self._apply_multi_level_fallback(results, min_threshold, fallback_levels)
        elif fallback_strategy == 'score_sort':
            fallback_results = self._apply_score_sort_fallback(results, min_threshold)
        elif fallback_strategy == 'random':
            fallback_results = self._apply_random_fallback(results, min_threshold)
        elif fallback_strategy == 'original':
            fallback_results = self._apply_original_fallback(results, min_threshold)
        else:
            logger.warning(f"æœªçŸ¥çš„å›é€€ç­–ç•¥: {fallback_strategy}ï¼Œä½¿ç”¨é»˜è®¤ç­–ç•¥")
            fallback_results = self._apply_multi_level_fallback(results, min_threshold, fallback_levels)
        
        # è®°å½•å›é€€ç›‘æ§ç»Ÿè®¡
        final_count = len(fallback_results)
        self._monitor_fallback_usage(original_count, final_count, fallback_strategy)
        
        return fallback_results
    
    def _apply_multi_level_fallback(self, results: List[Dict], min_threshold: int, 
                                   fallback_levels: int) -> List[Dict]:
        """
        å¤šçº§å›é€€ç­–ç•¥ï¼šé€æ­¥æ”¾å®½æ¡ä»¶ï¼Œç¡®ä¿è¿”å›è¶³å¤Ÿçš„ç»“æœ
        
        Args:
            results: å½“å‰ç»“æœåˆ—è¡¨
            min_threshold: æœ€å°ç»“æœæ•°é‡é˜ˆå€¼
            fallback_levels: å›é€€çº§åˆ«æ•°é‡
            
        Returns:
            å›é€€åçš„ç»“æœåˆ—è¡¨
        """
        logger.info(f"å¼€å§‹å¤šçº§å›é€€ï¼Œç›®æ ‡ç»“æœæ•°: {min_threshold}ï¼Œå›é€€çº§åˆ«: {fallback_levels}")
        
        # ç¬¬ä¸€çº§ï¼šå°è¯•é™ä½ç›¸å…³æ€§é˜ˆå€¼
        if len(results) < min_threshold:
            logger.info("ç¬¬ä¸€çº§å›é€€ï¼šé™ä½ç›¸å…³æ€§é˜ˆå€¼")
            # è¿™é‡Œå¯ä»¥é‡æ–°è°ƒç”¨ç›¸å…³æ€§è¿‡æ»¤ï¼Œä½¿ç”¨æ›´ä½çš„é˜ˆå€¼
            # æš‚æ—¶ä½¿ç”¨scoreæ’åºä½œä¸ºç¬¬ä¸€çº§å›é€€
            fallback_results = self._apply_score_sort_fallback(results, min_threshold)
            if len(fallback_results) >= min_threshold:
                logger.info(f"ç¬¬ä¸€çº§å›é€€æˆåŠŸï¼Œè·å¾— {len(fallback_results)} ä¸ªç»“æœ")
                return fallback_results
        
        # ç¬¬äºŒçº§ï¼šä½¿ç”¨åŸå§‹scoreæ’åºï¼Œä¸è€ƒè™‘MMRå¤šæ ·æ€§
        if len(results) < min_threshold:
            logger.info("ç¬¬äºŒçº§å›é€€ï¼šä½¿ç”¨åŸå§‹scoreæ’åº")
            fallback_results = self._apply_score_sort_fallback(results, min_threshold)
            if len(fallback_results) >= min_threshold:
                logger.info(f"ç¬¬äºŒçº§å›é€€æˆåŠŸï¼Œè·å¾— {len(fallback_results)} ä¸ªç»“æœ")
                return fallback_results
        
        # ç¬¬ä¸‰çº§ï¼šéšæœºé€‰æ‹©ï¼Œç¡®ä¿è¿”å›ç»“æœ
        if len(results) < min_threshold:
            logger.info("ç¬¬ä¸‰çº§å›é€€ï¼šéšæœºé€‰æ‹©")
            fallback_results = self._apply_random_fallback(results, min_threshold)
            if len(fallback_results) >= min_threshold:
                logger.info(f"ç¬¬ä¸‰çº§å›é€€æˆåŠŸï¼Œè·å¾— {len(fallback_results)} ä¸ªç»“æœ")
                return fallback_results
        
        # æœ€ç»ˆå›é€€ï¼šå¦‚æœç»“æœæ•°é‡ä»ç„¶ä¸è¶³ï¼Œé€šè¿‡é‡å¤ç»“æœæ¥è¾¾åˆ°ç›®æ ‡æ•°é‡
        if len(results) < min_threshold:
            logger.warning(f"æ‰€æœ‰å›é€€ç­–ç•¥éƒ½æ— æ³•è¾¾åˆ°ç›®æ ‡æ•°é‡ï¼Œé€šè¿‡é‡å¤ç»“æœæ¥è¾¾åˆ°ç›®æ ‡")
            
            # å¤„ç†ç©ºç»“æœçš„æƒ…å†µ
            if len(results) == 0:
                logger.warning("åŸå§‹ç»“æœä¸ºç©ºï¼Œæ— æ³•é€šè¿‡é‡å¤æ¥è¾¾åˆ°ç›®æ ‡æ•°é‡")
                return []
            
            fallback_results = results.copy()
            while len(fallback_results) < min_threshold:
                # å¾ªç¯æ·»åŠ ç»“æœï¼Œç›´åˆ°è¾¾åˆ°ç›®æ ‡æ•°é‡
                for result in results:
                    if len(fallback_results) >= min_threshold:
                        break
                    # åˆ›å»ºç»“æœçš„å‰¯æœ¬ï¼Œé¿å…ä¿®æ”¹åŸå§‹æ•°æ®
                    result_copy = result.copy()
                    result_copy['_fallback_duplicate'] = True  # æ ‡è®°ä¸ºå›é€€é‡å¤
                    fallback_results.append(result_copy)
            
            logger.info(f"æœ€ç»ˆå›é€€å®Œæˆï¼Œé€šè¿‡é‡å¤ç»“æœè¾¾åˆ°ç›®æ ‡æ•°é‡: {len(fallback_results)}")
            return fallback_results
        
        return results
    
    def _apply_score_sort_fallback(self, results: List[Dict], min_threshold: int) -> List[Dict]:
        """
        æŒ‰scoreæ’åºçš„å›é€€ç­–ç•¥
        
        Args:
            results: å½“å‰ç»“æœåˆ—è¡¨
            min_threshold: æœ€å°ç»“æœæ•°é‡é˜ˆå€¼
            
        Returns:
            æŒ‰scoreæ’åºçš„ç»“æœåˆ—è¡¨ï¼Œå¦‚æœæ•°é‡ä¸è¶³åˆ™é€šè¿‡é‡å¤è¾¾åˆ°ç›®æ ‡æ•°é‡
        """
        if not results:
            return results
        
        # ä¼˜å…ˆä½¿ç”¨normalized_scoreï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨åŸå§‹score
        sorted_results = sorted(results, 
                              key=lambda x: x.get('normalized_score', x.get('score', 0)), 
                              reverse=True)
        
        # å¦‚æœç»“æœæ•°é‡å·²ç»æ»¡è¶³è¦æ±‚ï¼Œç›´æ¥è¿”å›å‰Nä¸ª
        if len(sorted_results) >= min_threshold:
            fallback_results = sorted_results[:min_threshold]
            logger.info(f"Scoreæ’åºå›é€€ï¼šä» {len(results)} ä¸ªç»“æœä¸­é€‰æ‹©å‰ {len(fallback_results)} ä¸ª")
            return fallback_results
        
        # å¦‚æœç»“æœæ•°é‡ä¸è¶³ï¼Œé€šè¿‡é‡å¤æ¥è¾¾åˆ°ç›®æ ‡æ•°é‡
        logger.info(f"Scoreæ’åºå›é€€ï¼šç»“æœæ•°é‡ä¸è¶³({len(sorted_results)} < {min_threshold})ï¼Œé€šè¿‡é‡å¤è¾¾åˆ°ç›®æ ‡æ•°é‡")
        fallback_results = sorted_results.copy()
        
        while len(fallback_results) < min_threshold:
            for result in sorted_results:
                if len(fallback_results) >= min_threshold:
                    break
                # åˆ›å»ºç»“æœçš„å‰¯æœ¬ï¼Œé¿å…ä¿®æ”¹åŸå§‹æ•°æ®
                result_copy = result.copy()
                result_copy['_fallback_duplicate'] = True  # æ ‡è®°ä¸ºå›é€€é‡å¤
                fallback_results.append(result_copy)
        
        logger.info(f"Scoreæ’åºå›é€€å®Œæˆï¼šæœ€ç»ˆç»“æœæ•°é‡ {len(fallback_results)}")
        return fallback_results
    
    def _apply_random_fallback(self, results: List[Dict], min_threshold: int) -> List[Dict]:
        """
        éšæœºé€‰æ‹©çš„å›é€€ç­–ç•¥
        
        Args:
            results: å½“å‰ç»“æœåˆ—è¡¨
            min_threshold: æœ€å°ç»“æœæ•°é‡é˜ˆå€¼
            
        Returns:
            éšæœºé€‰æ‹©çš„ç»“æœåˆ—è¡¨ï¼Œå¦‚æœæ•°é‡ä¸è¶³åˆ™é€šè¿‡é‡å¤è¾¾åˆ°ç›®æ ‡æ•°é‡
        """
        if not results:
            return results
        
        import random
        
        # å¦‚æœç»“æœæ•°é‡å·²ç»æ»¡è¶³è¦æ±‚ï¼Œéšæœºé€‰æ‹©Nä¸ª
        if len(results) >= min_threshold:
            fallback_results = random.sample(results, min_threshold)
            logger.info(f"éšæœºé€‰æ‹©å›é€€ï¼šä» {len(results)} ä¸ªç»“æœä¸­éšæœºé€‰æ‹© {len(fallback_results)} ä¸ª")
            return fallback_results
        
        # å¦‚æœç»“æœæ•°é‡ä¸è¶³ï¼Œé€šè¿‡é‡å¤æ¥è¾¾åˆ°ç›®æ ‡æ•°é‡
        logger.info(f"éšæœºé€‰æ‹©å›é€€ï¼šç»“æœæ•°é‡ä¸è¶³({len(results)} < {min_threshold})ï¼Œé€šè¿‡é‡å¤è¾¾åˆ°ç›®æ ‡æ•°é‡")
        fallback_results = results.copy()
        
        while len(fallback_results) < min_threshold:
            for result in results:
                if len(fallback_results) >= min_threshold:
                    break
                # åˆ›å»ºç»“æœçš„å‰¯æœ¬ï¼Œé¿å…ä¿®æ”¹åŸå§‹æ•°æ®
                result_copy = result.copy()
                result_copy['_fallback_duplicate'] = True  # æ ‡è®°ä¸ºå›é€€é‡å¤
                fallback_results.append(result_copy)
        
        logger.info(f"éšæœºé€‰æ‹©å›é€€å®Œæˆï¼šæœ€ç»ˆç»“æœæ•°é‡ {len(fallback_results)}")
        return fallback_results
    
    def _apply_original_fallback(self, results: List[Dict], min_threshold: int) -> List[Dict]:
        """
        ä¿æŒåŸå§‹é¡ºåºçš„å›é€€ç­–ç•¥
        
        Args:
            results: å½“å‰ç»“æœåˆ—è¡¨
            min_threshold: æœ€å°ç»“æœæ•°é‡é˜ˆå€¼
            
        Returns:
            ä¿æŒåŸå§‹é¡ºåºçš„ç»“æœåˆ—è¡¨ï¼Œå¦‚æœæ•°é‡ä¸è¶³åˆ™é€šè¿‡é‡å¤è¾¾åˆ°ç›®æ ‡æ•°é‡
        """
        if not results:
            return results
        
        # å¦‚æœç»“æœæ•°é‡å·²ç»æ»¡è¶³è¦æ±‚ï¼Œç›´æ¥è¿”å›å‰Nä¸ª
        if len(results) >= min_threshold:
            fallback_results = results[:min_threshold]
            logger.info(f"åŸå§‹é¡ºåºå›é€€ï¼šä¿æŒåŸå§‹é¡ºåºï¼Œè¿”å›å‰ {len(fallback_results)} ä¸ªç»“æœ")
            return fallback_results
        
        # å¦‚æœç»“æœæ•°é‡ä¸è¶³ï¼Œé€šè¿‡é‡å¤æ¥è¾¾åˆ°ç›®æ ‡æ•°é‡
        logger.info(f"åŸå§‹é¡ºåºå›é€€ï¼šç»“æœæ•°é‡ä¸è¶³({len(results)} < {min_threshold})ï¼Œé€šè¿‡é‡å¤è¾¾åˆ°ç›®æ ‡æ•°é‡")
        fallback_results = results.copy()
        
        while len(fallback_results) < min_threshold:
            for result in results:
                if len(fallback_results) >= min_threshold:
                    break
                # åˆ›å»ºç»“æœçš„å‰¯æœ¬ï¼Œé¿å…ä¿®æ”¹åŸå§‹æ•°æ®
                result_copy = result.copy()
                result_copy['_fallback_duplicate'] = True  # æ ‡è®°ä¸ºå›é€€é‡å¤
                fallback_results.append(result_copy)
        
        logger.info(f"åŸå§‹é¡ºåºå›é€€å®Œæˆï¼šæœ€ç»ˆç»“æœæ•°é‡ {len(fallback_results)}")
        return fallback_results
    
    def _monitor_fallback_usage(self, original_count: int, final_count: int, 
                               fallback_strategy: str, fallback_level: int = 0):
        """
        ç›‘æ§å›é€€æœºåˆ¶çš„ä½¿ç”¨æƒ…å†µ
        
        Args:
            original_count: åŸå§‹ç»“æœæ•°é‡
            final_count: æœ€ç»ˆç»“æœæ•°é‡
            fallback_strategy: ä½¿ç”¨çš„å›é€€ç­–ç•¥
            fallback_level: å›é€€çº§åˆ«
        """
        if not hasattr(self, '_fallback_stats'):
            self._fallback_stats = {
                'total_fallbacks': 0,
                'strategy_usage': {},
                'level_usage': {},
                'count_improvement': []
            }
        
        # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯
        self._fallback_stats['total_fallbacks'] += 1
        
        # ç­–ç•¥ä½¿ç”¨ç»Ÿè®¡
        if fallback_strategy not in self._fallback_stats['strategy_usage']:
            self._fallback_stats['strategy_usage'][fallback_strategy] = 0
        self._fallback_stats['strategy_usage'][fallback_strategy] += 1
        
        # çº§åˆ«ä½¿ç”¨ç»Ÿè®¡
        if fallback_level not in self._fallback_stats['level_usage']:
            self._fallback_stats['level_usage'][fallback_level] = 0
        self._fallback_stats['level_usage'][fallback_level] += 1
        
        # æ•°é‡æ”¹å–„ç»Ÿè®¡
        improvement = final_count - original_count
        self._fallback_stats['count_improvement'].append(improvement)
        
        # è®°å½•ç›‘æ§ä¿¡æ¯
        logger.info(f"å›é€€æœºåˆ¶ç›‘æ§ - ç­–ç•¥: {fallback_strategy}, çº§åˆ«: {fallback_level}")
        logger.info(f"å›é€€æœºåˆ¶ç›‘æ§ - åŸå§‹æ•°é‡: {original_count}, æœ€ç»ˆæ•°é‡: {final_count}, æ”¹å–„: {improvement}")
        
        # ç¡®ä¿ç»Ÿè®¡ä¿¡æ¯è¢«æ­£ç¡®è®°å½•
        logger.debug(f"å½“å‰å›é€€ç»Ÿè®¡: {self._fallback_stats}")
    
    def get_fallback_statistics(self) -> Dict[str, Any]:
        """
        è·å–å›é€€æœºåˆ¶çš„ç»Ÿè®¡ä¿¡æ¯
        
        Returns:
            å›é€€æœºåˆ¶ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        if not hasattr(self, '_fallback_stats'):
            return {
                'total_fallbacks': 0,
                'strategy_usage': {},
                'level_usage': {},
                'count_improvement': []
            }
        
        stats = self._fallback_stats.copy()
        
        # è®¡ç®—å¹³å‡å€¼
        if stats['count_improvement']:
            stats['avg_improvement'] = sum(stats['count_improvement']) / len(stats['count_improvement'])
        else:
            stats['avg_improvement'] = 0
        
        return stats
    
    def _calculate_dynamic_lambda(self, query_text: str, base_lambda: float = None) -> float:
        """
        æ ¹æ®queryé•¿åº¦åŠ¨æ€è°ƒæ•´Î»å‚æ•°
        
        Args:
            query_text: æŸ¥è¯¢æ–‡æœ¬
            base_lambda: åŸºç¡€Î»å€¼
            
        Returns:
            è°ƒæ•´åçš„Î»å€¼
        """
        # ä»é…ç½®è·å–é»˜è®¤å€¼
        if base_lambda is None:
            base_lambda = get_processor_config('mmr').get('base_lambda', 0.5)
        
        # ä»é…ç½®è·å–é˜ˆå€¼å’Œè°ƒæ•´å€¼
        short_query_threshold = get_processor_config('mmr').get('short_query_threshold', 10)
        medium_query_threshold = get_processor_config('mmr').get('medium_query_threshold', 30)
        short_adjustment = get_processor_config('mmr').get('short_adjustment', 0.3)
        long_adjustment = get_processor_config('mmr').get('long_adjustment', 0.2)
        max_lambda = get_processor_config('mmr').get('max_lambda', 0.9)
        min_lambda = get_processor_config('mmr').get('min_lambda', 0.3)
        
        if not query_text:
            return base_lambda
        
        # è®¡ç®—queryé•¿åº¦ï¼ˆå»é™¤ç©ºæ ¼ï¼‰
        query_length = len(query_text.strip())
        
        # æ ¹æ®é•¿åº¦è°ƒæ•´Î»ï¼Œä½¿ç”¨é…ç½®å€¼ï¼Œä¸å†hardcode
        if query_length <= short_query_threshold:
            # çŸ­queryï¼ˆå•ä¸ªå…³é”®è¯ï¼‰æ›´çœ‹é‡ç›¸å…³æ€§
            return min(max_lambda, base_lambda + short_adjustment)
        elif query_length <= medium_query_threshold:
            # ä¸­ç­‰é•¿åº¦queryï¼Œä¿æŒå¹³è¡¡
            return base_lambda
        else:
            # é•¿queryï¼ˆå™è¿°å‹ï¼‰é€‚å½“é™ä½Î»ï¼Œè®©å¤šæ ·æ€§å‘æŒ¥ä½œç”¨
            return max(min_lambda, base_lambda - long_adjustment)
    
    def _apply_log_minmax_normalization(self, scores: List[float]) -> List[float]:
        """å¯¹æ•°å˜æ¢ + Min-Maxæ ‡å‡†åŒ–ï¼ˆé€‚ç”¨äºæç«¯å¼‚å¸¸å€¼ï¼‰"""
        if not scores:
            return []
        
        # å¤„ç†æç«¯å¼‚å¸¸å€¼ï¼šå¯¹æ•°å˜æ¢
        log_scores = []
        for score in scores:
            if score > 0:
                # æ­£å€¼å–å¯¹æ•°
                log_scores.append(np.log(score + 1))  # +1é¿å…log(0)
            elif score < 0:
                # è´Ÿå€¼å–ç»å¯¹å€¼çš„å¯¹æ•°ï¼Œç„¶ååŠ è´Ÿå·
                log_scores.append(-np.log(abs(score) + 1))
            else:
                # é›¶å€¼ä¿æŒä¸å˜
                log_scores.append(0.0)
        
        # Min-Maxæ ‡å‡†åŒ–åˆ°[0,1]
        min_log_score = min(log_scores)
        max_log_score = max(log_scores)
        
        if max_log_score > min_log_score:
            normalized_scores = []
            for log_score in log_scores:
                normalized_score = (log_score - min_log_score) / (max_log_score - min_log_score)
                normalized_scores.append(normalized_score)
            return normalized_scores
        else:
            # æ‰€æœ‰scoreç›¸åŒçš„æƒ…å†µ
            return [0.5] * len(scores)

    def get_config_schema(self) -> Dict[str, Any]:
        """è·å–é…ç½®æ¨¡å¼ - ä»é…ç½®æ–‡ä»¶è¯»å–é»˜è®¤å€¼"""
        config = get_processor_config('mmr')
        return {
            # æ ¸å¿ƒMMRå‚æ•°ï¼ˆå®é™…ä½¿ç”¨ï¼‰
            'lambda_param': {
                'type': 'float',
                'min': 0.0,
                'max': 1.0,
                'default': config.get('lambda_param', 0.7),
                'description': 'MMR lambdaå‚æ•°ï¼Œæ§åˆ¶ç›¸å…³æ€§å’Œå¤šæ ·æ€§çš„å¹³è¡¡ (0=çº¯å¤šæ ·æ€§, 1=çº¯ç›¸å…³æ€§)'
            },
            'select_n': {
                'type': 'integer',
                'min': 1,
                'default': config.get('select_n', 10),
                'description': 'æœ€ç»ˆé€‰æ‹©çš„æ–‡æ¡£æ•°é‡'
            },
            'enable_mmr': {
                'type': 'boolean',
                'default': config.get('enable_mmr', True),
                'description': 'æ˜¯å¦å¯ç”¨MMRå¤„ç†'
            },
            'min_text_length': {
                'type': 'integer',
                'min': 1,
                'default': config.get('min_text_length', 10),
                'description': 'å¤„ç†çš„æœ€å°æ–‡æœ¬é•¿åº¦'
            },
            
            # ç›¸å…³æ€§è¿‡æ»¤å‚æ•°ï¼ˆå®é™…ä½¿ç”¨ï¼‰
            'relevance_threshold': {
                'type': 'float',
                'min': 0.0,
                'max': 1.0,
                'default': config.get('relevance_threshold', 0.3),
                'description': 'ç›¸å…³æ€§é˜ˆå€¼ï¼Œä½äºæ­¤å€¼çš„ç»“æœè¢«è¿‡æ»¤'
            },
            'enable_relevance_filter': {
                'type': 'boolean',
                'default': config.get('enable_relevance_filter', False),
                'description': 'æ˜¯å¦å¯ç”¨ç›¸å…³æ€§è¿‡æ»¤'
            },
            
            # Scoreæ ‡å‡†åŒ–å‚æ•°ï¼ˆå®é™…ä½¿ç”¨ï¼‰
            'enable_score_normalization': {
                'type': 'boolean',
                'default': config.get('enable_score_normalization', True),
                'description': 'æ˜¯å¦å¯ç”¨scoreæ ‡å‡†åŒ–ï¼Œè§£å†³ä¸åŒæœç´¢å¼•æ“çš„æ•°å€¼ç©ºé—´ä¸ä¸€è‡´é—®é¢˜'
            },
            
            # MMRç®—æ³•ä¼˜åŒ–å‚æ•°ï¼ˆå®é™…ä½¿ç”¨ï¼‰
            'max_candidates': {
                'type': 'integer',
                'min': 50,
                'max': 1000,
                'default': config.get('max_candidates', 200),
                'description': 'è¿›å…¥MMRçš„æœ€å¤§å€™é€‰æ–‡æ¡£æ•°é‡ï¼Œé¿å…å†…å­˜å¼€é”€è¿‡å¤§'
            },
            'dynamic_lambda': {
                'type': 'boolean',
                'default': config.get('dynamic_lambda', True),
                'description': 'æ˜¯å¦å¯ç”¨åŠ¨æ€Î»è°ƒæ•´ï¼Œæ ¹æ®queryé•¿åº¦è‡ªåŠ¨è°ƒæ•´MMRå‚æ•°'
            },
            'use_optimized_mmr': {
                'type': 'boolean',
                'default': config.get('use_optimized_mmr', True),
                'description': 'æ˜¯å¦ä½¿ç”¨ä¼˜åŒ–çš„MMRç®—æ³•ï¼ˆé¿å…é‡å¤è®¡ç®—ï¼‰'
            },
            
            # é›¶å‘é‡ä¿æŠ¤å‚æ•°ï¼ˆå®é™…ä½¿ç”¨ï¼‰
            'zero_vector_protection': {
                'type': 'boolean',
                'default': config.get('zero_vector_protection', True),
                'description': 'æ˜¯å¦å¯ç”¨é›¶å‘é‡ä¿æŠ¤'
            },
            'zero_vector_strategy': {
                'type': 'string',
                'options': ['return_zero', 'return_unit', 'skip', 'log_only'],
                'default': config.get('zero_vector_strategy', 'return_zero'),
                'description': 'é›¶å‘é‡å¤„ç†ç­–ç•¥'
            },
            'min_norm_threshold': {
                'type': 'float',
                'min': 1e-12,
                'max': 1e-6,
                'default': config.get('min_norm_threshold', 1e-8),
                'description': 'æœ€å°èŒƒæ•°é˜ˆå€¼ï¼Œä½äºæ­¤å€¼è§†ä¸ºé›¶å‘é‡'
            },
            
            # ç¼“å­˜ä¼˜åŒ–å‚æ•°ï¼ˆå®é™…ä½¿ç”¨ï¼‰
            'use_cache_optimization': {
                'type': 'boolean',
                'default': config.get('use_cache_optimization', True),
                'description': 'æ˜¯å¦ä½¿ç”¨ç¼“å­˜ä¼˜åŒ–çš„MMRç®—æ³•'
            },
            
            # è¾“å‡ºæ’åºå‚æ•°ï¼ˆå®é™…ä½¿ç”¨ï¼‰
            'output_order': {
                'type': 'string',
                'options': ['mmr_score', 'relevance', 'diversity'],
                'default': config.get('output_order', 'mmr_score'),
                'description': 'è¾“å‡ºæ’åºæ–¹å¼'
            },
            'reverse_order': {
                'type': 'boolean',
                'default': config.get('reverse_order', False),
                'description': 'æ˜¯å¦é€†åºæ’åˆ—ç»“æœ'
            },
            
            # æ ‡å‡†åŒ–æ–¹æ³•å‚æ•°ï¼ˆå®é™…ä½¿ç”¨ï¼‰
            'normalization_method': {
                'type': 'string',
                'options': ['log_minmax', 'minmax', 'zscore', 'auto'],
                'default': config.get('normalization_method', 'log_minmax'),
                'description': 'scoreæ ‡å‡†åŒ–æ–¹æ³•ï¼Œlog_minmaxé€‚ç”¨äºæç«¯å¼‚å¸¸å€¼'
            },
            
            # åŠ¨æ€Î»è°ƒæ•´å‚æ•°ï¼ˆå®é™…ä½¿ç”¨ï¼‰
            'base_lambda': {
                'type': 'float',
                'min': 0.0,
                'max': 1.0,
                'default': config.get('base_lambda', 0.5),
                'description': 'åŠ¨æ€Î»è°ƒæ•´çš„åŸºç¡€å€¼'
            },
            'short_query_threshold': {
                'type': 'integer',
                'min': 1,
                'max': 50,
                'default': config.get('short_query_threshold', 10),
                'description': 'çŸ­æŸ¥è¯¢é•¿åº¦é˜ˆå€¼'
            },
            'medium_query_threshold': {
                'type': 'integer',
                'min': 10,
                'max': 100,
                'default': config.get('medium_query_threshold', 30),
                'description': 'ä¸­ç­‰æŸ¥è¯¢é•¿åº¦é˜ˆå€¼'
            },
            'short_adjustment': {
                'type': 'float',
                'min': 0.0,
                'max': 1.0,
                'default': config.get('short_adjustment', 0.3),
                'description': 'çŸ­æŸ¥è¯¢æ—¶Î»çš„è°ƒæ•´å€¼'
            },
            'long_adjustment': {
                'type': 'float',
                'min': 0.0,
                'max': 1.0,
                'default': config.get('long_adjustment', 0.2),
                'description': 'é•¿æŸ¥è¯¢æ—¶Î»çš„è°ƒæ•´å€¼'
            },
            'max_lambda': {
                'type': 'float',
                'min': 0.0,
                'max': 1.0,
                'default': config.get('max_lambda', 0.9),
                'description': 'åŠ¨æ€Î»è°ƒæ•´çš„æœ€å¤§å€¼'
            },
            'min_lambda': {
                'type': 'float',
                'min': 0.0,
                'max': 1.0,
                'default': config.get('min_lambda', 0.3),
                'description': 'åŠ¨æ€Î»è°ƒæ•´çš„æœ€å°å€¼'
            },
            
            # é»˜è®¤åˆ†æ•°å‚æ•°ï¼ˆå®é™…ä½¿ç”¨ï¼‰
            'default_normalized_score': {
                'type': 'float',
                'min': 0.0,
                'max': 1.0,
                'default': config.get('default_normalized_score', 0.5),
                'description': 'æ ‡å‡†åŒ–æ—¶çš„é»˜è®¤åˆ†æ•°'
            },
            
            # å›é€€æœºåˆ¶å‚æ•°ï¼ˆå®é™…ä½¿ç”¨ï¼‰
            'fallback_strategy': {
                'type': 'string',
                'options': ['score_sort', 'random', 'original', 'multi_level'],
                'default': config.get('fallback_strategy', 'multi_level'),
                'description': 'å›é€€ç­–ç•¥ï¼šscore_sort=æŒ‰åˆ†æ•°æ’åºï¼Œrandom=éšæœºé€‰æ‹©ï¼Œoriginal=ä¿æŒåŸåºï¼Œmulti_level=å¤šçº§å›é€€'
            },
            'min_results_threshold': {
                'type': 'integer',
                'min': 1,
                'max': 50,
                'default': config.get('min_results_threshold', 3),
                'description': 'æœ€å°ç»“æœæ•°é‡é˜ˆå€¼ï¼Œä½äºæ­¤å€¼è§¦å‘å›é€€æœºåˆ¶'
            },
            'fallback_levels': {
                'type': 'integer',
                'min': 1,
                'max': 5,
                'default': config.get('fallback_levels', 3),
                'description': 'å¤šçº§å›é€€æœºåˆ¶çš„çº§åˆ«æ•°é‡'
            },
            'enable_fallback_monitoring': {
                'type': 'boolean',
                'default': config.get('enable_fallback_monitoring', True),
                'description': 'æ˜¯å¦å¯ç”¨å›é€€æœºåˆ¶ç›‘æ§å’Œç»Ÿè®¡'
            }
        }