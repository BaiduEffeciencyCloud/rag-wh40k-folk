import os
from pinecone import Pinecone
from openai import OpenAI
from typing import List, Dict, Any
import logging
from config import OPENAI_API_KEY, RERANK_MODEL, EMBADDING_MODEL, get_embedding_model, BM25_K1, BM25_B, BM25_MIN_FREQ, BM25_MAX_VOCAB_SIZE, BM25_CUSTOM_DICT_PATH, BM25_MODEL_PATH, BM25_VOCAB_PATH
import pinecone
from DATAUPLOD.bm25_manager import BM25Manager

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class VectorSearch:
    def __init__(self, pinecone_api_key: str, index_name: str, openai_api_key=OPENAI_API_KEY):
        """
        åˆå§‹åŒ–å‘é‡æœç´¢ç±»
        
        Args:
            pinecone_api_key: Pinecone APIå¯†é’¥
            index_name: Pineconeç´¢å¼•åç§°
            openai_api_key: OpenAI APIå¯†é’¥
        """
        self.client = OpenAI(api_key=openai_api_key)
        self.pc = Pinecone(api_key=pinecone_api_key)
        self.index = self.pc.Index(index_name)
        self.embedding_model = get_embedding_model()
        self.bm25 = BM25Manager(
            k1=BM25_K1,
            b=BM25_B,
            min_freq=BM25_MIN_FREQ,
            max_vocab_size=BM25_MAX_VOCAB_SIZE,
            custom_dict_path=BM25_CUSTOM_DICT_PATH
        )
        # å°è¯•åŠ è½½å·²è®­ç»ƒæ¨¡å‹
        try:
            self.bm25.load_model(BM25_MODEL_PATH, BM25_VOCAB_PATH)
        except Exception as e:
            logger.warning(f"BM25æ¨¡å‹åŠ è½½å¤±è´¥: {e}ï¼Œè¯·å…ˆè®­ç»ƒBM25æ¨¡å‹")
        logger.info("VectorSearchåˆå§‹åŒ–å®Œæˆ")
        
    def generate_query_variants(self, query: str) -> List[str]:
        """
        ç”ŸæˆæŸ¥è¯¢å˜ä½“
        
        Args:
            query: åŸå§‹æŸ¥è¯¢
            
        Returns:
            List[str]: æŸ¥è¯¢å˜ä½“åˆ—è¡¨
        """
        try:
            prompt = f"""è¯·åŸºäºä»¥ä¸‹é—®é¢˜ç”Ÿæˆ3ä¸ªç›¸å…³çš„æŸ¥è¯¢å˜ä½“ï¼Œæ¯ä¸ªå˜ä½“éƒ½åº”è¯¥èƒ½å¤Ÿè·å–éƒ¨åˆ†ç­”æ¡ˆï¼š

åŸå§‹é—®é¢˜ï¼š{query}

è¦æ±‚ï¼š
1. å˜ä½“åº”è¯¥åŒ…å«åŸå§‹é—®é¢˜çš„å…³é”®ä¿¡æ¯
2. å˜ä½“ä¹‹é—´åº”è¯¥æœ‰é€»è¾‘å…³è”
3. å˜ä½“åº”è¯¥ä»ä¸åŒè§’åº¦æ¢ç´¢åŸå§‹é—®é¢˜
4. å˜ä½“åº”è¯¥å…·ä½“ä¸”æ˜ç¡®

è¯·ç”Ÿæˆ3ä¸ªæŸ¥è¯¢å˜ä½“ï¼š"""
            
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.7,
                max_tokens=1000
            )
            
            variants = [line.strip() for line in response.choices[0].message.content.split('\n') if line.strip()]
            logger.info(f"ç”Ÿæˆçš„æŸ¥è¯¢å˜ä½“ï¼š{variants}")
            return variants
            
        except Exception as e:
            logger.error(f"ç”ŸæˆæŸ¥è¯¢å˜ä½“æ—¶å‡ºé”™ï¼š{str(e)}")
            return []
            
    def semantic_parse(self, query: str, context: List[str]) -> str:
        """
        ä½¿ç”¨OpenAIè¿›è¡Œè¯­ä¹‰è§£æ
        
        Args:
            query: ç”¨æˆ·é—®é¢˜
            context: ä¸Šä¸‹æ–‡ä¿¡æ¯
            
        Returns:
            str: è§£æåçš„å›ç­”
        """
        try:
            prompt = f"""# è§’è‰²ï¼šæˆ˜é”¤40Kè§„åˆ™ä¸“å®¶
ä½ æ˜¯ä¸€åä¸“ä¸šçš„æˆ˜é”¤40Kæ¯”èµ›è§„åˆ™ä¸“å®¶ï¼Œå…·å¤‡ç²¾å‡†çš„ä¿¡æ¯æå–ä¸åˆ†æèƒ½åŠ›ã€‚ä½ çš„ä»»åŠ¡æ˜¯åŸºäºæä¾›çš„ä¸Šä¸‹æ–‡èµ„æ–™ï¼Œä¸ºç”¨æˆ·æä¾›å‡†ç¡®ã€å…¨é¢ä¸”æœ‰æ¡ç†çš„å›ç­”ã€‚

## æ ¸å¿ƒè¦æ±‚
1. **ä¸¥æ ¼åŸºäºä¸Šä¸‹æ–‡**ï¼šåªèƒ½ä½¿ç”¨æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯å›ç­”ï¼Œç»å¯¹ä¸å…è®¸æ·»åŠ ä»»ä½•æ¨æµ‹ã€è™šæ„æˆ–ä¸åœ¨ä¸Šä¸‹æ–‡ä¸­çš„å†…å®¹
2. **å®Œæ•´æ€§ä¼˜å…ˆ**ï¼šå¿…é¡»æ•´åˆæ‰€æœ‰ç›¸å…³çš„è§„åˆ™ä¿¡æ¯ï¼ŒåŒ…æ‹¬ä¸»è¦è§„åˆ™ã€ä¾‹å¤–æƒ…å†µã€é™åˆ¶æ¡ä»¶å’Œç‰¹æ®Šè¯´æ˜
3. **ç»“æ„åŒ–å›ç­”**ï¼šæŒ‰ç…§é€»è¾‘é¡ºåºç»„ç»‡ä¿¡æ¯ï¼Œå…ˆè¯´æ˜æ ¸å¿ƒè§„åˆ™ï¼Œå†è¡¥å……ä¾‹å¤–å’Œç»†èŠ‚
4. **ä¸“ä¸šæœ¯è¯­**ï¼šä½¿ç”¨æˆ˜é”¤40Kçš„æ ‡å‡†æœ¯è¯­å’Œè¡¨è¾¾æ–¹å¼

## ä¸¥æ ¼é™åˆ¶
- **ç¦æ­¢æ¨æµ‹**ï¼šå¦‚æœä¸Šä¸‹æ–‡ä¸­æ²¡æœ‰æ˜ç¡®æåˆ°æŸä¸ªæ­¦å™¨ã€å•ä½æˆ–è§„åˆ™ï¼Œç»å¯¹ä¸èƒ½åœ¨ç­”æ¡ˆä¸­æåŠ
- **ç¦æ­¢æ³›åŒ–**ï¼šä¸è¦ä½¿ç”¨"é€šå¸¸"ã€"ä¸€èˆ¬"ã€"å¯èƒ½"ç­‰æ¨¡ç³Šè¡¨è¿°ï¼Œåªé™ˆè¿°ä¸Šä¸‹æ–‡ä¸­æ˜ç¡®å­˜åœ¨çš„ä¿¡æ¯
- **ç¦æ­¢æ·»åŠ **ï¼šä¸è¦æ·»åŠ ä»»ä½•ä¸åœ¨ä¸Šä¸‹æ–‡ä¸­çš„å…·ä½“æ­¦å™¨åç§°ã€å•ä½åç§°æˆ–è§„åˆ™ç»†èŠ‚
- **æ˜ç¡®æ ‡æ³¨**ï¼šå¦‚æœä¸Šä¸‹æ–‡ä¿¡æ¯ä¸è¶³ä»¥å›ç­”å®Œæ•´é—®é¢˜ï¼Œæ˜ç¡®è¯´æ˜"æ ¹æ®æä¾›çš„èµ„æ–™ï¼Œæ— æ³•ç¡®å®š..."

## å›ç­”ç»“æ„
è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„ç»„ç»‡å›ç­”ï¼š

### æ ¸å¿ƒè§„åˆ™
- ç›´æ¥å›ç­”ç”¨æˆ·é—®é¢˜çš„æ ¸å¿ƒå†…å®¹
- è¯´æ˜åŸºæœ¬æœºåˆ¶å’Œæ•ˆæœ
- **åªåŸºäºä¸Šä¸‹æ–‡ä¸­çš„æ˜ç¡®ä¿¡æ¯**

### è¯¦ç»†è¯´æ˜
- è¡¥å……ç›¸å…³çš„è§„åˆ™ç»†èŠ‚
- è¯´æ˜ä½¿ç”¨æ¡ä»¶å’Œé™åˆ¶
- **ä¸¥æ ¼é™åˆ¶åœ¨ä¸Šä¸‹æ–‡èŒƒå›´å†…**

### ä¾‹å¤–æƒ…å†µ
- **å¿…é¡»ä»”ç»†æ£€æŸ¥æ‰€æœ‰ä¸Šä¸‹æ–‡ï¼Œå¯»æ‰¾ä»»ä½•ä¾‹å¤–è§„åˆ™**
- ç‰¹åˆ«å…³æ³¨åŒ…å«ä»¥ä¸‹å…³é”®è¯çš„å†…å®¹ï¼š
  * "ä½†æ˜¯"ã€"ç„¶è€Œ"ã€"ä¸è¿‡"
  * "ä¾‹å¤–"ã€"ç‰¹æ®Š"ã€"å…è®¸"
  * "å¦‚æœ...é‚£ä¹ˆ"ã€"å°½ç®¡...ä»ç„¶"
  * "çªå‡»æ­¦å™¨"ã€"ç‰¹æ®Šèƒ½åŠ›"ã€"æŠ€èƒ½"
- åˆ—å‡ºæ‰€æœ‰ç›¸å…³çš„ä¾‹å¤–è§„åˆ™å’Œç‰¹æ®Šæƒ…å†µ
- è¯´æ˜ä¾‹å¤–è§„åˆ™çš„å…·ä½“æ¡ä»¶å’Œæ•ˆæœ
- **åªåŒ…å«ä¸Šä¸‹æ–‡ä¸­æ˜ç¡®æåˆ°çš„ä¾‹å¤–**

### æ³¨æ„äº‹é¡¹
- é‡è¦çš„æé†’å’Œè­¦å‘Š
- å®¹æ˜“å¿½ç•¥çš„å…³é”®ç‚¹
- **åŸºäºä¸Šä¸‹æ–‡ä¸­çš„å…·ä½“ä¿¡æ¯**

## ä¿¡æ¯æ•´åˆåŸåˆ™
1. **ä¸¥æ ¼ä¸Šä¸‹æ–‡é™åˆ¶**ï¼šåªä½¿ç”¨æä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œä¸æ·»åŠ ä»»ä½•å¤–éƒ¨çŸ¥è¯†
2. **å…¨é¢æ‰«æä¾‹å¤–**ï¼šä»”ç»†æ£€æŸ¥æ¯ä¸ªä¸Šä¸‹æ–‡ç‰‡æ®µï¼Œå¯»æ‰¾ä»»ä½•å½¢å¼çš„ä¾‹å¤–æƒ…å†µ
3. **å…³é”®è¯è¯†åˆ«**ï¼šç‰¹åˆ«å…³æ³¨åŒ…å«"çªå‡»"ã€"ç‰¹æ®Š"ã€"ä¾‹å¤–"ã€"å…è®¸"ç­‰å…³é”®è¯çš„å†…å®¹
4. **é€»è¾‘å®Œæ•´æ€§**ï¼šç¡®ä¿ç­”æ¡ˆåŒ…å«å®Œæ•´çš„è§„åˆ™é€»è¾‘ï¼ŒåŒ…æ‹¬æ‰€æœ‰ä¾‹å¤–æƒ…å†µ
5. **é¿å…é—æ¼**ï¼šå¦‚æœä¸Šä¸‹æ–‡ä¸­æåˆ°ä»»ä½•ä¾‹å¤–æˆ–ç‰¹æ®Šæƒ…å†µï¼Œå¿…é¡»åŒ…å«åœ¨ç­”æ¡ˆä¸­
6. **ä¿æŒé€»è¾‘æ€§**ï¼šæŒ‰ç…§è§„åˆ™é€»è¾‘é¡ºåºç»„ç»‡ä¿¡æ¯ï¼Œé¿å…è·³è·ƒæ€§è¡¨è¿°
7. **çªå‡ºå…³é”®ä¿¡æ¯**ï¼šç”¨æ¸…æ™°çš„è¯­è¨€å¼ºè°ƒé‡è¦çš„è§„åˆ™è¦ç‚¹

## è¾“å‡ºæ ¼å¼
ç›´æ¥è¾“å‡ºç»“æ„åŒ–çš„ç­”æ¡ˆï¼Œæ— éœ€æ·»åŠ "é—®é¢˜ï¼š"ã€"å›ç­”ï¼š"ç­‰æ ‡ç­¾ã€‚ç¡®ä¿ç­”æ¡ˆå®Œæ•´ã€å‡†ç¡®ã€æ˜“äºç†è§£ï¼Œä¸”ä¸¥æ ¼åŸºäºæä¾›çš„ä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚

ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼š
{chr(10).join([f"ã€{i+1}ã€‘{text}" for i, text in enumerate(context)])}

ç”¨æˆ·é—®é¢˜ï¼š{query}"""
            
            response = self.client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role": "user", "content": prompt}],
                temperature=0.4,  # è¿›ä¸€æ­¥é™ä½æ¸©åº¦ä»¥è·å¾—æ›´ç¨³å®šçš„è¾“å‡º
                max_tokens=3000
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            logger.error(f"è¯­ä¹‰è§£ææ—¶å‡ºé”™ï¼š{str(e)}")
            return "æŠ±æ­‰ï¼Œè§£æé—®é¢˜æ—¶å‡ºé”™ã€‚"
            
    def get_embedding(self, text):
        # ç»Ÿä¸€é€šè¿‡config.get_embedding_model()è·å–embedding
        embedding = self.embedding_model.embed_query(text)
        return embedding

    def get_sparse_embedding(self, text: str) -> Dict[str, Any]:
        """
        é€šè¿‡BM25Managerç”Ÿæˆç¨€ç–å‘é‡
        """
        return self.bm25.get_sparse_vector(text)

    def hybrid_scale(self, dense: List[float], sparse: Dict[str, Any], alpha: float):
        """
        æŒ‰alphaåŠ æƒdenseå’Œsparse embedding
        """
        hdense = [v * alpha for v in dense]
        hsparse = {"indices": sparse["indices"], "values": [v * (1 - alpha) for v in sparse["values"]]}
        return hdense, hsparse

    def search(self, query: str, top_k: int = 10, alpha: float = 0.3) -> List[Dict[str, Any]]:
        """
        æ‰§è¡Œhybridå‘é‡æœç´¢ï¼Œè¿”å›åŸå§‹æ£€ç´¢ç»“æœ
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡
            alpha: dense/sparseåŠ æƒå‚æ•°
        Returns:
            List[Dict[str, Any]]: åŸå§‹æœç´¢ç»“æœåˆ—è¡¨ï¼ŒåŒ…å«metadataå’Œscore
        """
        try:
            # è·å–dense embedding
            query_embedding = self.get_embedding(query)
            # è·å–sparse embedding
            query_sparse = self.get_sparse_embedding(query)
            # æŒ‰alphaåŠ æƒ
            hdense, hsparse = self.hybrid_scale(query_embedding, query_sparse, alpha)
            
            # Pineconeå®˜æ–¹hybrid searchæ¥å£
            results = self.index.query(
                vector=hdense,
                sparse_vector=hsparse,
                top_k=top_k,
                include_metadata=True
            )
            
            # è¿”å›åŸå§‹æ£€ç´¢ç»“æœ
            search_results = []
            for match in results.matches:
                text = match.metadata.get('text', '')
                # è¿‡æ»¤ç©ºå†…å®¹æˆ–è¿‡çŸ­çš„å†…å®¹
                if not text or len(text.strip()) < 10:
                    continue
                search_results.append({
                    'text': text,
                    'score': match.score,
                    'metadata': match.metadata
                })
            return search_results
        except Exception as e:
            logger.error(f"æœç´¢æ—¶å‡ºé”™ï¼š{str(e)}")
            return []

    def search_with_adjacent_chunks(self, query: str, top_k: int = 10, adjacent_range: int = 2) -> List[Dict[str, Any]]:
        """
        æ‰§è¡Œå‘é‡æœç´¢ï¼Œå¹¶å¬å›ç›¸é‚»åˆ‡ç‰‡
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡
            adjacent_range: ç›¸é‚»åˆ‡ç‰‡èŒƒå›´ï¼ˆå‰åå„å‡ ä¸ªåˆ‡ç‰‡ï¼‰
            
        Returns:
            List[Dict[str, Any]]: åŒ…å«ç›¸é‚»åˆ‡ç‰‡çš„æœç´¢ç»“æœåˆ—è¡¨
        """
        try:
            # é¦–å…ˆæ‰§è¡Œå¸¸è§„æœç´¢
            initial_results = self.search(query, top_k)
            
            if not initial_results:
                return []
            
            # æ”¶é›†æ‰€æœ‰éœ€è¦è·å–çš„åˆ‡ç‰‡ID
            chunk_ids_to_fetch = set()
            
            for result in initial_results:
                metadata = result.get('metadata', {})
                chunk_id = metadata.get('chunk_id')
                if chunk_id:
                    # æ·»åŠ å½“å‰åˆ‡ç‰‡ID
                    chunk_ids_to_fetch.add(chunk_id)
                    
                    # æ·»åŠ ç›¸é‚»åˆ‡ç‰‡ID
                    try:
                        chunk_num = int(chunk_id)
                        for i in range(1, adjacent_range + 1):
                            chunk_ids_to_fetch.add(str(chunk_num - i))  # å‰å‡ ä¸ªåˆ‡ç‰‡
                            chunk_ids_to_fetch.add(str(chunk_num + i))  # åå‡ ä¸ªåˆ‡ç‰‡
                    except ValueError:
                        # å¦‚æœchunk_idä¸æ˜¯æ•°å­—ï¼Œè·³è¿‡ç›¸é‚»åˆ‡ç‰‡é€»è¾‘
                        pass
            
            # è·å–æ‰€æœ‰ç›¸å…³åˆ‡ç‰‡çš„å†…å®¹
            all_results = initial_results.copy()
            
            # é€šè¿‡IDè·å–ç›¸é‚»åˆ‡ç‰‡
            for chunk_id in chunk_ids_to_fetch:
                # æ£€æŸ¥æ˜¯å¦å·²ç»åœ¨åˆå§‹ç»“æœä¸­
                if any(r.get('metadata', {}).get('chunk_id') == chunk_id for r in initial_results):
                    continue
                
                # é€šè¿‡IDæŸ¥è¯¢åˆ‡ç‰‡
                try:
                    fetch_results = self.index.query(
                        id=chunk_id,
                        include_metadata=True,
                        top_k=1
                    )
                    
                    if fetch_results.matches:
                        match = fetch_results.matches[0]
                        text = match.metadata.get('text', '')
                        if text and len(text.strip()) >= 10:
                            all_results.append({
                                'text': text,
                                'score': match.score,
                                'metadata': match.metadata,
                                'source': 'adjacent_chunk'  # æ ‡è®°ä¸ºç›¸é‚»åˆ‡ç‰‡
                            })
                except Exception as e:
                    logger.warning(f"è·å–ç›¸é‚»åˆ‡ç‰‡ {chunk_id} æ—¶å‡ºé”™: {e}")
                    continue
            
            # æŒ‰åˆ†æ•°æ’åºå¹¶å»é‡
            seen_texts = set()
            final_results = []
            
            for result in sorted(all_results, key=lambda x: x.get('score', 0), reverse=True):
                text = result.get('text', '').strip()
                if text and text not in seen_texts:
                    seen_texts.add(text)
                    final_results.append(result)
            
            logger.info(f"åŸå§‹æ£€ç´¢: {len(initial_results)} ä¸ªç»“æœï¼Œæ·»åŠ ç›¸é‚»åˆ‡ç‰‡å: {len(final_results)} ä¸ªç»“æœ")
            
            return final_results
            
        except Exception as e:
            logger.error(f"æœç´¢ç›¸é‚»åˆ‡ç‰‡æ—¶å‡ºé”™ï¼š{str(e)}")
            return self.search(query, top_k)  # å›é€€åˆ°æ™®é€šæœç´¢
    
    def search_and_generate_answer(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """
        æ‰§è¡Œå‘é‡æœç´¢å¹¶ç”Ÿæˆç­”æ¡ˆ
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            List[Dict[str, Any]]: åŒ…å«ç”Ÿæˆç­”æ¡ˆçš„ç»“æœåˆ—è¡¨
        """
        try:
            # æ‰§è¡Œçº¯æ£€ç´¢
            search_results = self.search(query, top_k)
            
            if not search_results:
                return []
            
            # æå–æ£€ç´¢åˆ°çš„æ–‡æœ¬å†…å®¹
            retrieved_texts = [result['text'] for result in search_results]
            
            # ä½¿ç”¨semantic_parseç”Ÿæˆç­”æ¡ˆ
            integrated_answer = self.semantic_parse(query, retrieved_texts)
            
            # è¿”å›æ•´åˆåçš„ç­”æ¡ˆ
            return [{
                'text': integrated_answer, 
                'score': 1.0,
                'retrieved_results': search_results
            }]
            
        except Exception as e:
            logger.error(f"æœç´¢å¹¶ç”Ÿæˆç­”æ¡ˆæ—¶å‡ºé”™ï¼š{str(e)}")
            return []
    
    def search_and_integrate(self, query: str, top_k: int = 5) -> str:
        """
        æœç´¢å¹¶æ•´åˆç»“æœï¼ˆå‘åå…¼å®¹æ–¹æ³•ï¼‰
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            str: æ•´åˆåçš„ç­”æ¡ˆ
        """
        results = self.search_and_generate_answer(query, top_k)
        if not results:
            return "æŠ±æ­‰ï¼Œæ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚"
        return results[0]['text']

    def close(self):
        # å…³é—­èµ„æº
        pass  # è¿™é‡Œå¯ä»¥æ›¿æ¢ä¸ºå®é™…çš„å…³é—­é€»è¾‘

    def search_with_filter(self, query: str, entity: str, top_k: int = 10) -> List[Dict[str, Any]]:
        """
        å®ä½“->filter+å‘é‡->å¬å›åˆ‡ç‰‡demo
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            entity: è¯†åˆ«åˆ°çš„å®ä½“ï¼ˆå¦‚å•ä½ã€æŠ€èƒ½ç­‰ï¼‰
            top_k: è¿”å›ç»“æœæ•°é‡
        Returns:
            List[Dict[str, Any]]: æ£€ç´¢ç»“æœåˆ—è¡¨ï¼ŒåŒ…å«metadataå’Œscore
        """
        try:
            query_embedding = self.get_embedding(query)
            # Pinecone filter: hierarchyåŒ…å«entity
            filter_dict = {"hierarchy": {"$contains": entity}}
            results = self.index.query(
                vector=query_embedding,
                top_k=top_k,
                include_metadata=True,
                filter=filter_dict,
                hybrid_search=True,
                alpha=0.3,
                rerank_config={
                    "model": RERANK_MODEL,
                    "top_k": top_k
                }
            )
            search_results = []
            for match in results.matches:
                text = match.metadata.get('text', '')
                if not text or len(text.strip()) < 10:
                    continue
                search_results.append({
                    'text': text,
                    'score': match.score,
                    'metadata': match.metadata
                })
            return search_results
        except Exception as e:
            logger.error(f"search_with_filterå‡ºé”™: {str(e)}")
            return []

# ç¡®ä¿ç±»å¯ä»¥è¢«å¯¼å…¥
__all__ = ['VectorSearch']

def main():
    """
    ä¸»å‡½æ•°ï¼šå¤„ç†å‘½ä»¤è¡Œå‚æ•°å¹¶æ‰§è¡Œå‘é‡æœç´¢
    """
    import argparse
    import sys
    from config import PINECONE_API_KEY, PINECONE_INDEX
    
    # åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨
    parser = argparse.ArgumentParser(
        description='æˆ˜é”¤40Kå‘é‡æœç´¢ç³»ç»Ÿ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  python3 vector_search.py "å¹½å†¥éª‘å£«çš„é˜”æ­¥å·¨å…½æŠ€èƒ½å¦‚ä½•ä½¿ç”¨ï¼Ÿ"
  python3 vector_search.py --top_k 10 "åœ°å½¢æ¨¡å‹å¯¹ç§»åŠ¨æœ‰ä»€ä¹ˆå½±å“ï¼Ÿ"
  python3 vector_search.py --query "å†²é”‹æŠ€èƒ½ä¼šé€ æˆå¤šå°‘ä¼¤å®³ï¼Ÿ"
        """
    )
    
    parser.add_argument(
        'query',
        type=str,
        nargs='?',
        help='è¦æœç´¢çš„æŸ¥è¯¢æ–‡æœ¬'
    )
    
    parser.add_argument(
        '--query',
        type=str,
        dest='query_arg',
        help='è¦æœç´¢çš„æŸ¥è¯¢æ–‡æœ¬ï¼ˆå¯é€‰å‚æ•°å½¢å¼ï¼‰'
    )
    
    parser.add_argument(
        '--top_k',
        type=int,
        default=5,
        help='è¿”å›ç»“æœæ•°é‡ï¼ˆé»˜è®¤ï¼š5ï¼‰'
    )
    
    parser.add_argument(
        '--verbose',
        action='store_true',
        help='æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯'
    )
    
    # è§£æå‘½ä»¤è¡Œå‚æ•°
    args = parser.parse_args()
    
    # ç¡®å®šæŸ¥è¯¢æ–‡æœ¬
    query = args.query or args.query_arg
    
    if not query:
        print("âŒ é”™è¯¯ï¼šè¯·æä¾›æŸ¥è¯¢æ–‡æœ¬")
        print("ä½¿ç”¨æ–¹æ³•ï¼š")
        print("  python3 vector_search.py 'ä½ çš„æŸ¥è¯¢'")
        print("  python3 vector_search.py --query 'ä½ çš„æŸ¥è¯¢'")
        sys.exit(1)
    
    try:
        # åˆ›å»ºå‘é‡æœç´¢å®ä¾‹
        vector_search = VectorSearch(
            pinecone_api_key=PINECONE_API_KEY,
            index_name=PINECONE_INDEX
        )
        
        print("=" * 60)
        print("ğŸ” æˆ˜é”¤40Kå‘é‡æœç´¢ç³»ç»Ÿ")
        print("=" * 60)
        print(f"ğŸ“ æŸ¥è¯¢æ–‡æœ¬: {query}")
        print(f"ğŸ“Š é¢„æœŸè¿”å›ç»“æœæ•°: {args.top_k}")
        print("-" * 60)
        
        # æ‰§è¡Œæœç´¢ï¼ˆåªè§‚å¯Ÿå¬å›æ•ˆæœï¼‰
        results = vector_search.search(query, args.top_k)
        
        if not results:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ç»“æœ")
            sys.exit(1)
        
        # æ˜¾ç¤ºç»“æœ
        print(f"âœ… æ‰¾åˆ° {len(results)} ä¸ªå¬å›ç»“æœ:")
        print("=" * 60)
        
        for i, result in enumerate(results, 1):
            print(f"ğŸ“‹ å¬å›ç»“æœ {i}:")
            print(f"ğŸ“Š ç›¸ä¼¼åº¦åˆ†æ•°: {result.get('score', 'N/A'):.4f}")
            print(f"ğŸ“„ å†…å®¹:")
            print(result.get('text', 'æ— å†…å®¹'))
            print("\n" + "="*40 + "\n")
        
        print("=" * 60)
        print("âœ… æœç´¢å®Œæˆï¼")
        
        # æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if args.verbose:
            print("\nğŸ” è¯¦ç»†ä¿¡æ¯:")
            print(f"   æŸ¥è¯¢å˜ä½“: {vector_search.generate_query_variants(query)}")
            print(f"   æœç´¢ç»“æœæ•°é‡: {len(results)}")
        
    except KeyboardInterrupt:
        print("\nâŒ ç”¨æˆ·ä¸­æ–­æ“ä½œ")
        sys.exit(1)
    except Exception as e:
        print(f"âŒ æœç´¢å¤±è´¥: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)
    finally:
        # æ¸…ç†èµ„æº
        try:
            vector_search.close()
        except:
            pass

if __name__ == "__main__":
    main() 