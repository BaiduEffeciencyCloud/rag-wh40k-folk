# ===================== 数据路径配置 =====================
intent_data_path: intent_training/data/raw/intent_sample.csv   # 意图识别数据CSV路径
slot_data_path: intent_training/data/raw/slot_sample.conll     # 槽位填充数据CoNLL路径

# ===================== 数据切分参数 =====================
test_size: 0.2        # 测试集占比，0~1之间小数
val_size: 0.1         # 验证集占比，0~1之间小数
random_state: 42      # 随机种子，保证实验可复现
stratify: true        # 是否分层抽样，true/false
min_query_length: 3   # 查询最小长度，过滤过短无效数据
max_query_length: 200 # 查询最大长度，过滤过长异常数据
min_sentence_length: 2   # 槽位句子最小长度
max_sentence_length: 100 # 槽位句子最大长度

# ===================== 特征工程参数 =====================
feature_type: pa  # 特征提取器类型：basic=基础特征，advanced=高级特征，pa=Position-Aware特征
use_enhanced_features: true  # 是否使用增强特征（句向量融合）
intent_feature:
  max_features: 1000  # TF-IDF最大特征数
  ngram_range: [1, 2] # ngram范围，(1,2)表示1-2gram
  min_df: 1           # 最小文档频率，过滤低频特征
  analyzer: char      # 分析粒度，char=字符级，word=词级
  intent_tfidf: intent_tfidf.pkl  # TF-IDF特征提取器文件名

slot_feature:
  max_features: 1000  # 槽位特征最大数
  ngram_range: [1, 2] # 槽位特征ngram范围

# ===================== 高级特征提取器配置 =====================
advanced_feature:
  # 增强特征配置
  enhanced:
    use_sentence_embedding: true  # 是否使用句向量
    sentence_model: "shibing624/text2vec-base-chinese"  # 句向量模型
    fusion_method: "weighted"  # 特征融合方法：concatenate=拼接，weighted=加权
    pa_weight: 0.7  # Position Aware特征权重
    sentence_weight: 0.3  # 句向量特征权重
    # 网络配置
    network_timeout: 30  # 网络超时时间（秒）
    allow_offline: true  # 是否允许离线模式
    fallback_to_zero: true  # 网络失败时是否回退到零向量
  
  # 路径配置
  vocab_dir: "dict/wh40k_vocabulary"  # WH40K词汇表目录
  basic_keywords: ["战锤", "40k", "wh40k"]  # 基本关键词列表
  
  # TF-IDF特征配置
  tfidf:
    max_features: 1500  # 最大特征数（增加）
    ngram_range: [1, 3] # ngram范围（增加三元组）
    min_df: 1           # 最小文档频率
    analyzer: char       # 分析粒度
  
  # 复杂度计算配置
  complexity:
    max_sentence_length: 20.0  # 最大句子长度阈值
    long_word_threshold: 4     # 长词长度阈值
    very_long_word_threshold: 6  # 超长词长度阈值
    punctuation_threshold: 10.0  # 标点符号复杂度阈值
    weight_length: 0.25        # 长度复杂度权重
    weight_unique: 0.25        # 词汇多样性权重
    weight_long_word: 0.25     # 长词复杂度权重
    weight_punctuation: 0.25   # 标点符号复杂度权重
  
  # 语义复杂度特征配置开关, 如果不打开那么系统只使用feature_weights 中的前三个(char,sementic,statistical_features)
  complexity_feature:
    enabled: true              # 是否启用复杂度特征
  
  # 统计特征配置
  statistical:
    long_word_threshold: 4     # 长词长度阈值
    very_long_word_threshold: 6  # 超长词长度阈值
  
  # 标点符号配置
  punctuation:
    question_exclamation: "？？!！"  # 问号感叹号
    brackets: "（）【】"         # 括号
    others: "：；，。"          # 其他标点
    all_punctuation: "，。！？；：（）【】"  # 所有标点符号
  
  # 特征融合权重配置
  feature_weights:
    char_features: 1.0      # TF-IDF特征权重
    semantic_features: 3.0  # 语义特征权重（提高，充分利用句向量）
    statistical_features: 1.5  # 统计特征权重（适度提高）
    complexity_features: 5.0  # 复杂度特征权重（从1.0增加到5.0）
  
  # 意图关键词配置
  intent_keywords:
    compare:
      - "哪个"
      - "相比"
      - "比较"
      - "更"
      - "最高"
      - "最低"
      - "最远"
      - "最近"
      - "最长"
      - "最短"
      - "哪个更高"
      - "哪个更低"
      - "哪个更好"
      - "哪个更差"
      - "哪个更小"
      - "哪个更大"
    list:
      - "有哪些"
      - "多少个"
      - "列举"
      - "哪些"
      - "多少种"
      - "什么类型"
      - "什么种类"
      - "什么单位"
      - "什么武器"
      - "什么技能"
    query:
      - "什么是"
      - "如何"
      - "解释"
      - "说明"
      - "定义"
      - "是什么"
      - "什么意思"
      - "怎么用"
      - "怎么触发"
      - "怎么计算"
      - "是啥"
      - "告诉我"
      - "我想知道"
      - "帮我查一下"
      - "请解释"
      - "能否说明"
    rule:
      - "什么情况下"
      - "如何触发"
      - "规则"
      - "何时"
      - "条件"
      - "当...时"
      - "在...时"
      - "在...后"
      - "什么时候"
      - "什么条件"
      - "什么要求"
      - "什么限制"
      - "如果...那么"
      - "当...的时候"
      - "在...的情况下"
      - "需要满足"
      - "必须满足"

# ===================== 模型文件名配置 =====================
model:
  intent_classifier: intent_classifier.pkl  # 意图分类器模型文件名
  sequence_slot_filler: sequence_slot_filler.pkl  # 序列槽位填充器模型文件名

# ===================== 分类器参数 =====================
classifier:
  type: logistic   # 分类器类型：logistic(逻辑回归)/svm(支持向量机)/random_forest(随机森林)/ensemble(集成学习)
  random_state: 42  # 随机种子
  
  # Logistic Regression参数
  logistic:
    max_iter: 1000
    C: 1.0
    penalty: l2
    solver: lbfgs
    
  # SVM参数
  svm:
    C: 1.0
    kernel: rbf
    gamma: scale
    probability: true
    max_iter: 1000
    
  # Random Forest参数
  random_forest:
    n_estimators: 100
    max_depth: 10
    min_samples_split: 2
    min_samples_leaf: 1
    
  # 集成学习参数
  ensemble:
    base_classifiers: [logistic, svm, random_forest]
    voting_method: soft  # soft/hard
    weights: [0.4, 0.3, 0.3]  # 各分类器权重
    
  # 类别权重（用于处理不平衡数据）
  class_weights:
    Query: 2.5    # 提升Query权重（当前准确率低）
    List: 1.0     # 保持List权重（当前准确率高）
    Compare: 1.5  # 适度提升Compare权重
    Rule: 1.2     # 适度提升Rule权重

slot_buffer_max_size: 1000  # 槽位缓存最大长度
slot_classifier_type: logistic # 槽位分类器类型
slot_classifier_max_iter: 200  # 槽位分类器最大迭代次数

# ===================== 模型导出与评估 =====================
model_output_dir: intent_training/model_output/   # 统一的模型产出目录，训练、评估、导出、上线全流程共用
report_path: intent_training/report/        # 评估报告保存路径

# ===================== 不确定性与解释性参数 =====================
uncertainty:
  review_threshold: 0.5     # 人工审核阈值，超过则需人工复核
  auto_confidence_threshold: 0.85  # 自动信任阈值，高于此值自动通过
  methods: [entropy, confidence, margin]  # 不确定性计算方法
  combined_weight:          # 各方法权重，和为1
    entropy: 0.4            # 熵方法权重
    confidence: 0.4         # 置信度方法权重
    margin: 0.2             # 边距方法权重
  buffer_max_size: 1000     # 不确定性查询缓存最大长度 

# 评估相关配置
evaluation:
  run_evaluation: true  # 是否在训练后执行评估流程的总开关
  export_threshold: 0.85  # 模型评估的质量门槛，frame_accuracy 必须高于此值模型才会被导出
  summary_report_path: "document/evaluation_summary.md"  # 摘要报告的输出路径
  detailed_report_path: "document/evaluation_detailed.json"  # 详细报告的输出路径 