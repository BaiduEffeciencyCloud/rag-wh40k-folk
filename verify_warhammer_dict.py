#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
éªŒè¯è„šæœ¬ï¼šæ£€æŸ¥warhammer_dict.txtçš„å®Œæ•´æ€§
1. æ£€æŸ¥æ˜¯å¦ä¸all_docs_dict_2508242302.txt.meta.jsonä¸­çš„è¯æ±‡ä¸€ä¸€å¯¹åº”
2. æ£€æŸ¥æ˜¯å¦åŒ…å«äº†wh40k_vocabularyä¸‹4ä¸ªjsonæ–‡ä»¶é‡Œçš„æ‰€æœ‰ä¸“ä¸šè¯æ±‡
"""

import json
import os
from pathlib import Path
from typing import Set, Dict, List, Tuple


def load_warhammer_dict(file_path: str) -> Set[str]:
    """åŠ è½½warhammer_dict.txtä¸­çš„è¯æ±‡"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            # æ¯è¡Œä¸€ä¸ªè¯æ±‡ï¼Œå»é™¤ç©ºç™½å­—ç¬¦
            words = {line.strip() for line in f if line.strip()}
        print(f"âœ… æˆåŠŸåŠ è½½warhammer_dict.txt: {len(words)}ä¸ªè¯æ±‡")
        return words
    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")
        return set()
    except Exception as e:
        print(f"âŒ åŠ è½½warhammer_dict.txtå¤±è´¥: {e}")
        return set()


def load_all_docs_dict_meta(file_path: str) -> Set[str]:
    """åŠ è½½all_docs_dict_2508242302.txt.meta.jsonä¸­çš„è¯æ±‡"""
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        # æå–æ‰€æœ‰è¯æ±‡ï¼ˆJSONçš„é”®ï¼‰
        words = set(data.keys())
        print(f"âœ… æˆåŠŸåŠ è½½all_docs_dict_2508242302.txt.meta.json: {len(words)}ä¸ªè¯æ±‡")
        return words
    except FileNotFoundError:
        print(f"âŒ æ–‡ä»¶æœªæ‰¾åˆ°: {file_path}")
        return set()
    except Exception as e:
        print(f"âŒ åŠ è½½all_docs_dict_2508242302.txt.meta.jsonå¤±è´¥: {e}")
        return set()


def load_wh40k_vocabulary(vocab_dir: str) -> Set[str]:
    """åŠ è½½wh40k_vocabularyä¸‹æ‰€æœ‰JSONæ–‡ä»¶ä¸­çš„ä¸“ä¸šè¯æ±‡"""
    vocab_dir_path = Path(vocab_dir)
    if not vocab_dir_path.exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {vocab_dir}")
        return set()
    
    all_words = set()
    json_files = list(vocab_dir_path.glob("*.json"))
    
    for json_file in json_files:
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # æå–ä¸»è¯æ±‡å’ŒåŒä¹‰è¯
            for main_word, word_info in data.items():
                all_words.add(main_word)
                # æ·»åŠ åŒä¹‰è¯
                if isinstance(word_info, dict) and "synonyms" in word_info:
                    all_words.update(word_info["synonyms"])
            
            print(f"âœ… æˆåŠŸåŠ è½½ {json_file.name}: {len(data)}ä¸ªä¸»è¯æ±‡")
            
        except Exception as e:
            print(f"âŒ åŠ è½½ {json_file.name} å¤±è´¥: {e}")
    
    print(f"âœ… æ€»è®¡åŠ è½½wh40k_vocabulary: {len(all_words)}ä¸ªä¸“ä¸šè¯æ±‡")
    return all_words


def compare_vocabularies(warhammer_words: Set[str], all_docs_meta_words: Set[str], wh40k_words: Set[str]) -> Tuple[Dict, Dict]:
    """æ¯”è¾ƒä¸‰ä¸ªè¯æ±‡é›†åˆ"""
    results = {
        "warhammer_vs_all_docs_meta": {},
        "warhammer_vs_wh40k": {}
    }
    
    # 1. æ¯”è¾ƒwarhammer_dict vs all_docs_dict_meta
    print("\n" + "="*60)
    print("1. æ£€æŸ¥warhammer_dict.txt vs all_docs_dict_2508242302.txt.meta.json")
    print("="*60)
    
    # æ£€æŸ¥warhammer_dictä¸­æ˜¯å¦åŒ…å«æ‰€æœ‰all_docs_dict_metaè¯æ±‡
    missing_in_warhammer = all_docs_meta_words - warhammer_words
    extra_in_warhammer = warhammer_words - all_docs_meta_words
    
    results["warhammer_vs_all_docs_meta"] = {
        "warhammer_total": len(warhammer_words),
        "all_docs_meta_total": len(all_docs_meta_words),
        "missing_in_warhammer": len(missing_in_warhammer),
        "extra_in_warhammer": len(extra_in_warhammer),
        "common": len(warhammer_words & all_docs_meta_words),
        "missing_list": sorted(list(missing_in_warhammer)),
        "extra_list": sorted(list(extra_in_warhammer))
    }
    
    print(f"warhammer_dict.txt æ€»è¯æ±‡æ•°: {len(warhammer_words)}")
    print(f"all_docs_dict_meta.json æ€»è¯æ±‡æ•°: {len(all_docs_meta_words)}")
    print(f"å…±åŒè¯æ±‡æ•°: {len(warhammer_words & all_docs_meta_words)}")
    print(f"warhammer_dict.txt ç¼ºå¤±çš„è¯æ±‡æ•°: {len(missing_in_warhammer)}")
    print(f"warhammer_dict.txt å¤šä½™çš„è¯æ±‡æ•°: {len(extra_in_warhammer)}")
    
    if missing_in_warhammer:
        print(f"\nâŒ warhammer_dict.txt ç¼ºå¤±çš„è¯æ±‡ (å‰20ä¸ª):")
        for word in sorted(list(missing_in_warhammer))[:20]:
            print(f"  - {word}")
        if len(missing_in_warhammer) > 20:
            print(f"  ... è¿˜æœ‰ {len(missing_in_warhammer) - 20} ä¸ª")
    
    if extra_in_warhammer:
        print(f"\nâš ï¸  warhammer_dict.txt å¤šä½™çš„è¯æ±‡ (å‰20ä¸ª):")
        for word in sorted(list(extra_in_warhammer))[:20]:
            print(f"  - {word}")
        if len(extra_in_warhammer) > 20:
            print(f"  ... è¿˜æœ‰ {len(extra_in_warhammer) - 20} ä¸ª")
    
    # 2. æ¯”è¾ƒwarhammer_dict vs wh40k_vocabulary
    print("\n" + "="*60)
    print("2. æ£€æŸ¥warhammer_dict.txt vs wh40k_vocabulary")
    print("="*60)
    
    # æ£€æŸ¥warhammer_dictä¸­æ˜¯å¦åŒ…å«æ‰€æœ‰wh40kä¸“ä¸šè¯æ±‡
    missing_wh40k_in_warhammer = wh40k_words - warhammer_words
    
    results["warhammer_vs_wh40k"] = {
        "warhammer_total": len(warhammer_words),
        "wh40k_total": len(wh40k_words),
        "missing_wh40k_in_warhammer": len(missing_wh40k_in_warhammer),
        "common": len(warhammer_words & wh40k_words),
        "missing_list": sorted(list(missing_wh40k_in_warhammer))
    }
    
    print(f"warhammer_dict.txt æ€»è¯æ±‡æ•°: {len(warhammer_words)}")
    print(f"wh40k_vocabulary æ€»ä¸“ä¸šè¯æ±‡æ•°: {len(wh40k_words)}")
    print(f"å…±åŒè¯æ±‡æ•°: {len(warhammer_words & wh40k_words)}")
    print(f"warhammer_dict.txt ç¼ºå¤±çš„wh40kä¸“ä¸šè¯æ±‡æ•°: {len(missing_wh40k_in_warhammer)}")
    
    if missing_wh40k_in_warhammer:
        print(f"\nâŒ warhammer_dict.txt ç¼ºå¤±çš„wh40kä¸“ä¸šè¯æ±‡ (å‰30ä¸ª):")
        for word in sorted(list(missing_wh40k_in_warhammer))[:30]:
            print(f"  - {word}")
        if len(missing_wh40k_in_warhammer) > 30:
            print(f"  ... è¿˜æœ‰ {len(missing_wh40k_in_warhammer) - 30} ä¸ª")
    
    return results


def generate_summary_report(results: Dict) -> str:
    """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
    report = []
    report.append("="*80)
    report.append("ğŸ“Š WARHAMMER_DICT.TXT éªŒè¯æ€»ç»“æŠ¥å‘Š")
    report.append("="*80)
    
    # 1. warhammer vs all_docs_dict_meta æ€»ç»“
    all_docs_result = results["warhammer_vs_all_docs_meta"]
    report.append(f"\n1ï¸âƒ£ ä¸ all_docs_dict_2508242302.txt.meta.json å¯¹æ¯”:")
    report.append(f"   âœ… å…±åŒè¯æ±‡: {all_docs_result['common']}")
    report.append(f"   âŒ ç¼ºå¤±è¯æ±‡: {all_docs_result['missing_in_warhammer']}")
    report.append(f"   âš ï¸  å¤šä½™è¯æ±‡: {all_docs_result['extra_in_warhammer']}")
    
    if all_docs_result['missing_in_warhammer'] == 0:
        report.append("   ğŸ‰ å®Œå…¨åŒ¹é…ï¼warhammer_dict.txt åŒ…å«æ‰€æœ‰ all_docs_dict_meta è¯æ±‡")
    else:
        report.append("   âš ï¸  å­˜åœ¨ç¼ºå¤±ï¼Œéœ€è¦æ£€æŸ¥")
    
    # 2. warhammer vs wh40k æ€»ç»“
    wh40k_result = results["warhammer_vs_wh40k"]
    report.append(f"\n2ï¸âƒ£ ä¸ wh40k_vocabulary å¯¹æ¯”:")
    report.append(f"   âœ… å…±åŒä¸“ä¸šè¯æ±‡: {wh40k_result['common']}")
    report.append(f"   âŒ ç¼ºå¤±ä¸“ä¸šè¯æ±‡: {wh40k_result['missing_wh40k_in_warhammer']}")
    
    if wh40k_result['missing_wh40k_in_warhammer'] == 0:
        report.append("   ğŸ‰ å®Œå…¨è¦†ç›–ï¼warhammer_dict.txt åŒ…å«æ‰€æœ‰ wh40k ä¸“ä¸šè¯æ±‡")
    else:
        report.append("   âš ï¸  å­˜åœ¨ç¼ºå¤±ï¼Œéœ€è¦æ£€æŸ¥")
    
    # 3. æ€»ä½“è¯„ä¼°
    report.append(f"\n3ï¸âƒ£ æ€»ä½“è¯„ä¼°:")
    total_issues = all_docs_result['missing_in_warhammer'] + wh40k_result['missing_wh40k_in_warhammer']
    if total_issues == 0:
        report.append("   ğŸ‰ å®Œç¾ï¼warhammer_dict.txt å®Œå…¨æ»¡è¶³è¦æ±‚")
    elif total_issues <= 10:
        report.append("   âœ… è‰¯å¥½ï¼å­˜åœ¨å°‘é‡é—®é¢˜ï¼ŒåŸºæœ¬æ»¡è¶³è¦æ±‚")
    elif total_issues <= 50:
        report.append("   âš ï¸  ä¸€èˆ¬ï¼å­˜åœ¨ä¸€äº›é—®é¢˜ï¼Œéœ€è¦å…³æ³¨")
    else:
        report.append("   âŒ è¾ƒå·®ï¼å­˜åœ¨è¾ƒå¤šé—®é¢˜ï¼Œéœ€è¦ä¿®å¤")
    
    report.append("="*80)
    return "\n".join(report)


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” å¼€å§‹éªŒè¯ warhammer_dict.txt çš„å®Œæ•´æ€§...")
    
    # æ–‡ä»¶è·¯å¾„
    warhammer_dict_path = "dict/warhammer_dict_2508242302.txt"
    all_docs_dict_meta_path = "dict/all_docs_dict_2508242302.txt.meta.json"
    wh40k_vocab_dir = "dict/wh40k_vocabulary"
    
    # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(warhammer_dict_path):
        print(f"âŒ warhammer_dict.txt ä¸å­˜åœ¨: {warhammer_dict_path}")
        return
    
    if not os.path.exists(all_docs_dict_meta_path):
        print(f"âŒ all_docs_dict_2508242302.txt.meta.json ä¸å­˜åœ¨: {all_docs_dict_meta_path}")
        return
    
    if not os.path.exists(wh40k_vocab_dir):
        print(f"âŒ wh40k_vocabulary ç›®å½•ä¸å­˜åœ¨: {wh40k_vocab_dir}")
        return
    
    # åŠ è½½è¯æ±‡
    warhammer_words = load_warhammer_dict(warhammer_dict_path)
    all_docs_meta_words = load_all_docs_dict_meta(all_docs_dict_meta_path)
    wh40k_words = load_wh40k_vocabulary(wh40k_vocab_dir)
    
    if not warhammer_words or not all_docs_meta_words or not wh40k_words:
        print("âŒ è¯æ±‡åŠ è½½å¤±è´¥ï¼Œæ— æ³•ç»§ç»­éªŒè¯")
        return
    
    # æ¯”è¾ƒè¯æ±‡
    results = compare_vocabularies(warhammer_words, all_docs_meta_words, wh40k_words)
    
    # ç”Ÿæˆæ€»ç»“æŠ¥å‘Š
    summary = generate_summary_report(results)
    print(summary)
    
    # ä¿å­˜è¯¦ç»†ç»“æœåˆ°JSONæ–‡ä»¶
    output_file = "warhammer_dict_verification_results.json"
    try:
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ è¯¦ç»†éªŒè¯ç»“æœå·²ä¿å­˜åˆ°: {output_file}")
    except Exception as e:
        print(f"âŒ ä¿å­˜éªŒè¯ç»“æœå¤±è´¥: {e}")


if __name__ == "__main__":
    main()
