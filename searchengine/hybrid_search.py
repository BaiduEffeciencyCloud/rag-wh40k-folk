import os
import sys
from typing import Dict, Any, List, Union
import logging

# åŠ¨æ€æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°æ¨¡å—æœç´¢è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from .search_interface import SearchEngineInterface
from .dense_search import DenseSearchEngine
from .base_search import BaseSearchEngine
from embedding.em_factory import EmbeddingFactory
from conn.osconn import OpenSearchConnection
import config
from storage.oss_storage import OSSStorage
logger = logging.getLogger(__name__)
from dataupload.bm25_config import BM25Config
from dataupload.bm25_manager import BM25Manager
import glob

class HybridSearchEngine(BaseSearchEngine, SearchEngineInterface):
    """Hybridæ··åˆæœç´¢å¼•æ“ï¼Œèåˆdenseå’Œsparseæœç´¢"""
    
    def __init__(self):
        super().__init__()  # ä¿®å¤ï¼šæ­£ç¡®è°ƒç”¨çˆ¶ç±»æ„é€ å‡½æ•°
        # å»¶è¿Ÿåˆå§‹åŒ–denseæœç´¢å¼•æ“ï¼ˆéœ€è¦db_connå‚æ•°ï¼‰
        self.dense_engine = None
        # åŠ è½½BM25Manager
        self.bm25_manager = None
        self._load_bm25_manager()
        logger.info("Hybridæœç´¢å¼•æ“åˆå§‹åŒ–å®Œæˆ")

    def _load_bm25_manager(self):
        """åŠ è½½BM25Managerå’Œè¯å…¸ï¼Œå‚è€ƒSparseSearchEngineï¼Œè‡ªåŠ¨åŠ è½½ç™½åå•userdict"""
        try:
            self.bm25_config = BM25Config()
            # Phase-1: åˆå§‹åŒ–äº‘ç«¯è¯»èƒ½åŠ›ï¼ˆä»å›é€€æœ¬åœ°ï¼‰
            cloud_userdict_bytes = None
            cloud_vocab_bytes = None
            if getattr(config, 'CLOUD_STORAGE', False):
                try:
                    oss = OSSStorage(
                        access_key_id=config.OSS_ACCESS_KEY,
                        access_key_secret=config.OSS_ACCESS_KEY_SECRET,
                        endpoint=config.OSS_ENDPOINT,
                        bucket_name=config.OSS_BUCKET_NAME_DICT,
                        region=config.OSS_REGION
                    )
                    # åˆ—ä¸¾äº‘ç«¯å¯¹è±¡
                    try:
                        freq_keys = oss.list_objects(prefix='bm25_vocab_freq_') or []
                    except Exception:
                        freq_keys = []
                    try:
                        dict_keys = oss.list_objects(prefix='all_docs_dict_') or []
                    except Exception:
                        dict_keys = []
                    # ç®€å•æŒ‰keyå­—é¢æ’åºï¼ˆYYMMDDHHMMSSå³æ—¶é—´åºï¼‰å¹¶è¯»å–bytes
                    if freq_keys:
                        freq_keys.sort()
                        latest_freq_key = freq_keys[-1]
                        try:
                            cloud_vocab_bytes = oss.load(latest_freq_key)
                        except Exception:
                            pass
                    if dict_keys:
                        dict_keys.sort()
                        latest_ud_key = dict_keys[-1]
                        try:
                            cloud_userdict_bytes = oss.load(latest_ud_key)
                        except Exception:
                            pass
                    logger.info("å·²å¯ç”¨äº‘ç«¯è¯»å–èƒ½åŠ›ï¼ˆäº‘ç«¯ä¼˜å…ˆï¼šè‹¥bytesæ‹‰å–æˆåŠŸå°†ç›´æ¥æ³¨å…¥BM25Managerï¼‰")
                except Exception as e:
                    logger.warning(f"äº‘ç«¯è¯»å–åˆå§‹åŒ–å¤±è´¥ï¼Œå›é€€æœ¬åœ°: {e}")
            # ç™½åå•æ¥æºï¼šäº‘ç«¯ä¼˜å…ˆï¼›äº‘ç«¯å¤±è´¥æ—¶å†è¿›è¡Œæœ¬åœ°globå›é€€
            project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            dict_dir = os.path.join(project_root, "dict")
            whitelist_path = None
            if not cloud_userdict_bytes:
                whitelist_files = glob.glob(os.path.join(dict_dir, "all_docs_dict_*.txt"))
                whitelist_files = [f for f in whitelist_files if not f.endswith(".meta.json")]
                if whitelist_files:
                    whitelist_files.sort(reverse=True)
                    whitelist_path = whitelist_files[0]
                    logger.info(f"æ£€æµ‹åˆ°ç™½åå•userdict: {whitelist_path}")
                else:
                    logger.info("æœªæ£€æµ‹åˆ°ç™½åå•userdictï¼ŒæŒ‰æ— ç™½åå•æµç¨‹åŠ è½½BM25Manager")
            self.bm25_manager = BM25Manager(
                k1=self.bm25_config.k1,
                b=self.bm25_config.b,
                min_freq=self.bm25_config.min_freq,
                max_vocab_size=self.bm25_config.max_vocab_size,
                user_dict_path=whitelist_path
            )
            # è‹¥äº‘ç«¯byteså¯ç”¨ï¼Œä¼˜å…ˆæ³¨å…¥BM25Managerï¼ˆä¸è§¦ç›˜ï¼‰
            if cloud_userdict_bytes:
                try:
                    self.bm25_manager.load_userdict_from_bytes(cloud_userdict_bytes)
                    logger.info("å·²ä»äº‘ç«¯bytesåŠ è½½userdictï¼ˆç™½åå•ï¼‰")
                except Exception as e:
                    logger.warning(f"äº‘ç«¯userdict bytesåŠ è½½å¤±è´¥ï¼Œå¿½ç•¥å¹¶å›é€€æœ¬åœ°: {e}")
            vocab_loaded_from_cloud = False
            if cloud_vocab_bytes:
                try:
                    self.bm25_manager.load_dictionary_from_bytes(cloud_vocab_bytes)
                    vocab_loaded_from_cloud = True
                    logger.info("å·²ä»äº‘ç«¯bytesåŠ è½½BM25è¯å…¸")
                except Exception as e:
                    logger.warning(f"äº‘ç«¯è¯å…¸ bytesåŠ è½½å¤±è´¥ï¼Œå›é€€æœ¬åœ°: {e}")
            # ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•çš„ç»å¯¹è·¯å¾„
            # ä»searchengine/hybrid_search.py -> é¡¹ç›®æ ¹ç›®å½•
            project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            dict_dir = os.path.join(project_root, "dict")
            vocab_path = None
            if not vocab_loaded_from_cloud:
                vocab_path = self.bm25_manager.get_latest_freq_dict_file(dict_dir)
                if not vocab_path or not os.path.exists(vocab_path):
                    logger.error("æœªæ‰¾åˆ°æœ‰æ•ˆçš„è¯æ±‡è¡¨æ–‡ä»¶ï¼ˆäº‘ç«¯ä¸æœ¬åœ°å‡ä¸å¯ç”¨ï¼‰")
                    raise FileNotFoundError("æœªæ‰¾åˆ°æœ‰æ•ˆçš„è¯æ±‡è¡¨æ–‡ä»¶")
            # ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•çš„ç»å¯¹è·¯å¾„
            model_path = os.path.join(project_root, self.bm25_config.get_model_path())
            if os.path.exists(model_path):
                # æœ‰æ¨¡å‹æ–‡ä»¶åˆ™ä¼˜å…ˆè½½å…¥æ¨¡å‹ï¼›è‹¥æ— æœ¬åœ°vocab_pathä¸”å·²ç”¨äº‘ç«¯bytesåŠ è½½è¯å…¸ï¼Œåˆ™ç”¨ä¸€ä¸ªå ä½è·¯å¾„
                self.bm25_manager.load_model(model_path, vocab_path if vocab_path else os.path.join(dict_dir, "bm25_vocab_freq_latest.json"))
                logger.info("æˆåŠŸåŠ è½½BM25æ¨¡å‹")
            else:
                if not vocab_loaded_from_cloud:
                    self.bm25_manager.load_dictionary(vocab_path)
                    logger.info(f"æˆåŠŸåŠ è½½BM25è¯æ±‡è¡¨ï¼Œè¯å…¸è·¯å¾„: {vocab_path}ï¼ˆæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œéœ€è¦é‡æ–°è®­ç»ƒï¼‰")
                else:
                    logger.info("æˆåŠŸåŠ è½½BM25è¯æ±‡è¡¨ï¼ˆæ¥è‡ªäº‘ç«¯bytesï¼Œæœªè½ç›˜ï¼›æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œéœ€è¦é‡æ–°è®­ç»ƒï¼‰")
        except Exception as e:
            logger.error(f"åŠ è½½BM25Managerå¤±è´¥: {str(e)}")
            self.bm25_manager = None



    def _generate_sparse_vector(self, query_text: str) -> Dict[str, List]:
        """
        ç”Ÿæˆqueryçš„sparseå‘é‡ï¼Œå‚è€ƒSparseSearchEngine
        Args:
            query_text: æŸ¥è¯¢æ–‡æœ¬
        Returns:
            Dict[str, List]: åŒ…å«indiceså’Œvaluesçš„ç¨€ç–å‘é‡
        """
        if not self.bm25_manager:
            raise RuntimeError("BM25Manageræœªåˆå§‹åŒ–")
        try:
            sparse_vector = self.bm25_manager.get_sparse_vector(query_text)
            logger.info(f"BM25ç¨€ç–å‘é‡ç”ŸæˆæˆåŠŸï¼Œindices: {sparse_vector['indices'][:5]}...")
            # Pineconeè¦æ±‚indicesä¸ºint
            sparse_vector['indices'] = [int(i) for i in sparse_vector['indices']]
            return sparse_vector
        except Exception as e:
            logger.warning(f"ç”Ÿæˆsparseå‘é‡å¤±è´¥: {str(e)}")
            raise

    def search(self, query, intent: str, top_k=10, db_conn=None, embedding_model=None, rerank=True, **kwargs):
        """
        æ‰§è¡Œhybridæœç´¢ï¼ˆdense+sparseï¼‰
        Args:
            query: æŸ¥è¯¢ï¼ˆå­—ç¬¦ä¸²æˆ–ç»“æ„åŒ–æŸ¥è¯¢å¯¹è±¡ï¼‰
            top_k: è¿”å›ç»“æœæ•°é‡
            **kwargs: å…¶ä»–å‚æ•°ï¼ˆå¦‚filterã€alphaã€db_connã€embedding_modelã€rerankç­‰ï¼‰
        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        # å¤„ç†æŸ¥è¯¢è¾“å…¥
        if isinstance(query, dict):
            query_text = query.get('text', '')
            if not query_text:
                logger.warning("ç»“æ„åŒ–æŸ¥è¯¢ä¸­æ²¡æœ‰æ‰¾åˆ°textå­—æ®µ")
                return []
        else:
            query_text = str(query)
        if not query_text.strip():
            logger.warning("æŸ¥è¯¢æ–‡æœ¬ä¸ºç©º")
            return []
        
        # è·å–å…³é”®å‚æ•°
        filter_dict = kwargs.get('filter', {})
        #alpha = kwargs.get('alpha', HYBRID_ALPHA)
        # db_conn å’Œ embedding_model éƒ½æ˜¯æ–¹æ³•å‚æ•°ï¼Œä¸è¦ä»kwargsé‡æ–°è·å–ï¼
        # db_conn = kwargs.get('db_conn')  # è¿™è¡Œä¹Ÿä¼šå¯¼è‡´Noneè¦†ç›–ï¼
        # embedding_model = kwargs.get('embedding_model')  # è¿™è¡Œå¯¼è‡´äº†Noneè¦†ç›–ï¼
        # rerank = kwargs.get('rerank', True)  # æ·»åŠ rerankå‚æ•°æ”¯æŒ
        query_intent = intent
        # åŠ¨æ€åŠ è½½intenté…ç½®
        try:
            # åˆ›å»ºä¸€ä¸ªä¸´æ—¶è¿æ¥å®ä¾‹æ¥åŠ è½½é…ç½®
            temp_conn = OpenSearchConnection()
            intent_config = temp_conn._load_intent_config(query_intent)
            alpha = intent_config.HYBRID_CONF.HYBRID_ALPHA
            algorithm = intent_config.HYBRID_CONF.HYBRID_ALGORITHM
            logger.info(f"æ ¹æ®intent '{query_intent}' åŠ¨æ€åŠ è½½ç®—æ³•é…ç½®: {algorithm}")
        except Exception as e:
            logger.warning(f"åŠ¨æ€åŠ è½½intenté…ç½®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ç®—æ³•: {str(e)}")
            algorithm = "pipeline"
            alpha = 0.5
        
        try:
            if algorithm == 'rrf':
                # ä½¿ç”¨RRFç®—æ³•
                results = self._search_with_rrf(query_text,query_intent,filter_dict, top_k, alpha, db_conn, embedding_model, rerank=rerank)
            else:
                # ä½¿ç”¨ç°æœ‰pipelineç®—æ³•ï¼ˆé»˜è®¤ï¼‰
                results = self._search_with_pipeline(query_text,query_intent,filter_dict, top_k, alpha, db_conn, embedding_model, rerank=rerank)
            
            # æ ¼å¼åŒ–ç»“æœï¼Œä¿æŒsearch_typeä¸º'hybrid'ä¾›åç»­æ¨¡å—ä½¿ç”¨
            final_results = self._format_without_rerank(results, query_text, 'hybrid')
            
            if rerank:
                logger.info(f"Hybridæœç´¢å®Œæˆï¼ˆå¯ç”¨rerankï¼‰ï¼ŒæŸ¥è¯¢: {query_text[:50]}...ï¼Œè¿”å› {len(final_results)} ä¸ªç»“æœ")
            else:
                logger.info(f"Hybridæœç´¢å®Œæˆï¼ˆè·³è¿‡rerankï¼‰ï¼ŒæŸ¥è¯¢: {query_text[:50]}...ï¼Œè¿”å› {len(final_results)} ä¸ªç»“æœ")
            
            return final_results
                
        except Exception as e:
            # æ£€æŸ¥æ˜¯å¦æ˜¯æ ¸å¿ƒåŠŸèƒ½å¤±è´¥ï¼ˆå¦‚embeddingç”Ÿæˆå¤±è´¥ï¼‰
            if "embedding" in str(e).lower() or "embed" in str(e).lower():
                logger.error(f"æ ¸å¿ƒåŠŸèƒ½å¤±è´¥ï¼Œæ— æ³•é™çº§: {str(e)}")
                raise  # é‡æ–°æŠ›å‡ºå¼‚å¸¸
            else:
                logger.warning(f"Hybridæ£€ç´¢å¤±è´¥: {str(e)}ï¼Œé™çº§ä¸ºdenseæ£€ç´¢")
                # é™çº§æ—¶ä½¿ç”¨ä¼ å…¥çš„db_connå’Œembedding_model
                if db_conn:
                    return self._fallback_to_dense(query_text, top_k, filter_dict, db_conn, embedding_model)
                else:
                    logger.error("æ— æ³•é™çº§ä¸ºdenseæ£€ç´¢ï¼šç¼ºå°‘db_connå‚æ•°")
                    return []

        # 3. ç»„è£…è¡¥å…¨åçš„ç»“æœ  
    
    def _fallback_to_dense(self, query_text: str, top_k: int, filter_dict: dict, db_conn, embedding_model) -> List[Dict[str, Any]]:
        """
        é™çº§ä¸ºdenseæ£€ç´¢
        """
        try:
            # ä½¿ç”¨å®ä¾‹çš„dense_engineï¼ˆå¦‚æœå­˜åœ¨ï¼‰æˆ–åˆ›å»ºæ–°çš„
            if hasattr(self, 'dense_engine') and self.dense_engine:
                dense_engine = self.dense_engine
            else:
                from .dense_search import DenseSearchEngine
                dense_engine = DenseSearchEngine()
                # ç¡®ä¿æ–°åˆ›å»ºçš„å®ä¾‹æœ‰embedding_modelå±æ€§
                dense_engine.embedding_model = embedding_model
            
            # è°ƒç”¨denseæ£€ç´¢
            results = dense_engine.search(
                query_text, 
                top_k=top_k, 
                db_conn=db_conn, 
                embedding_model=embedding_model,
                filter=filter_dict
            )
            
            logger.info(f"Denseæ£€ç´¢é™çº§å®Œæˆï¼ŒæŸ¥è¯¢: {query_text[:50]}...ï¼Œè¿”å› {len(results)} ä¸ªç»“æœ")
            return results
            
        except Exception as e:
            logger.error(f"Denseæ£€ç´¢é™çº§å¤±è´¥: {str(e)}")
            return []
    
    def _search_with_rrf(self, query_text: str, intent:str,filter_dict: dict, top_k: int, alpha: float, db_conn, embedding_model, rerank: bool = False) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨RRFç®—æ³•æ‰§è¡Œæ··åˆæœç´¢
        """
        # ç”Ÿæˆdenseå‘é‡ï¼ˆå¦‚å¤±è´¥ç›´æ¥raiseå¼‚å¸¸ï¼‰
        try:
            # ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„embedding_modelå®ä¾‹
            query_embedding = embedding_model.get_embedding(query_text)
        except Exception as e:
            logger.error(f"è·å–embeddingå¤±è´¥: {str(e)}")
            raise
        
        # ç”Ÿæˆsparseå‘é‡ï¼ˆå¦‚å¤±è´¥é™çº§denseï¼‰
        try:
            sparse_vector = self._generate_sparse_vector(query_text)
        except Exception as e:
            logger.warning(f"sparseå‘é‡ç”Ÿæˆå¤±è´¥ï¼Œé™çº§ä¸ºdenseæ£€ç´¢: {str(e)}")
            return self._fallback_to_dense(query_text, top_k, filter_dict, db_conn, embedding_model)
        
        # æ‰§è¡ŒRRFæ··åˆæœç´¢ï¼ˆå¦‚å¤±è´¥é™çº§denseï¼‰
        try:
            if db_conn and hasattr(db_conn, 'hybrid_search'):
                response = db_conn.hybrid_search(
                    query=query_text,
                    intent=intent,
                    filter=filter_dict,
                    top_k=top_k,
                    rerank=rerank,
                    algorithm='rrf',
                    sparse_vector=sparse_vector,
                    dense_vector=query_embedding
                )
                
                # æ·»åŠ è°ƒè¯•æ—¥å¿—ï¼Œäº†è§£è¿”å›æ•°æ®çš„ç»“æ„
                logger.debug(f"RRFæ··åˆæœç´¢ - OpenSearch è¿”å›çš„åŸå§‹æ•°æ®: {response}")
                logger.debug(f"RRFæ··åˆæœç´¢ - æ•°æ®ç±»å‹: {type(response)}")
                logger.debug(f"RRFæ··åˆæœç´¢ - æ•°æ®é”®: {list(response.keys()) if isinstance(response, dict) else 'Not a dict'}")
                
                if isinstance(response, dict) and 'hits' in response:
                    hits = response['hits']
                    logger.debug(f"RRFæ··åˆæœç´¢ - hits å­—æ®µ: {hits}")
                    logger.debug(f"RRFæ··åˆæœç´¢ - hits ç±»å‹: {type(hits)}")
                    if isinstance(hits, dict) and 'hits' in hits:
                        actual_hits = hits['hits']
                        logger.debug(f"RRFæ··åˆæœç´¢ - å®é™…ç»“æœæ•°é‡: {len(actual_hits) if isinstance(actual_hits, list) else 'Not a list'}")
                        if actual_hits and len(actual_hits) > 0:
                            logger.debug(f"RRFæ··åˆæœç´¢ - ç¬¬ä¸€ä¸ªç»“æœç»“æ„: {list(actual_hits[0].keys()) if isinstance(actual_hits, list) else 'Not a list'}")
                
                # æ ¼å¼åŒ–ç»“æœ
                formatted_results = self._format_hybrid_result(response)
                
                # ğŸ”´ å¤ç”¨åŸºç±»çš„scoreåˆ†ææ—¥å¿—å‡½æ•°
                self._log_score_analysis(formatted_results, "RRFæ··åˆæœç´¢", query_text)
                
                return formatted_results
            else:
                logger.warning("æ•°æ®åº“è¿æ¥ä¸æ”¯æŒRRFæ··åˆæœç´¢ï¼Œé™çº§ä¸ºdenseæ£€ç´¢")
                return self._fallback_to_dense(query_text, top_k, filter_dict, db_conn, embedding_model)
                
        except Exception as e:
            logger.warning(f"RRFæ··åˆæ£€ç´¢å¤±è´¥: {str(e)}ï¼Œé™çº§ä¸ºdenseæ£€ç´¢")
            return self._fallback_to_dense(query_text, top_k, filter_dict, db_conn, embedding_model)
    
    def _search_with_pipeline(self, query_text: str,intent:str, filter_dict: dict, top_k: int, alpha: float, db_conn, embedding_model, rerank: bool = False) -> List[Dict[str, Any]]:
        """
        ä½¿ç”¨ç°æœ‰pipelineç®—æ³•æ‰§è¡Œæ··åˆæœç´¢
        """
        # ç”Ÿæˆdenseå‘é‡ï¼ˆå¦‚å¤±è´¥ç›´æ¥raiseå¼‚å¸¸ï¼‰
        try:
            query_embedding = embedding_model.get_embedding(query_text)
        except Exception as e:
            logger.error(f"è·å–embeddingå¤±è´¥: {str(e)}")
            raise
        
        # æ‰§è¡Œhybridæœç´¢ï¼ˆå¦‚å¤±è´¥é™çº§denseï¼‰
        try:
            if db_conn and hasattr(db_conn, 'hybrid_search'):
                # ä½¿ç”¨ç»Ÿä¸€æ¥å£æ‰§è¡Œæ··åˆæœç´¢
                response = db_conn.hybrid_search(
                    query=query_text,
                    intent=intent,
                    filter=filter_dict,
                    top_k=top_k,
                    rerank=rerank,
                    algorithm='pipeline',
                    query_vector=query_embedding,
                    bm25_weight=alpha,
                    vector_weight=1.0 - alpha
                )
                
                if isinstance(response, dict) and 'hits' in response:
                    hits = response['hits']
                    if isinstance(hits, dict) and 'hits' in hits:
                        actual_hits = hits['hits']
                        logger.debug(f"Pipelineæ··åˆæœç´¢ - å®é™…ç»“æœæ•°é‡: {len(actual_hits) if isinstance(actual_hits, list) else 'Not a list'}")
                        if actual_hits and len(actual_hits) > 0:
                            logger.debug(f"Pipelineæ··åˆæœç´¢ - ç¬¬ä¸€ä¸ªç»“æœç»“æ„: {list(actual_hits[0].keys()) if isinstance(actual_hits, list) else 'Not a list'}")
                
                # æ ¼å¼åŒ–ç»“æœ
                formatted_results = self._format_hybrid_result(response)
                
                # ğŸ”´ å¤ç”¨åŸºç±»çš„scoreåˆ†ææ—¥å¿—å‡½æ•°
                self._log_score_analysis(formatted_results, "Pipelineæ··åˆæœç´¢", query_text, alpha=alpha)
                
                return formatted_results
            else:
                logger.warning("æ•°æ®åº“è¿æ¥ä¸æ”¯æŒæ··åˆæœç´¢ï¼Œé™çº§ä¸ºdenseæ£€ç´¢")
                return self._fallback_to_dense(query_text, top_k, filter_dict, db_conn, embedding_model)
                
        except Exception as e:
            logger.warning(f"Pipelineæ··åˆæ£€ç´¢å¤±è´¥: {str(e)}ï¼Œé™çº§ä¸ºdenseæ£€ç´¢")
            return self._fallback_to_dense(query_text, top_k, filter_dict, db_conn, embedding_model)
    

    

    
    def get_type(self) -> str:
        return "hybrid"

 
    
    def _format_hybrid_result(self, opensearch_results: dict) -> list:
        """
        å°† OpenSearch è¿”å›ç»“æœæ ¼å¼åŒ–ä¸ºæ ‡å‡†æœç´¢ç»“æœæ ¼å¼
        
        Args:
            opensearch_results: OpenSearch è¿”å›çš„åŸå§‹å“åº”ç»“æ„ï¼ŒåŒ…å«totalå’Œhits
            
        Returns:
            list: æ ‡å‡†æ ¼å¼çš„æœç´¢ç»“æœåˆ—è¡¨
        """
        formatted_results = []
        
        # å¤„ç†ä¸åŒçš„æ•°æ®ç»“æ„ï¼ˆRRF vs Pipelineï¼‰
        if 'hits' in opensearch_results:
            # RRF è¿”å›çš„å®Œæ•´å“åº”ç»“æ„
            if isinstance(opensearch_results['hits'], dict) and 'hits' in opensearch_results['hits']:
                hits = opensearch_results['hits']['hits']
            else:
                # Pipeline è¿”å›çš„ç›´æ¥ hits ç»“æ„
                hits = opensearch_results['hits']
        else:
            hits = []
        
        for hit in hits:
            # åˆ›å»ºæ ‡å‡†æ ¼å¼çš„æœç´¢ç»“æœ
            formatted_result = {
                'id': hit['_id'],
                'score': hit['_score'],
                'text': hit['_source']['text'],
                'faction': hit['_source'].get('faction', ''),
                'content_type': hit['_source'].get('content_type', ''),
                'section_heading': hit['_source'].get('section_heading', ''),
                'h1': hit['_source'].get('h1', ''),
                'h2': hit['_source'].get('h2', ''),
                'h3': hit['_source'].get('h3', ''),
                'source_file': hit['_source'].get('source_file', ''),
                'chunk_index': hit['_source'].get('chunk_index', 0),
                'created_at': hit['_source'].get('created_at', '')
            }
            formatted_results.append(formatted_result)
        
        return formatted_results

    def _format_without_rerank(self, formatted_results: List[Dict], query_text: str, search_engine: str) -> List[Dict]:
        """
        è·³è¿‡rerankæ—¶ï¼Œå°†formatted_resultsè½¬æ¢ä¸ºä¸compositeä¸€è‡´çš„æ ¼å¼
        
        Args:
            formatted_results: _format_hybrid_resultæ–¹æ³•è¿”å›çš„ç»“æœ
            query_text: æŸ¥è¯¢æ–‡æœ¬
            search_engine: æœç´¢å¼•æ“ç±»å‹
            
        Returns:
            List[Dict]: ä¸compositeæ ¼å¼ä¸€è‡´çš„ç»“æœåˆ—è¡¨
        """
        results = []
        for i, item in enumerate(formatted_results):
            result = {
                'id': item.get('id', i),  # ä½¿ç”¨åŸå§‹IDæˆ–ç´¢å¼•
                'text': item.get('text', ''),
                'score': item.get('score', 0.0),  # ä¿æŒåŸå§‹å‘é‡åˆ†æ•°
                'query': query_text,
                # ä¿ç•™é‡è¦å…ƒæ•°æ®ï¼Œç¡®ä¿postsearchæ¨¡å—èƒ½æ­£å¸¸å¤„ç†
                'faction': item.get('faction', ''),
                'content_type': item.get('content_type', ''),
                'section_heading': item.get('section_heading', ''),
                'source_file': item.get('source_file', ''),
                'chunk_index': item.get('chunk_index', 0)
            }
            results.append(result)
        
        return results
    
    def _format_with_rerank(self, rerank_results: any, query_text: str, search_engine: str) -> List[Dict]:
        """
        ä½¿ç”¨rerankç»“æœï¼Œè½¬æ¢ä¸ºæ ‡å‡†æ ¼å¼
        
        Args:
            rerank_results: rerank APIè¿”å›çš„ç»“æœ
            query_text: æŸ¥è¯¢æ–‡æœ¬
            search_engine: æœç´¢å¼•æ“ç±»å‹
            
        Returns:
            List[Dict]: æ ‡å‡†æ ¼å¼çš„ç»“æœåˆ—è¡¨
        """
        # å¤ç”¨åŸºç±»çš„compositeæ–¹æ³•
        return self.composite(rerank_results, query_text, search_engine)

