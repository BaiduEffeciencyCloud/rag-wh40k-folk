#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
è°ƒè¯•è„šæœ¬ï¼šåˆ†æwh40k_vocabularyåŠ è½½è¿‡ç¨‹
æ‰¾å‡ºä¸ºä»€ä¹ˆ"æ­»ç¥å†›æ¯’ç¾é£è‰‡"æ²¡æœ‰è¢«æ­£ç¡®åŠ è½½
"""

import json
import os
from pathlib import Path
from typing import Set, Dict, List


def debug_wh40k_vocabulary_loading(vocab_dir: str):
    """è°ƒè¯•wh40k_vocabularyåŠ è½½è¿‡ç¨‹"""
    vocab_dir_path = Path(vocab_dir)
    if not vocab_dir_path.exists():
        print(f"âŒ ç›®å½•ä¸å­˜åœ¨: {vocab_dir}")
        return
    
    print("ğŸ” å¼€å§‹è°ƒè¯•wh40k_vocabularyåŠ è½½è¿‡ç¨‹...")
    print("="*60)
    
    json_files = list(vocab_dir_path.glob("*.json"))
    print(f"æ‰¾åˆ° {len(json_files)} ä¸ªJSONæ–‡ä»¶:")
    for f in json_files:
        print(f"  - {f.name}")
    
    print("\n" + "="*60)
    
    all_words = set()
    all_main_words = set()
    all_synonyms = set()
    
    for json_file in json_files:
        print(f"\nğŸ“ å¤„ç†æ–‡ä»¶: {json_file.name}")
        print("-" * 40)
        
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            file_main_words = set()
            file_synonyms = set()
            
            print(f"æ–‡ä»¶åŒ…å« {len(data)} ä¸ªä¸»è¯æ±‡")
            
            # è¯¦ç»†åˆ†ææ¯ä¸ªè¯æ±‡
            for main_word, word_info in data.items():
                file_main_words.add(main_word)
                all_main_words.add(main_word)
                
                # æ£€æŸ¥è¯æ±‡ä¿¡æ¯ç»“æ„
                if isinstance(word_info, dict):
                    print(f"  âœ“ {main_word}: {type(word_info)}")
                    
                    # æ£€æŸ¥åŒä¹‰è¯
                    if "synonyms" in word_info:
                        synonyms = word_info["synonyms"]
                        if isinstance(synonyms, list):
                            print(f"    - åŒä¹‰è¯: {synonyms}")
                            file_synonyms.update(synonyms)
                            all_synonyms.update(synonyms)
                        else:
                            print(f"    âš ï¸  åŒä¹‰è¯æ ¼å¼é”™è¯¯: {type(synonyms)}")
                    else:
                        print(f"    - æ— åŒä¹‰è¯")
                else:
                    print(f"  âš ï¸  {main_word}: æ ¼å¼é”™è¯¯ {type(word_info)}")
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«ç›®æ ‡è¯æ±‡
                if "æ­»ç¥å†›æ¯’ç¾é£è‰‡" in main_word:
                    print(f"    ğŸ¯ æ‰¾åˆ°ç›®æ ‡è¯æ±‡: {main_word}")
                if "æ¯’ç¾" in main_word:
                    print(f"    ğŸ¯ æ‰¾åˆ°åŒ…å«'æ¯’ç¾'çš„è¯æ±‡: {main_word}")
                if "é£è‰‡" in main_word:
                    print(f"    ğŸ¯ æ‰¾åˆ°åŒ…å«'é£è‰‡'çš„è¯æ±‡: {main_word}")
            
            # æ£€æŸ¥åŒä¹‰è¯ä¸­æ˜¯å¦åŒ…å«ç›®æ ‡è¯æ±‡
            for synonym in file_synonyms:
                if "æ­»ç¥å†›æ¯’ç¾é£è‰‡" in synonym:
                    print(f"    ğŸ¯ åœ¨åŒä¹‰è¯ä¸­æ‰¾åˆ°ç›®æ ‡è¯æ±‡: {synonym}")
                if "æ¯’ç¾" in synonym:
                    print(f"    ğŸ¯ åœ¨åŒä¹‰è¯ä¸­æ‰¾åˆ°åŒ…å«'æ¯’ç¾'çš„è¯æ±‡: {synonym}")
                if "é£è‰‡" in synonym:
                    print(f"    ğŸ¯ åœ¨åŒä¹‰è¯ä¸­æ‰¾åˆ°åŒ…å«'é£è‰‡'çš„è¯æ±‡: {synonym}")
            
            print(f"  ğŸ“Š æœ¬æ–‡ä»¶ç»Ÿè®¡:")
            print(f"    - ä¸»è¯æ±‡: {len(file_main_words)}")
            print(f"    - åŒä¹‰è¯: {len(file_synonyms)}")
            
        except Exception as e:
            print(f"âŒ åŠ è½½ {json_file.name} å¤±è´¥: {e}")
    
    print("\n" + "="*60)
    print("ğŸ“Š æ€»ä½“ç»Ÿè®¡:")
    print(f"ä¸»è¯æ±‡æ€»æ•°: {len(all_main_words)}")
    print(f"åŒä¹‰è¯æ€»æ•°: {len(all_synonyms)}")
    print(f"æ€»è¯æ±‡æ•°: {len(all_main_words) + len(all_synonyms)}")
    
    # æ£€æŸ¥ç›®æ ‡è¯æ±‡
    print("\n" + "="*60)
    print("ğŸ¯ ç›®æ ‡è¯æ±‡æ£€æŸ¥:")
    
    target_word = "æ­»ç¥å†›æ¯’ç¾é£è‰‡"
    found_in_main = target_word in all_main_words
    found_in_synonyms = target_word in all_synonyms
    
    print(f"ç›®æ ‡è¯æ±‡: '{target_word}'")
    print(f"åœ¨ä¸»è¯æ±‡ä¸­: {'âœ…' if found_in_main else 'âŒ'}")
    print(f"åœ¨åŒä¹‰è¯ä¸­: {'âœ…' if found_in_synonyms else 'âŒ'}")
    
    if not found_in_main and not found_in_synonyms:
        print("\nğŸ” æœç´¢ç›¸ä¼¼è¯æ±‡:")
        similar_words = []
        for word in all_main_words:
            if any(part in word for part in ["æ­»ç¥å†›", "æ¯’ç¾", "é£è‰‡"]):
                similar_words.append(word)
        
        for word in all_synonyms:
            if any(part in word for part in ["æ­»ç¥å†›", "æ¯’ç¾", "é£è‰‡"]):
                similar_words.append(word)
        
        if similar_words:
            print("æ‰¾åˆ°ç›¸ä¼¼è¯æ±‡:")
            for word in sorted(set(similar_words)):
                print(f"  - {word}")
        else:
            print("æœªæ‰¾åˆ°ä»»ä½•ç›¸ä¼¼è¯æ±‡")
    
    # æ£€æŸ¥wh40k_vocabularyä¸­å®é™…åŒ…å«çš„è¯æ±‡
    print("\n" + "="*60)
    print("ğŸ“‹ wh40k_vocabularyå®é™…åŒ…å«çš„è¯æ±‡æ ·æœ¬:")
    
    # æ˜¾ç¤ºä¸€äº›ä¸»è¯æ±‡
    print("\nä¸»è¯æ±‡æ ·æœ¬ (å‰20ä¸ª):")
    for word in sorted(list(all_main_words))[:20]:
        print(f"  - {word}")
    
    # æ˜¾ç¤ºä¸€äº›åŒä¹‰è¯
    print("\nåŒä¹‰è¯æ ·æœ¬ (å‰20ä¸ª):")
    for word in sorted(list(all_synonyms))[:20]:
        print(f"  - {word}")


def main():
    """ä¸»å‡½æ•°"""
    wh40k_vocab_dir = "dict/wh40k_vocabulary"
    
    if not os.path.exists(wh40k_vocab_dir):
        print(f"âŒ wh40k_vocabulary ç›®å½•ä¸å­˜åœ¨: {wh40k_vocab_dir}")
        return
    
    debug_wh40k_vocabulary_loading(wh40k_vocab_dir)


if __name__ == "__main__":
    main()
