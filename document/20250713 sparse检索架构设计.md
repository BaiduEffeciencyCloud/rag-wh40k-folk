
# sparse检索架构设计

1. 业务背景
1.1 需求与目标
当前RAG系统在处理穷举类query（如“艾达灵族有多少骑乘单位”）时召回效果不佳。
这类query通常需要遍历所有文档片段，并将分散在不同chunk中的关键信息进行聚合，才能给出完整答案。
目标是提升此类“全量枚举/聚合”场景下的召回率和答案完整性。
1.2 现有系统痛点
现有系统主要依赖dense检索（向量召回），对于特征明显、关键词明确的穷举类query，召回率低，容易遗漏关键信息。
尝试过通过MMR+扩大top_k来提升召回全面性，但实际效果有限，仍无法覆盖所有相关片段。
需要引入hybrid检索（dense+sparse），利用sparse检索对关键词/短语的高覆盖能力，提升穷举类query的召回和聚合效果。

---

## 2.1 系统架构图

### 系统流程说明

1. **原始文档采集**  
   ↓  
2. **文档切分（chunking）**  
   - 将大文档切分为适合检索的chunk  
   ↓  
3. **分词与短语挖掘**  
   - 使用`jieba`等工具对chunk分词，统计unigram/bigram/trigram，挖掘高PMI短语  
   ↓  
4. **全局词典生成（userdict）**  
   - 汇总所有token/短语，生成唯一id映射  
   ↓  
5. **chunk稀疏特征编码**  
   - 每个chunk根据userdict编码为稀疏向量（indices+values）  
   ↓  
6. **向量化（dense embedding）**  
   - 对chunk文本生成dense向量  
   ↓  
7. **数据上传（upsert）**  
   - 将chunk的稀疏向量和dense向量一同上传到Pinecone等向量数据库  
   ↓  
8. **在线检索**  
   - 用户query分词→映射userdict→生成sparse query→Pinecone检索  
   - 可与dense检索结果hybrid融合  
   ↓  
9. **结果聚合与答案生成**

---

### Markdown流程图

```markdown
原始文档
   │
   ▼
[文档切分]
   │
   ▼
[分词+短语挖掘]───►[全局词典(userdict)]
   │                    │
   │                    ▼
   │             [chunk稀疏特征编码]
   │                    │
   │                    ▼
   └─────────────►[chunk dense向量]
                        │
                        ▼
                [数据上传(upsert)]
                        │
                        ▼
                [Pinecone向量库]
                        │
                        ▼
                [在线检索]
                        │
                        ▼
                [结果聚合/答案生成]
```

---

### 说明

- **左侧流程**：离线数据处理与上传
- **右侧流程**：在线检索与答案生成
- **全局词典**：是稀疏特征编码的基础，保证chunk和query分词一致性
- **Pinecone**：自动管理稀疏索引（倒排索引）和dense向量，支持hybrid检索

---

好的，下面是**2.2 关键模块说明**的详细撰写，结合你们现有代码结构和 Pinecone 官方文档：

---

## 2.2 关键模块说明

### 2.2.1 全局词典与短语挖掘（`dataupload.gen_userdict.py`）

- **功能**：负责从所有原始文档中自动挖掘高频词、短语（unigram/bigram/trigram），并结合PMI等统计方法筛选高质量短语，最终生成全局词典（userdict）。
- **实现要点**：
  - 使用`jieba`分词，对所有文档进行分词和n-gram统计。
  - 通过多重过滤（标点、停用词、结构助词、HTML标签等）去除无效token。
  - 采用PMI等方法自动发现高质量短语（如“可以使用”、“本单位可以”），并可人工补充业务高频短语。
  - 词典既包含单字/词，也包含高质量短语，支持多粒度检索。
  - 词典为后续chunk和query的稀疏特征编码提供唯一id映射。

---

### 2.2.2 chunk稀疏特征生成与上传（`dataupload.upsert.py`）

- **功能**：将每个chunk文本转为稀疏向量（bag-of-words/TF-IDF/BM25等），并与dense向量一同上传到向量数据库（如Pinecone）。
- **实现要点**：
  - 对每个chunk文本，使用与userdict一致的分词和短语挖掘逻辑，生成token列表。
  - 将token映射为userdict中的id，统计词频或计算TF-IDF/BM25权重，形成稀疏向量（indices+values）。
  - 通过Pinecone的`sparse_values`字段，将稀疏向量与dense向量一同upsert到数据库。
  - 支持批量上传，提升数据导入效率。
  - 保证chunk和query的分词、编码方式完全一致，确保检索时能正确召回。

---

### 2.2.3 检索服务接口与未来SparseSearch模块结构

- **searchengine接口与工厂类**（未来扩展）：
  - 设计`SparseSearchEngine`模块，继承统一的`SearchEngineInterface`，实现基于sparse向量的检索逻辑。
  - 工厂类（如`SearchEngineFactory`）支持按配置动态选择`sparse`、`dense`、`hybrid`等检索引擎，便于灵活切换和组合。
  - 典型接口：
    ```python
    class SearchEngineInterface:
        def search(self, query, top_k=10, **kwargs):
            pass

    class SparseSearchEngine(SearchEngineInterface):
        def search(self, query, top_k=10, **kwargs):
            # 1. query分词
            # 2. token映射userdict id
            # 3. 生成sparse query
            # 4. 调用Pinecone的sparse检索接口
            # 5. 返回召回结果
    ```
  - 支持hybrid检索时，工厂类可组合`sparse`和`dense`结果，做去重与融合排序。

---

### 2.2.4 Pinecone对Sparse检索与倒排索引的支持

- **Pinecone官方文档说明**：
  - Pinecone支持`sparse index`，可直接upsert稀疏向量（indices+values），并支持用sparse query进行检索。
  - 用户无需手动维护倒排索引，Pinecone内部自动为稀疏特征建立高效的倒排索引结构，实现高效的关键词/短语检索。
  - 典型用法：
    ```python
    # 创建稀疏索引
    index_description = pc.create_index(
        name="example-sparse",
        metric=Metric.Dotproduct,
        vector_type=VectorType.Sparse,
        spec=ServerlessSpec(
            cloud=CloudProvider.AWS,
            region=AwsRegion.US_WEST_2,
        )
    )
    idx = pc.Index(host=index_description.host)

    # 上传稀疏向量
    idx.upsert(
        namespace='my-namespace',
        vectors=[
            {
                "id": 1,
                "sparse_values": {
                    "indices": [1, 2],
                    "values": [0.2, 0.4]
                }
            },
        ]
    )

    # 检索时直接用sparse query
    idx.query(
        namespace='my-namespace',
        sparse_vector={
            "indices": [1, 2],
            "values": [1.0, 0.5]
        },
        top_k=10
    )
    ```

  - Pinecone自动管理倒排索引，用户只需专注于生成高质量的稀疏特征和query向量。

---

**小结**：  
- 全局词典与短语挖掘为稀疏检索提供基础；
- chunk稀疏特征生成与上传保证了数据的高效可检索性；
- 检索服务接口和未来SparseSearch模块为系统扩展和hybrid检索打下基础；
- Pinecone等现代向量数据库自动完成倒排索引的维护，极大简化了工程实现。

## 3. 主体流程

### 3.1 离线流程（补充：词典生成与管理）

#### 3.1.1 词典生成与管理

- **初始词典构建**  
  - 对所有现有文档进行分词、短语挖掘，统计unigram/bigram/trigram，结合PMI等方法筛选高质量短语，生成全局userdict。
  - 词典为每个token/短语分配唯一id，作为稀疏特征编码的基础。

- **词典增量更新机制**  
  - **场景**：随着新文档的不断加入，原有词典可能无法覆盖新出现的词/短语，需支持词典的动态扩充和增量更新。
  - **流程**：
    1. **新文档分词与短语挖掘**：对新文档单独分词、短语挖掘，统计新出现的高频token/短语。
    2. **与现有userdict对比**：找出userdict中尚未包含的新token/短语。
    3. **增量合并**：为新token/短语分配新的id，合并到全局userdict中，形成新版本词典。
    4. **稀疏特征同步**：对新文档chunk直接用新词典编码；如需保证全局一致性，可考虑对历史chunk做稀疏特征重编码（可选，视业务需求和存储/检索一致性要求）。
    5. **版本管理**：为userdict维护版本号，chunk和query编码时带上词典版本，便于兼容和回溯。

- **用户反馈驱动的词典完善**  
  - **场景**：用户在实际检索中发现召回不全、分词不准、同义词未覆盖等问题。
  - **机制**：
    1. **日志与反馈收集**：记录未召回的query token、用户标注的高频短语、同义词等。
    2. **人工/自动补充**：定期分析日志，人工或自动将高价值token/短语/同义词加入userdict。
    3. **热更新/定期重建**：支持userdict的热更新或定期重建，提升系统召回率和分词准确性。

- **业界常见做法参考**  
  - **分布式倒排索引/词典**：如Elasticsearch、Lucene等，支持动态增量索引和分片扩展。
  - **词典版本化**：如百度、阿里等大规模检索系统，userdict采用版本号管理，支持灰度发布和回滚。
  - **分词一致性保障**：chunk、query、userdict三者分词逻辑完全一致，避免编码不一致导致的召回缺失。
  - **同义词/拼写纠错/用户词典**：结合业务场景，支持同义词映射、拼写纠错、用户自定义词典等机制，提升召回和体验。

---

#### 3.1.2 稀疏特征同步与一致性

- **新chunk编码**：新文档chunk用最新userdict编码稀疏特征。
- **历史chunk兼容**：如需全局一致性，可对历史chunk做稀疏特征重编码（可选，视存储和检索一致性要求）。
- **检索时兼容**：query编码时需指定userdict版本，检索服务需支持多版本兼容或统一切换。

---

#### 3.1.3 词典维护与监控

- **定期分析未召回token**，自动生成补充建议。
- **用户反馈通道**，支持人工补充高频短语、同义词。
- **词典变更日志**，便于追溯和问题定位。

---
**小结**：  
- 词典增量更新和用户反馈驱动的完善，是保证sparse检索长期高召回率和高准确率的关键。
- 业界主流做法是**分词一致性+词典版本化+增量合并+用户反馈补充**，你们的系统完全可以借鉴这些思路。

## 5.示例代码

### 5.1 query稀疏值向量生成与检索

#### 5.1.1 query稀疏向量生成

假设你已经有全局userdict（词→id），并用jieba分词：

  ```python

import jieba

# 假设userdict如下
userdict = {"艾达灵族": 1, "骑乘": 2, "单位": 3, "有": 4}

# 用户query
query = "艾达灵族有多少骑乘单位"

# 分词
tokens = list(jieba.cut(query))  # 例如: ['艾达灵族', '有', '多少', '骑乘', '单位']

# 只保留userdict中有的词
indices = [userdict[token] for token in tokens if token in userdict]
values = [1.0] * len(indices)  # 可以用TF/TF-IDF/BM25等权重

sparse_query = {
    "indices": indices,
    "values": values
}
print(sparse_query)
# 输出: {'indices': [1, 4, 2, 3], 'values': [1.0, 1.0, 1.0, 1.0]}

  ```

#### 5.1.2 Pinecone稀疏检索

  ``` python
from pinecone import Pinecone

pc = Pinecone(api_key="YOUR_API_KEY")
idx = pc.Index("your-sparse-index")

# 稀疏检索
results = idx.query(
    namespace="your-namespace",
    sparse_vector=sparse_query,
    top_k=20
)
for match in results['matches']:
    print(match['id'], match['score'])
  ```

### 5.2 与dense检索结果一起做rerank/MMR

#### 5.2.1 dense检索

  ```python
# 假设你有dense embedding模型
dense_query_vec = embed_model.encode([query])[0]
dense_results = idx.query(
    namespace="your-namespace",
    vector=dense_query_vec,
    top_k=20
)
  ```
#### 5.2.2 hybrid结果合并

  ```python
# 假设sparse_results和dense_results都是Pinecone返回的结果
def merge_hybrid_results(sparse_results, dense_results, alpha=0.5):
    # 先将结果转为dict: id -> score
    sparse_dict = {m['id']: m['score'] for m in sparse_results['matches']}
    dense_dict = {m['id']: m['score'] for m in dense_results['matches']}
    all_ids = set(sparse_dict) | set(dense_dict)
    hybrid = []
    for doc_id in all_ids:
        s_score = sparse_dict.get(doc_id, 0.0)
        d_score = dense_dict.get(doc_id, 0.0)
        final_score = alpha * d_score + (1 - alpha) * s_score
        hybrid.append({"id": doc_id, "score": final_score})
    # 按final_score排序
    hybrid.sort(key=lambda x: x['score'], reverse=True)
    return hybrid

hybrid_results = merge_hybrid_results(sparse_results, dense_results, alpha=0.5)
for item in hybrid_results[:10]:
    print(item['id'], item['score'])

  ```

## 6. 测试方案设计

### 6.1 单元测试

#### 6.1.1 词典生成模块测试

- **测试目标**：验证`dataupload.gen_userdict.py`模块的正确性和稳定性
- **测试用例**：
  - **基础分词测试**：验证jieba分词结果与预期一致
  - **短语挖掘测试**：验证PMI算法能正确识别高质量短语
  - **词典去重测试**：确保userdict中无重复token/短语
  - **ID分配测试**：验证每个token/短语获得唯一ID
  - **过滤规则测试**：验证停用词、标点、HTML标签等过滤效果
  - **边界条件测试**：空文档、单字符文档、超长文档等异常情况

- **测试数据**：

  ```python
  # 测试文档样例
  test_docs = [
      "艾达灵族拥有多种骑乘单位，包括喷气摩托和飞艇。",
      "骑乘单位是艾达灵族的重要军事力量。",
      "喷气摩托速度快，适合快速突击。"
  ]
  
  # 预期userdict部分内容
  expected_tokens = ["艾达灵族", "骑乘", "单位", "喷气摩托", "飞艇"]
  ```

#### 6.1.2 稀疏特征编码测试

- **测试目标**：验证chunk稀疏向量生成的正确性
- **测试用例**：
  - **编码一致性测试**：相同chunk多次编码结果一致
  - **权重计算测试**：验证TF-IDF/BM25权重计算准确性
  - **向量格式测试**：确保生成的稀疏向量符合Pinecone格式要求
  - **词典覆盖测试**：验证userdict中所有token都能正确编码
  - **未知token处理**：测试userdict中不存在的token处理逻辑

- **测试代码示例**：
  ```python

  def test_sparse_encoding():
      chunk = "艾达灵族骑乘单位包括喷气摩托"
      userdict = {"艾达灵族": 1, "骑乘": 2, "单位": 3, "喷气摩托": 4}
      
      sparse_vec = encode_chunk_to_sparse(chunk, userdict)
      
      assert sparse_vec["indices"] == [1, 2, 3, 4]
      assert len(sparse_vec["values"]) == len(sparse_vec["indices"])
      assert all(0 < v <= 1 for v in sparse_vec["values"])
  ```

#### 6.1.3 查询处理模块测试

- **测试目标**：验证在线查询分词和稀疏向量生成的正确性
- **测试用例**：
  - **查询分词测试**：验证query分词结果与chunk分词一致
  - **userdict映射测试**：验证query token能正确映射到userdict ID
  - **稀疏query生成测试**：验证生成的稀疏query向量格式正确
  - **未知token处理**：测试query中userdict未覆盖token的处理
  - **权重计算测试**：验证query token权重计算逻辑

### 6.2 集成测试

#### 6.2.1 端到端检索流程测试

- **测试目标**：验证完整的sparse检索流程
- **测试场景**：
  - **基础检索测试**：验证sparse检索能正确召回相关文档
  - **召回率测试**：验证穷举类query的召回完整性
  - **排序质量测试**：验证检索结果的排序合理性
  - **性能测试**：验证检索响应时间满足要求

- **测试数据设计**：
  ```python
  # 测试文档集（模拟WH40K相关文档）
  test_corpus = [
      "艾达灵族拥有多种骑乘单位，包括喷气摩托、飞艇和悬浮坦克。",
      "喷气摩托是艾达灵族最快速的骑乘单位，适合侦察和快速突击。",
      "飞艇提供空中支援，能够携带重型武器。",
      "悬浮坦克结合了速度和火力，是艾达灵族的主力装备。",
      "艾达灵族的骑乘单位都采用了先进的悬浮技术。"
  ]
  
  # 测试查询
  test_queries = [
      "艾达灵族有多少骑乘单位",  # 穷举类查询
      "喷气摩托的特点",         # 具体单位查询
      "艾达灵族悬浮技术"        # 技术相关查询
  ]
  ```

#### 6.2.2 Hybrid检索融合测试

- **测试目标**：验证sparse和dense检索结果的融合效果
- **测试用例**：
  - **融合算法测试**：验证加权融合公式的正确性
  - **去重逻辑测试**：验证sparse和dense结果去重效果
  - **排序一致性测试**：验证融合后排序的合理性
  - **参数调优测试**：测试不同alpha值对融合效果的影响

- **测试代码示例**：
  ```python
  def test_hybrid_fusion():
      sparse_results = [{"id": "doc1", "score": 0.9}, {"id": "doc2", "score": 0.7}]
      dense_results = [{"id": "doc2", "score": 0.8}, {"id": "doc3", "score": 0.6}]
      
      hybrid_results = merge_hybrid_results(sparse_results, dense_results, alpha=0.5)
      
      # 验证去重和融合
      assert len(hybrid_results) == 3  # doc1, doc2, doc3
      assert hybrid_results[0]["id"] == "doc1"  # 最高分
  ```

#### 6.2.3 Pinecone集成测试

- **测试目标**：验证与Pinecone的集成正确性
- **测试用例**：
  - **数据上传测试**：验证稀疏向量和dense向量正确上传
  - **检索接口测试**：验证sparse检索接口调用正确
  - **结果解析测试**：验证Pinecone返回结果的正确解析
  - **错误处理测试**：验证网络异常、API限制等错误情况的处理

### 6.3 性能测试

#### 6.3.1 检索性能测试

- **测试指标**：
  - **响应时间**：单次检索的响应时间（目标：<100ms）
  - **吞吐量**：每秒能处理的查询数量（目标：>100 QPS）
  - **并发性能**：多并发查询下的性能表现
  - **内存使用**：检索过程中的内存占用情况

- **测试方法**：
  ```python
  import time
  import concurrent.futures
  
  def performance_test():
      queries = generate_test_queries(1000)
      
      # 单线程性能测试
      start_time = time.time()
      for query in queries:
          results = sparse_search(query)
      avg_time = (time.time() - start_time) / len(queries)
      
      # 并发性能测试
      with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
          start_time = time.time()
          futures = [executor.submit(sparse_search, query) for query in queries]
          concurrent.futures.wait(futures)
          total_time = time.time() - start_time
          
      qps = len(queries) / total_time
      print(f"平均响应时间: {avg_time:.3f}s, QPS: {qps:.1f}")
  ```

#### 6.3.2 词典构建性能测试

- **测试指标**：
  - **处理速度**：文档处理速度（MB/s）
  - **内存效率**：大文档集处理时的内存使用
  - **词典大小**：生成的userdict大小对检索性能的影响

#### 6.3.3 数据上传性能测试

- **测试指标**：
  - **上传速度**：批量上传到Pinecone的速度
  - **成功率**：大批量数据上传的成功率
  - **错误恢复**：上传失败时的重试和恢复机制

### 6.4 质量评估测试

#### 6.4.1 召回率评估

- **评估方法**：
  - **人工标注**：对测试查询的期望结果进行人工标注
  - **召回率计算**：`Recall = |相关文档 ∩ 召回文档| / |相关文档|`
  - **穷举类查询专项评估**：重点评估"艾达灵族有多少骑乘单位"等穷举类查询的召回完整性

- **评估指标**：
  ```python
  def calculate_recall(ground_truth, retrieved_docs):
      relevant_retrieved = set(ground_truth) & set(retrieved_docs)
      recall = len(relevant_retrieved) / len(ground_truth)
      return recall
  ```

#### 6.4.2 排序质量评估

- **评估方法**：
  - **相关性评分**：对检索结果进行相关性人工评分（1-5分）
  - **NDCG计算**：计算Normalized Discounted Cumulative Gain
  - **MRR计算**：计算Mean Reciprocal Rank

- **评估代码示例**：
  ```python
  def calculate_ndcg(relevance_scores, k=10):
      dcg = sum(score / np.log2(i + 2) for i, score in enumerate(relevance_scores[:k]))
      ideal_scores = sorted(relevance_scores, reverse=True)
      idcg = sum(score / np.log2(i + 2) for i, score in enumerate(ideal_scores[:k]))
      return dcg / idcg if idcg > 0 else 0
  ```

#### 6.4.3 A/B测试设计

- **测试目标**：对比sparse检索与现有dense检索的效果
- **测试指标**：
  - **用户满意度**：用户对检索结果的满意度评分
  - **答案完整性**：穷举类查询答案的完整性评分
  - **使用频率**：用户对sparse检索功能的使用频率

### 6.5 压力测试与稳定性测试

#### 6.5.1 压力测试

- **测试场景**：
  - **高并发查询**：模拟大量用户同时查询的场景
  - **大数据量测试**：测试大规模文档集下的检索性能
  - **长时间运行测试**：验证系统长时间运行的稳定性

#### 6.5.2 异常情况测试

- **测试场景**：
  - **网络异常**：Pinecone连接中断时的处理
  - **词典损坏**：userdict文件损坏时的恢复机制
  - **内存不足**：系统内存不足时的处理策略
  - **API限制**：Pinecone API调用限制时的处理

### 6.6 测试环境与工具

#### 6.6.1 测试环境配置

- **开发环境**：本地开发测试，使用小规模测试数据
- **测试环境**：独立的测试服务器，使用中等规模测试数据
- **预生产环境**：模拟生产环境配置，使用大规模测试数据

#### 6.6.2 测试工具

- **单元测试**：pytest框架
- **性能测试**：locust、ab等压力测试工具
- **监控工具**：Prometheus + Grafana监控系统性能
- **日志分析**：ELK Stack分析系统日志

#### 6.6.3 自动化测试

- **CI/CD集成**：将测试集成到持续集成流程中
- **自动化回归测试**：每次代码变更后自动运行回归测试
- **性能回归测试**：定期运行性能测试，监控性能变化

---

**小结**：

- 测试方案覆盖了单元测试、集成测试、性能测试、质量评估等各个层面
- 重点关注穷举类查询的召回率提升效果
- 通过A/B测试验证sparse检索相比现有dense检索的改进效果
- 建立完善的自动化测试体系，确保系统质量和稳定性
```

这个测试方案设计涵盖了：

1. **单元测试**：针对各个核心模块的详细测试用例
2. **集成测试**：端到端流程和hybrid融合的测试
3. **性能测试**：响应时间、吞吐量、并发性能等关键指标
4. **质量评估**：召回率、排序质量、用户满意度等评估方法
5. **压力测试**：高并发、大数据量、长时间运行等场景
6. **测试环境**：开发、测试、预生产环境的配置和工具

好的，下面是**7. 配置管理**部分的详细设计，结合你们现有的`config.py`、`searchconfig`模块和业界最佳实践：

---

## 7. 配置管理

### 7.1 词典/短语/停用词配置

- **全局词典（userdict）**  
  - 存储所有分词、短语及其唯一id映射，通常为json或pickle格式，支持版本化管理。
  - 支持人工补充、自动挖掘、同义词归一等多种来源。
  - 路径、加载方式、版本号等可在`config.py`或专用配置文件中统一管理。

- **短语库**  
  - 存储高PMI短语、业务高频短语，支持人工维护和自动挖掘。
  - 可单独配置短语白名单/黑名单，提升分词和召回质量。

- **停用词表**  
  - 存储常见无意义词（如“的”、“了”、“是”等），用于分词和特征过滤。
  - 支持自定义扩展，配置路径在`config.py`或专用配置文件中指定。

---

### 7.2 稀疏特征参数（min_freq、min_pmi、max_vocab_size等）

- **参数说明**  
  - `min_freq`：词/短语出现的最小频率，低于该值不纳入词典。
  - `min_pmi`：短语PMI阈值，控制短语质量。
  - `max_vocab_size`：词典最大容量，防止过大导致检索效率下降。
  - 其他如`max_len`（短语最大长度）、`bm25参数`等。

- **配置方式**  
  - 支持通过`.env`、`config.py`、命令行参数等多种方式配置，便于灵活调整。
  - 推荐将核心参数集中在`config.py`或`searchconfig`模块统一管理，便于全局调用和热更新。

---

### 7.3 Pinecone索引与namespace配置

- **索引名称与namespace**  
  - 支持多环境（dev/test/prod）、多业务线、多索引并行管理。
  - 索引名称、namespace、API key等敏感信息统一在`config.py`或`.env`中配置，避免硬编码。
  - 支持通过环境变量动态切换，便于灰度发布和多租户管理。

- **Pinecone连接参数**  
  - API key、host、region等参数集中管理，支持本地开发和线上部署的无缝切换。
  - 支持代理、SSL证书等高级配置，满足企业级安全需求。

---

### 7.4 分词/短语挖掘/过滤规则配置

- **分词工具与词典**  
  - jieba主词典、用户自定义词典、短语白名单/黑名单路径等集中配置。
  - 支持热加载和动态扩展，提升分词灵活性。

- **短语挖掘参数**  
  - PMI阈值、n-gram范围、最小/最大短语长度等参数可配置。
  - 支持不同业务场景下的参数定制。

- **过滤规则**  
  - 停用词、标点、结构助词、HTML标签等过滤规则集中管理。
  - 支持正则表达式、函数式过滤等多种扩展方式。

---

### 7.5 线上/离线参数热更新机制

- **参数热更新**  
  - 支持通过配置文件、环境变量、远程配置中心等方式动态更新核心参数，无需重启服务。
  - 典型做法：定时检测配置文件变更，自动reload；或通过API触发热更新。

- **词典/短语/停用词热更新**  
  - 支持定期或按需重新加载userdict、短语库、停用词表，保证新词/短语能及时生效。
  - 词典版本号管理，chunk和query编码时带上版本，保证检索一致性。

- **参数变更监控与回滚**  
  - 配置变更自动记录日志，支持回滚到历史版本，提升系统稳定性和可维护性。

- **模块化配置管理**  
  - 通用参数放在`config.py`，特定模块参数放在`searchconfig`等专用模块，便于分层管理和团队协作。

---

**小结：**  
- 配置管理是保障系统灵活性、可维护性和高可用性的基础。
- 推荐采用**集中式+模块化+热更新**的配置管理方案，结合版本控制和变更监控，满足大规模RAG系统的工程需求。
