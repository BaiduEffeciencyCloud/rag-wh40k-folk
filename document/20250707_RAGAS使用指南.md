# RAGAS评估模块使用指南（20250707）

## 1. 快速开始

### 1.1 安装依赖
```bash
# 安装RAGAS相关依赖
pip3 install -r requirements_ragas.txt

# 或者单独安装
pip3 install ragas datasets evaluate
```

### 1.2 准备测试数据
确保你有以下格式的CSV文件：

**查询文件 (queries.csv)**：
```csv
query
"幽冥骑士的阔步巨兽技能如何使用？"
"地形模型对移动有什么影响？"
```

**标准答案文件 (answers.csv)**：
```csv
query,answer
"幽冥骑士的阔步巨兽技能如何使用？","阔步巨兽技能允许单位在移动阶段移动额外的距离..."
"地形模型对移动有什么影响？","地形模型会影响单位的移动距离和移动方式..."
```

### 1.3 运行评估
```bash
# 基本用法
python3 evaltool/ragas_evaluator.py \
    --query test_data/ragas_test_queries.csv \
    --gold test_data/ragas_test_answers.csv

# 自定义参数
python3 evaltool/ragas_evaluator.py \
    --query test_data/ragas_test_queries.csv \
    --gold test_data/ragas_test_answers.csv \
    --top_k 10 \
    --output custom_output_dir
```

---

## 2. 输出结果说明

### 2.1 控制台输出

```
============================================================
RAGAS评估结果摘要
============================================================
context_relevancy: 0.8500
context_recall: 0.7800
faithfulness: 0.9200
answer_relevancy: 0.8800
answer_correctness: 0.8200
answer_completeness: 0.7900
answer_conciseness: 0.8500
报告路径: document/250707/ragas_evaluation_report_250707_143022.md
详情路径: document/250707/dataset_details_250707_143022.json
```

### 2.2 生成文件

- **评估报告**：`document/YYMMDD/ragas_evaluation_report_YYMMDD_HHMMSS.md`
- **数据集详情**：`document/YYMMDD/dataset_details_YYMMDD_HHMMSS.json`

---

## 3. 指标解读

### 3.1 检索指标

#### Context Relevancy（上下文相关性）

- **优秀**：0.8-1.0 ✅
- **良好**：0.6-0.8 ⚠️
- **需要改进**：0.0-0.6 ❌

**优化建议**：

- 提升embedding模型质量
- 调整检索参数（top_k, alpha）
- 使用混合检索策略

#### Context Recall（上下文召回率）
- **优秀**：0.8-1.0 ✅
- **良好**：0.6-0.8 ⚠️
- **需要改进**：0.0-0.6 ❌

**优化建议**：
- 增加检索数量
- 使用查询扩展技术
- 实现多路召回融合

### 3.2 生成指标

#### Faithfulness（忠实度）
- **优秀**：0.8-1.0 ✅
- **良好**：0.6-0.8 ⚠️
- **需要改进**：0.0-0.6 ❌

**优化建议**：
- 优化prompt设计
- 调整生成模型参数
- 增加检索上下文质量

#### Answer Correctness（答案正确性）
- **优秀**：0.8-1.0 ✅
- **良好**：0.6-0.8 ⚠️
- **需要改进**：0.0-0.6 ❌

**优化建议**：
- 提升检索质量
- 改进生成模型
- 实现答案验证机制

---

## 4. 编程接口使用

### 4.1 基本用法
```python
from evaltool.ragas_evaluator import run_ragas_evaluation

# 运行完整评估
result = run_ragas_evaluation(
    query_file='queries.csv',
    gold_file='answers.csv',
    top_k=5,
    output_dir='document/250707'
)

# 查看结果
print(f"Context Relevancy: {result['metrics']['context_relevancy']:.4f}")
print(f"Faithfulness: {result['metrics']['faithfulness']:.4f}")
```

### 4.2 高级用法
```python
from evaltool.ragas_evaluator import RAGASEvaluator
from vector_search import VectorSearch

# 初始化
vector_search = VectorSearch(pinecone_api_key, index_name)
evaluator = RAGASEvaluator(vector_search)

# 准备数据
dataset = evaluator.prepare_dataset(queries, gold_answers, top_k=5)

# 分别评估检索和生成指标
retrieval_results = evaluator.evaluate_retrieval_metrics(dataset)
generation_results = evaluator.evaluate_generation_metrics(dataset)

# 生成详细报告
report_path = evaluator.generate_detailed_report(dataset, results, 'output_dir')
```

---

## 5. 常见问题

### 5.1 安装问题
**Q: 安装RAGAS时出现错误**
```bash
# 解决方案1：升级pip
pip3 install --upgrade pip

# 解决方案2：使用conda
conda install -c conda-forge ragas

# 解决方案3：从源码安装
pip3 install git+https://github.com/explodinggradients/ragas.git
```

### 5.2 数据格式问题
**Q: CSV文件格式不正确**
- 确保查询文件和答案文件的查询顺序一致
- 检查CSV编码格式（推荐UTF-8）
- 验证查询数量与答案数量匹配

### 5.3 评估失败问题
**Q: 评估过程中出现错误**
- 检查网络连接（需要访问OpenAI API）
- 验证Pinecone索引配置
- 查看详细错误日志

---

## 6. 性能优化

### 6.1 批量处理
```python
# 对于大量数据，建议分批处理
batch_size = 50
for i in range(0, len(queries), batch_size):
    batch_queries = queries[i:i+batch_size]
    batch_answers = gold_answers[i:i+batch_size]
    # 处理批次
```

### 6.2 缓存机制
```python
# 启用缓存以减少重复计算
import os
os.environ['RAGAS_CACHE_DIR'] = './cache'
```

### 6.3 并行处理
```python
# 使用多进程加速评估
from multiprocessing import Pool

def evaluate_batch(batch_data):
    # 批次评估逻辑
    pass

with Pool(processes=4) as pool:
    results = pool.map(evaluate_batch, batch_data)
```

---

## 7. 集成到现有评估体系

### 7.1 评估中控台集成
```python
# 在eval_dashboard.py中添加RAGAS模式
if args.mode == 'ragas':
    from ragas_evaluator import run_ragas_evaluation
    result = run_ragas_evaluation(
        query_file=args.csv,
        gold_file=args.gold,
        top_k=args.top_k
    )
```

### 7.2 配置文件集成
```json
// 在evalsearch/evaluator_config.json中添加
{
  "evaluators": {
    "ragas_metrics": {
      "name": "ragas_metrics",
      "description": "RAGAS标准评估指标",
      "requires_gold": true
    }
  }
}
```

---

## 8. 最佳实践

### 8.1 数据准备
- 使用多样化的查询类型
- 确保标准答案质量
- 保持查询和答案的一致性

### 8.2 评估频率
- 定期评估（建议每周或每次重要更新后）
- 保存历史评估结果进行对比
- 建立评估基线

### 8.3 结果分析
- 关注指标趋势变化
- 分析失败案例
- 根据指标指导优化方向

---

## 9. 故障排除

### 9.1 常见错误及解决方案

| 错误类型 | 可能原因 | 解决方案 |
|----------|----------|----------|
| ImportError | RAGAS未安装 | `pip3 install ragas` |
| ValueError | 数据格式错误 | 检查CSV格式和编码 |
| ConnectionError | 网络问题 | 检查网络连接和API密钥 |
| MemoryError | 数据量过大 | 分批处理或增加内存 |

### 9.2 调试模式
```bash
# 启用详细日志
export RAGAS_LOG_LEVEL=DEBUG
python3 evaltool/ragas_evaluator.py --query queries.csv --gold answers.csv
```

---

## 10. 联系支持

如果在使用过程中遇到问题：

1. 查看详细错误日志
2. 检查RAGAS官方文档：https://docs.ragas.io/
3. 提交Issue到项目仓库
4. 联系技术支持团队

---

## 附录

### A. 完整示例脚本
```python
#!/usr/bin/env python3
"""
RAGAS评估完整示例
"""

import os
import sys
sys.path.append('.')

from evaltool.ragas_evaluator import run_ragas_evaluation

def main():
    # 配置参数
    query_file = 'test_data/ragas_test_queries.csv'
    gold_file = 'test_data/ragas_test_answers.csv'
    output_dir = 'document/250707'
    
    # 运行评估
    try:
        result = run_ragas_evaluation(
            query_file=query_file,
            gold_file=gold_file,
            top_k=5,
            output_dir=output_dir
        )
        
        # 输出结果
        print("评估完成！")
        print(f"样本数量: {result['sample_count']}")
        print(f"报告路径: {result['report_path']}")
        
        # 显示关键指标
        metrics = result['metrics']
        print(f"\n关键指标:")
        print(f"Context Relevancy: {metrics['context_relevancy']:.4f}")
        print(f"Faithfulness: {metrics['faithfulness']:.4f}")
        print(f"Answer Correctness: {metrics['answer_correctness']:.4f}")
        
    except Exception as e:
        print(f"评估失败: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()
```

### B. 环境变量配置
```bash
# 在.env文件中添加
OPENAI_API_KEY=your_openai_api_key
PINECONE_API_KEY=your_pinecone_api_key
PINECONE_INDEX=your_index_name
RAGAS_CACHE_DIR=./cache
RAGAS_LOG_LEVEL=INFO
``` 

# RAGAS评估体系设计（20250707）

## 1. 背景与目标

### 1.1 设计目标
- 集成RAGAS（RAG Assessment）开源评估框架到现有RAG评估体系中
- 提供标准化的RAG评估指标，包括检索质量和生成质量
- 支持dense向量检索的专项评估和优化建议

### 1.2 RAGAS优势
- **标准化指标**：提供业界认可的RAG评估指标
- **自动化评估**：基于LLM的自动化评估，减少人工标注成本
- **全面覆盖**：涵盖检索和生成两个核心环节
- **开源免费**：无需额外付费，降低评估成本

---

## 2. RAGAS指标体系

### 2.1 检索阶段指标（Retrieval Metrics）

#### 2.1.1 Context Relevancy（上下文相关性）
- **定义**：检索到的上下文与查询问题的相关程度
- **取值范围**：0-1，越高越好
- **评估方式**：基于LLM判断检索内容是否与问题相关
- **优化方向**：提升embedding质量、调整检索参数

#### 2.1.2 Context Recall（上下文召回率）
- **定义**：检索结果中包含正确答案相关信息的比例
- **取值范围**：0-1，越高越好
- **评估方式**：基于标准答案判断检索覆盖度
- **优化方向**：增加检索数量、使用查询扩展

### 2.2 生成阶段指标（Generation Metrics）

#### 2.2.1 Faithfulness（忠实度）
- **定义**：生成答案对检索内容的忠实程度
- **取值范围**：0-1，越高越好
- **评估方式**：判断生成内容是否基于检索信息
- **优化方向**：优化prompt设计、调整生成参数

#### 2.2.2 Answer Relevancy（答案相关性）
- **定义**：生成答案与查询问题的相关程度
- **取值范围**：0-1，越高越好
- **评估方式**：基于LLM判断答案是否回答原问题
- **优化方向**：改进生成策略、提升检索质量

#### 2.2.3 Answer Correctness（答案正确性）
- **定义**：生成答案的事实准确性
- **取值范围**：0-1，越高越好
- **评估方式**：与标准答案对比判断正确性
- **优化方向**：提升检索质量、改进生成模型

#### 2.2.4 Answer Completeness（答案完整性）
- **定义**：生成答案对问题的完整回答程度
- **取值范围**：0-1，越高越好
- **评估方式**：判断是否完整回答了问题的各个方面
- **优化方向**：增加检索覆盖、优化生成策略

#### 2.2.5 Answer Conciseness（答案简洁性）
- **定义**：生成答案的简洁程度，避免冗余信息
- **取值范围**：0-1，越高越好
- **评估方式**：判断答案是否简洁明了
- **优化方向**：优化prompt、调整生成参数

---

## 3. 集成方案设计

### 3.1 模块架构

```
evaltool/
├── ragas_evaluator.py          # RAGAS评估器主模块
├── evalsearch/                 # 现有评估体系
│   ├── main.py
│   ├── metrics.py
│   └── ...
└── eval_dashboard.py           # 评估中控台（扩展支持RAGAS）
```

### 3.2 数据流程

```
输入数据 → RAGAS评估器 → 向量检索 → 答案生成 → 指标计算 → 报告生成
   ↓           ↓           ↓         ↓         ↓         ↓
CSV文件   数据集准备    Pinecone    OpenAI    RAGAS     Markdown
```

### 3.3 接口设计

#### 3.3.1 命令行接口
```bash
# 基本用法
python3 evaltool/ragas_evaluator.py --query queries.csv --gold answers.csv

# 高级用法
python3 evaltool/ragas_evaluator.py \
    --query queries.csv \
    --gold answers.csv \
    --top_k 10 \
    --output custom_output_dir
```

#### 3.3.2 编程接口
```python
from evaltool.ragas_evaluator import run_ragas_evaluation

result = run_ragas_evaluation(
    query_file='queries.csv',
    gold_file='answers.csv',
    top_k=5,
    output_dir='document/250707'
)
```

### 3.4 数据格式要求

#### 3.4.1 输入CSV格式
```csv
# queries.csv
query
"幽冥骑士的阔步巨兽技能如何使用？"
"地形模型对移动有什么影响？"
"冲锋技能会造成多少伤害？"

# answers.csv
query,answer
"幽冥骑士的阔步巨兽技能如何使用？","阔步巨兽技能允许单位在移动阶段..."
"地形模型对移动有什么影响？","地形模型会影响单位的移动距离..."
"冲锋技能会造成多少伤害？","冲锋技能在近战阶段提供额外攻击..."
```

#### 3.4.2 输出格式
```json
{
    "metrics": {
        "context_relevancy": 0.85,
        "context_recall": 0.78,
        "faithfulness": 0.92,
        "answer_relevancy": 0.88,
        "answer_correctness": 0.82,
        "answer_completeness": 0.79,
        "answer_conciseness": 0.85
    },
    "report_path": "document/250707/ragas_evaluation_report_250707_143022.md",
    "details_path": "document/250707/dataset_details_250707_143022.json",
    "sample_count": 20,
    "evaluation_time": "2025-07-07T14:30:22"
}
```

---

## 4. 评估流程设计

### 4.1 评估步骤

1. **数据加载与验证**
   - 加载查询文件和标准答案文件
   - 验证数据格式和数量匹配
   - 数据预处理和清洗

2. **向量检索执行**
   - 对每个查询执行dense向量检索
   - 获取top-k检索结果
   - 提取检索上下文

3. **答案生成**
   - 基于检索上下文生成答案
   - 使用semantic_parse方法
   - 处理异常情况

4. **RAGAS指标计算**
   - 准备RAGAS格式数据集
   - 执行各项指标评估
   - 收集评估结果

5. **报告生成**
   - 生成详细评估报告
   - 提供优化建议
   - 保存数据集详情

### 4.2 异常处理

- **检索失败**：记录错误，使用空上下文
- **生成失败**：使用默认答案，标记为失败
- **指标计算失败**：跳过该指标，记录错误
- **数据格式错误**：提供详细错误信息

---

## 5. 优化建议体系

### 5.1 基于指标的优化建议

#### 5.1.1 Context Relevancy < 0.7
```
优化建议：
1. 提升检索质量
   - 优化embedding模型（考虑使用更先进的模型）
   - 调整检索参数（top_k, alpha等）
   - 考虑使用混合检索策略（dense + sparse）
   - 优化文档分块策略

2. 改进查询处理
   - 使用查询扩展技术
   - 实现查询重写
   - 添加同义词处理
```

#### 5.1.2 Context Recall < 0.7
```
优化建议：
1. 提升召回率
   - 增加检索数量（top_k）
   - 使用查询扩展技术
   - 考虑多路召回融合
   - 实现查询变体生成

2. 改进检索策略
   - 使用混合检索（dense + sparse + keyword）
   - 实现分层检索
   - 添加实体识别和过滤
```

#### 5.1.3 Faithfulness < 0.7
```
优化建议：
1. 提升生成质量
   - 优化prompt设计
   - 调整生成模型参数
   - 增加检索上下文质量
   - 实现答案验证机制

2. 改进生成策略
   - 使用更严格的生成约束
   - 实现答案溯源
   - 添加事实检查
```

### 5.2 综合优化策略

#### 5.2.1 检索优化
- **模型升级**：使用更先进的embedding模型
- **参数调优**：系统化调整检索参数
- **策略融合**：实现多路检索融合
- **查询优化**：实现智能查询处理

#### 5.2.2 生成优化
- **Prompt工程**：优化prompt设计
- **模型选择**：选择更适合的生成模型
- **质量控制**：实现答案质量检查
- **迭代优化**：基于评估结果持续改进

---

## 6. 与现有评估体系集成

### 6.1 评估中控台扩展

在`eval_dashboard.py`中添加RAGAS模式：

```python
def main():
    parser.add_argument('--mode', choices=['embedding', 'answer', 'dict', 'ragas'], 
                       required=True, help='评估模式')
    
    if args.mode == 'ragas':
        from ragas_evaluator import run_ragas_evaluation
        result = run_ragas_evaluation(
            query_file=args.csv,
            gold_file=args.gold,
            top_k=args.top_k
        )
```

### 6.2 评估配置扩展

在`evalsearch/evaluator_config.json`中添加RAGAS配置：

```json
{
  "evaluators": {
    "ragas_metrics": {
      "name": "ragas_metrics",
      "description": "RAGAS标准评估指标",
      "requires_gold": true,
      "conditions": {
        "requires_gold_file": true
      },
      "visualization": {
        "type": "metrics_table",
        "output_file": "ragas_metrics.png",
        "title": "RAGAS评估指标"
      }
    }
  }
}
```

### 6.3 报告集成

- RAGAS评估结果自动归档到`document/YYMMDD/`目录
- 生成时间戳命名的报告文件
- 支持PDF报告生成和LLM解读

---

## 7. 使用示例

### 7.1 基本评估
```bash
# 安装依赖
pip3 install ragas datasets

# 运行评估
python3 evaltool/ragas_evaluator.py \
    --query test_data/queries.csv \
    --gold test_data/answers.csv
```

### 7.2 自定义参数评估
```bash
python3 evaltool/ragas_evaluator.py \
    --query test_data/queries.csv \
    --gold test_data/answers.csv \
    --top_k 10 \
    --output custom_output
```

### 7.3 编程调用
```python
from evaltool.ragas_evaluator import RAGASEvaluator
from vector_search import VectorSearch

# 初始化
vector_search = VectorSearch(pinecone_api_key, index_name)
evaluator = RAGASEvaluator(vector_search)

# 准备数据
dataset = evaluator.prepare_dataset(queries, gold_answers, top_k=5)

# 执行评估
results = evaluator.evaluate_all_metrics(dataset)

# 生成报告
report_path = evaluator.generate_detailed_report(dataset, results, 'output_dir')
```

---

## 8. 成本与性能考量

### 8.1 计算成本
- **RAGAS评估**：每个样本约需要2-3次LLM调用
- **向量检索**：每个查询1次embedding + 1次检索
- **答案生成**：每个查询1次LLM调用

### 8.2 时间成本
- **20个样本**：约5-10分钟
- **100个样本**：约20-30分钟
- **批量处理**：支持并行处理提升效率

### 8.3 优化建议
- **缓存机制**：缓存embedding和检索结果
- **批量处理**：批量执行LLM调用
- **异步处理**：使用异步处理提升效率
- **增量评估**：支持增量评估减少重复计算

---

## 9. 未来扩展

### 9.1 自定义指标
- 支持添加自定义评估指标
- 实现特定业务场景的评估需求
- 支持指标权重调整

### 9.2 多模态评估
- 支持图像、音频等多模态内容评估
- 实现跨模态检索质量评估
- 支持多模态生成质量评估

### 9.3 实时评估
- 支持实时RAG系统评估
- 实现在线质量监控
- 支持A/B测试评估

---

## 10. 总结

RAGAS评估体系的集成为我们的RAG系统提供了：

1. **标准化评估**：使用业界认可的评估指标
2. **全面覆盖**：涵盖检索和生成两个核心环节
3. **自动化评估**：减少人工标注成本
4. **详细分析**：提供具体的优化建议
5. **易于集成**：与现有评估体系无缝集成

通过RAGAS评估，我们可以：
- 量化RAG系统的性能瓶颈
- 指导系统优化方向
- 监控系统改进效果
- 提供客观的评估报告

这将显著提升我们的RAG系统评估能力和优化效率。 