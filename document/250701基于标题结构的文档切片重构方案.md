# 基于标题结构的文档切片重构方案

## 重构背景

当前`data_vector_v3.py`中的文档切片逻辑存在跨section合并的问题，导致层级信息混乱。通过分析发现，问题的根源在于chunk优化阶段缺乏对文档标题结构的严格对照。

## 重构目标

在保持现有切片和处理逻辑不变的前提下，引入标题结构抽取和对照机制，确保：
1. 文档标题结构作为切片的大纲指导
2. 正文内容正确归属到对应标题层级
3. 完全禁止跨标题的chunk合并

## 重构方案设计

### 1. 整体架构调整

#### 当前架构
```
文档内容 → _split_headings() → chunk_text() → optimize_chunks() → 最终结果
```

#### 重构后架构
```
文档内容 → extract_document_structure() → _split_headings() → chunk_text() → optimize_chunks() → 最终结果
                ↓
            标题结构大纲
                ↓
            对照检查机制
```

### 2. 核心组件设计

#### 2.1 文档结构抽取器 (DocumentStructureExtractor)

```python
class DocumentStructureExtractor:
    """文档标题结构抽取器"""
    
    def __init__(self):
        self.title_stack = ["" for _ in range(6)]
        self.sections = []
        self.hierarchy_map = {}  # 标题到层级的映射
    
    def extract_structure(self, text: str) -> Dict[str, Any]:
        """
        抽取文档的标题结构
        
        Returns:
            {
                'sections': [
                    {
                        'title': '军队规则',
                        'level': 1,
                        'hierarchy': {'level1': '军队规则'},
                        'content_type': 'army_rule',
                        'start_line': 1,
                        'end_line': 27
                    },
                    ...
                ],
                'hierarchy_map': {
                    '军队规则': {'level1': '军队规则'},
                    '殊途同归 DISPARATE PATHS': {
                        'level1': '军队规则', 
                        'level2': '殊途同归 DISPARATE PATHS'
                    },
                    ...
                }
            }
        """
        pass
    
    def validate_section_boundary(self, section_heading: str, content: str) -> bool:
        """验证section边界是否正确"""
        pass
    
    def get_section_hierarchy(self, section_heading: str) -> Dict[str, str]:
        """获取指定section的层级信息"""
        pass
```

#### 2.2 结构对照检查器 (StructureValidator)

```python
class StructureValidator:
    """结构对照检查器"""
    
    def __init__(self, document_structure: Dict[str, Any]):
        self.document_structure = document_structure
        self.hierarchy_map = document_structure['hierarchy_map']
    
    def validate_chunk_hierarchy(self, chunk: Dict[str, Any]) -> bool:
        """
        验证chunk的层级信息是否正确
        
        Args:
            chunk: 待验证的chunk
            
        Returns:
            bool: 层级信息是否正确
        """
        section_heading = chunk.get('section_heading', '')
        chunk_hierarchy = chunk.get('hierarchy', {})
        
        # 从文档结构中获取正确的层级信息
        expected_hierarchy = self.hierarchy_map.get(section_heading, {})
        
        return chunk_hierarchy == expected_hierarchy
    
    def can_merge_chunks(self, chunk1: Dict[str, Any], chunk2: Dict[str, Any]) -> bool:
        """
        判断两个chunks是否可以合并
        
        Args:
            chunk1: 第一个chunk
            chunk2: 第二个chunk
            
        Returns:
            bool: 是否可以合并
        """
        # 检查是否属于同一个顶级section
        level1_1 = chunk1.get('hierarchy', {}).get('level1', '')
        level1_2 = chunk2.get('hierarchy', {}).get('level1', '')
        
        if level1_1 != level1_2:
            return False
        
        # 检查section_heading是否相同
        heading1 = chunk1.get('section_heading', '')
        heading2 = chunk2.get('section_heading', '')
        
        return heading1 == heading2
```

### 3. 重构后的SemanticDocumentChunker

```python
class SemanticDocumentChunker:
    """重构后的语义文档切片器"""
    
    def __init__(self, ...):
        # 保持现有初始化逻辑
        self.structure_extractor = DocumentStructureExtractor()
        self.structure_validator = None
        self.document_structure = None
    
    def chunk_text(self, text: str, extra_metadata: Optional[Dict[str, Any]] = None) -> List[Dict[str, Any]]:
        """
        主方法：基于标题结构的文档切片
        
        Args:
            text: 输入文本
            extra_metadata: 额外的元数据
            
        Returns:
            List of chunk dicts with semantic metadata
        """
        # 步骤1：抽取文档标题结构
        self.document_structure = self.structure_extractor.extract_structure(text)
        self.structure_validator = StructureValidator(self.document_structure)
        
        # 步骤2：保持现有的section分割逻辑
        sections = self._split_headings(text)
        
        # 步骤3：生成chunks（保持现有逻辑）
        chunks = []
        for section in sections:
            # 保持现有的chunk生成逻辑
            section_chunks = self._process_section(section, extra_metadata)
            
            # 新增：验证chunk的层级信息
            for chunk in section_chunks:
                if not self.structure_validator.validate_chunk_hierarchy(chunk):
                    # 记录警告或错误
                    print(f"Warning: Invalid hierarchy for chunk with heading: {chunk.get('section_heading')}")
            
            chunks.extend(section_chunks)
        
        return chunks
    
    def optimize_chunks(self, chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        优化chunks（重构后的版本）
        
        Args:
            chunks: 待优化的chunks
            
        Returns:
            优化后的chunks
        """
        optimized_chunks = []
        
        for chunk in chunks:
            # 保持现有的token计算逻辑
            text = chunk['text']
            token_count = self._count_tokens(text)
            
            # 如果chunk太小，尝试与下一个chunk合并
            if token_count < self.max_tokens * 0.3 and len(optimized_chunks) > 0:
                last_chunk = optimized_chunks[-1]
                
                # 新增：使用结构验证器判断是否可以合并
                if self.structure_validator.can_merge_chunks(last_chunk, chunk):
                    # 保持现有的合并逻辑
                    combined_text = last_chunk['text'] + '\n\n' + text
                    combined_tokens = self._count_tokens(combined_text)
                    
                    if combined_tokens <= self.max_tokens:
                        # 保持现有的合并逻辑
                        last_chunk['text'] = combined_text
                        last_chunk['token_count'] = combined_tokens
                        last_chunk['sentence_count'] += chunk['sentence_count']
                        
                        # 更新层级信息（保持现有逻辑）
                        if chunk.get('hierarchy') and last_chunk.get('hierarchy'):
                            # 保持现有的层级更新逻辑
                            pass
                        
                        # 重新评估语义连贯性
                        coherence_metrics = self._assess_semantic_coherence(combined_text)
                        last_chunk.update(coherence_metrics)
                        continue
            
            # 保持现有的chunk处理逻辑
            if token_count > self.max_tokens * 1.2:
                sub_chunks = self._split_large_chunk(chunk)
                optimized_chunks.extend(sub_chunks)
            else:
                optimized_chunks.append(chunk)
        
        return optimized_chunks
```

## 重构优势

### 1. 保持向后兼容
- **现有API不变**：所有公共方法保持相同的接口
- **现有逻辑保留**：section分割、chunk生成、优化逻辑基本不变
- **现有配置兼容**：初始化参数和处理参数保持不变

### 2. 增强结构保证
- **标题结构指导**：文档标题结构作为切片的大纲指导
- **层级信息验证**：每个chunk的层级信息都经过验证
- **跨section保护**：完全禁止跨标题的chunk合并

### 3. 提高可维护性
- **结构清晰**：标题结构抽取和验证逻辑独立
- **错误检测**：能够检测和报告层级信息错误
- **调试友好**：提供详细的验证和警告信息

## 实施步骤

### 阶段1：添加结构抽取器
1. 实现`DocumentStructureExtractor`类
2. 在`SemanticDocumentChunker`中集成结构抽取
3. 测试结构抽取的准确性

### 阶段2：添加验证器
1. 实现`StructureValidator`类
2. 在chunk生成过程中添加验证
3. 测试验证逻辑的正确性

### 阶段3：重构优化逻辑
1. 在`optimize_chunks`中使用验证器
2. 确保跨section合并被完全禁止
3. 测试优化后的效果

### 阶段4：全面测试
1. 对比重构前后的切片结果
2. 验证层级信息的正确性
3. 确保性能没有显著下降

## 风险控制

### 1. 性能影响
- **增量计算**：结构抽取只在文档处理开始时执行一次
- **缓存机制**：抽取的结构信息可以缓存复用
- **性能监控**：添加性能指标监控

### 2. 兼容性保证
- **渐进式重构**：可以分阶段实施，每个阶段都可以回滚
- **配置开关**：可以添加开关控制是否启用新功能
- **向后兼容**：确保现有代码无需修改

### 3. 错误处理
- **优雅降级**：如果结构抽取失败，回退到原有逻辑
- **详细日志**：记录所有验证和警告信息
- **错误恢复**：提供错误恢复机制

## 总结

这个重构方案的核心思想是**在保持现有逻辑不变的前提下，引入标题结构抽取和对照机制**。通过这种方式，我们可以：

1. **保证现有功能不受影响**：所有现有的切片和处理逻辑都保持不变
2. **增强结构保证**：通过标题结构指导，确保内容归属正确
3. **提高可维护性**：结构抽取和验证逻辑独立，便于维护和调试
4. **渐进式实施**：可以分阶段实施，降低风险

这种方案既解决了当前的跨section合并问题，又为后续的功能扩展提供了良好的基础。 