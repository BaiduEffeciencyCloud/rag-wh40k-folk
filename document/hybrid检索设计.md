# 250703-BM25_hybridæ£€ç´¢è®¾è®¡æ–‡æ¡£ï¼ˆè¡¥ä¸å¼ä¿®è®¢ç‰ˆï¼‰

## 1. é¡¹ç›®ç›®æ ‡ä¸èŒƒå›´

ï¼ˆåŒå‰ï¼Œç•¥ï¼‰

---

## 2. ç³»ç»Ÿæ¶æ„ä¸æ•°æ®æµ



## 3. BM25Managerè®¾è®¡ä¸å®ç°

### 3.1 ç±»ç»“æ„
```python
class BM25Manager:
    def __init__(self, k1=1.5, b=0.75, min_freq=5, max_vocab_size=10000, custom_dict_path=None):
        self.k1 = k1
        self.b = b
        self.min_freq = min_freq
        self.max_vocab_size = max_vocab_size
        self.bm25_model = None
        self.vocabulary = {}
        self.corpus_tokens = []
        self.raw_texts = []  # æ–°å¢ï¼šåŸå§‹æ–‡æœ¬åˆ—è¡¨
        self.is_fitted = False
        if custom_dict_path and os.path.exists(custom_dict_path):
            jieba.load_userdict(custom_dict_path)
    def tokenize_chinese(self, text): ...
    def fit(self, corpus_texts): ...
    def incremental_update(self, new_corpus_texts): ...
    def get_sparse_vector(self, text): ...
    def save_model(self, model_path, vocab_path): ...
    def load_model(self, model_path, vocab_path): ...
    def get_vocabulary_stats(self): ...
```

### 3.2 è¯æ±‡è¡¨å‰ªæä¸å¢é‡æ›´æ–°ï¼ˆä¿®æ­£ï¼‰
- **å‰ªæ**ï¼šä»…ä¿ç•™å‡ºç°é¢‘ç‡å¤§äº`min_freq`çš„å‰`max_vocab_size`é«˜é¢‘è¯
- **å¢é‡æ›´æ–°**ï¼šç»´æŠ¤`self.raw_texts`ï¼Œæ¯æ¬¡`fit`/`incremental_update`éƒ½ç”¨**åŸå§‹æ–‡æœ¬åˆ—è¡¨**é‡å»ºè¯è¡¨ï¼Œé¿å…tokenå½“æ–‡æ¡£çš„bug

def fit(self, corpus_texts):
    self.raw_texts = list(corpus_texts)
    self.corpus_tokens = [self.tokenize_chinese(text) for text in self.raw_texts]
    self._build_vocabulary(self.raw_texts)
    self.bm25_model = BM25Okapi(self.corpus_tokens, k1=self.k1, b=self.b)
    self.is_fitted = True

def incremental_update(self, new_corpus_texts):
    self.raw_texts.extend(new_corpus_texts)

### 3.3 BM25æƒé‡è®¡ç®—ï¼ˆå®Œæ•´å…¬å¼ï¼Œå«k1ã€bã€å½’ä¸€åŒ–ï¼‰
def get_sparse_vector(self, text: str) -> Dict[str, Any]:
    tokens = self.tokenize_chinese(text)
    indices, values = [], []
    avgdl = self.bm25_model.avgdl
    k1, b = self.bm25_model.k1, self.bm25_model.b
    dl = len(tokens)
    token_freq = {}
    for token in tokens:
        token_freq[token] = token_freq.get(token, 0) + 1
    for token, freq in token_freq.items():
        if token in self.vocabulary:
            idf = self.bm25_model.idf.get(token, 0)
            tf = freq
            denom = tf + k1 * (1 - b + b * dl / avgdl)
            weight = idf * (tf * (k1 + 1)) / denom if denom > 0 else 0
            if weight > 0:
                indices.append(self.vocabulary[token])
                values.append(float(weight))
    return {"indices": indices, "values": values}


## 4. Hybridèåˆä¸æ£€ç´¢

### 4.1 hybrid_scaleæ–¹æ³•ï¼ˆè¡¥å……å®ç°ï¼‰
def hybrid_scale(self, dense, sparse, alpha):
    hdense = [v * alpha for v in dense]
    hsparse = {
        "indices": sparse["indices"],
        "values": [v * (1 - alpha) for v in sparse["values"]]
    }
    return hdense, hsparse
- æ£€ç´¢æ—¶ï¼š`hdense, hsparse = self.hybrid_scale(query_dense, query_sparse, alpha)`


## 5. é…ç½®ä¸å¯¼å…¥è§„èŒƒ

### 5.1 config.pyï¼ˆè¡¥å……/ä¿®æ­£ï¼‰
BM25_K1 = float(os.getenv('BM25_K1', '1.5'))
BM25_B = float(os.getenv('BM25_B', '0.75'))
BM25_MIN_FREQ = int(os.getenv('BM25_MIN_FREQ', '5'))
BM25_MAX_VOCAB_SIZE = int(os.getenv('BM25_MAX_VOCAB_SIZE', '10000'))
BM25_CUSTOM_DICT_PATH = os.getenv('BM25_CUSTOM_DICT_PATH', 'dicts/warhammer40k.txt')
BM25_MODEL_PATH = os.getenv('BM25_MODEL_PATH', 'models/bm25_model.pkl')
BM25_VOCAB_PATH = os.getenv('BM25_VOCAB_PATH', 'models/bm25_vocab.json')
PINECONE_SPARSE_DIMENSION = int(os.getenv('PINECONE_SPARSE_DIMENSION', '10000'))
PINECONE_API_KEY = os.getenv('PINECONE_API_KEY')
PINECONE_INDEX = os.getenv('PINECONE_INDEX')
- **æ‰€æœ‰ç´¢å¼•åˆ›å»ºã€upsertã€queryç­‰å‡åº”å¼•ç”¨é…ç½®å˜é‡ï¼Œä¸åº”ç¡¬ç¼–ç ã€‚**

### 5.2 å¯¼å…¥è·¯å¾„è§„èŒƒ
- ç»Ÿä¸€ç”¨ç»å¯¹è·¯å¾„ï¼šå¦‚`from DATAUPLOD.bm25_manager import BM25Manager`
- æµ‹è¯•è„šæœ¬åŠ `sys.path`ï¼Œä¿è¯å¯å¯¼å…¥


## 6. æµ‹è¯•ä¸éªŒè¯ï¼ˆè¡¥å……ï¼‰

### 6.1 æµ‹è¯•ç”¨ä¾‹
- ç¨€ç–å‘é‡æ­£ç¡®æ€§ï¼ˆindices/valuesé•¿åº¦ã€æ­£å€¼ã€ç´¢å¼•èŒƒå›´ï¼‰
- é”™è¯¯å¤„ç†ï¼ˆæœªè®­ç»ƒã€ç©ºè¯­æ–™ã€é…ç½®è¾¹ç•Œï¼‰
- å¢é‡æ›´æ–°ï¼ˆè¯è¡¨å¤§å°å˜åŒ–ã€æ–°è¯æ±‡æ·»åŠ ï¼‰
- hybrid_scaleèåˆæ­£ç¡®æ€§
- Pinecone upsert/queryå¼‚å¸¸æ•è·

### 6.2 ç¤ºä¾‹æµ‹è¯•è„šæœ¬ç‰‡æ®µ
def test_hybrid_scale():
    dense = [1.0, 2.0, 3.0]
    sparse = {"indices": [0, 2], "values": [0.5, 1.5]}
    alpha = 0.3
    hdense, hsparse = hybrid_scale(dense, sparse, alpha)
    assert all(abs(v - d * alpha) < 1e-6 for v, d in zip(hdense, dense))
    assert all(abs(v - s * (1 - alpha)) < 1e-6 for v, s in zip(hsparse["values"], sparse["values"]))


## 7. å¯é€‰ï¼šäºŒé˜¶æ®µRerankè®¾è®¡ï¼ˆè¡¥å……ï¼‰

### 7.1 æ–¹æ¡ˆè¯´æ˜
- åœ¨Hybridæ£€ç´¢top-kç»“æœåŸºç¡€ä¸Šï¼Œä½¿ç”¨Cross-Encoderæ¨¡å‹ï¼ˆå¦‚`cross-encoder/ms-marco-MiniLM-L-6-v2`ï¼‰å¯¹query-æ–‡æ¡£å¯¹è¿›è¡ŒäºŒæ¬¡æ’åºï¼Œæå‡æœ€ç»ˆç›¸å…³æ€§ã€‚

### 7.2 ä¼ªä»£ç 
from sentence_transformers import CrossEncoder
reranker = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')
rerank_scores = reranker.predict([[query, doc] for doc in topk_docs])
# æŒ‰rerank_scoresé‡æ–°æ’åºtopk_docs
- æ–‡æ¡£å¯è¡¥å……"å¯é€‰Rerankæµç¨‹"è¯´æ˜ï¼Œä¾¿äºåç»­æ‰©å±•ã€‚


## 8. ç›‘æ§ä¸ä¼˜åŒ–å»ºè®®



## 9. é£é™©ä¸æ³¨æ„äº‹é¡¹



## 10. æ€»ç»“

æœ¬è¡¥ä¸å¼ä¿®è®¢ç‰ˆåœ¨ç²¾ç‚¼ç»“æ„åŸºç¡€ä¸Šï¼Œ**è¡¥å……äº†BM25å…¬å¼ã€è¯è¡¨é‡å»ºã€hybrid_scaleã€é…ç½®å¼•ç”¨ã€æµ‹è¯•ã€Rerankç­‰å·¥ç¨‹å…³é”®ç»†èŠ‚**ï¼Œç¡®ä¿è®¾è®¡ä¸å®ç°å®Œå…¨å¯¹é½ï¼Œé€‚ç”¨äºé«˜è´¨é‡ä¸­æ–‡RAGç³»ç»Ÿçš„å·¥ç¨‹è½åœ°ã€‚


**å¦‚éœ€è¿›ä¸€æ­¥ç»†åŒ–æŸä¸€éƒ¨åˆ†æˆ–è¡¥å……ä»£ç å®ç°ç»†èŠ‚ï¼Œè¯·éšæ—¶å‘ŠçŸ¥ï¼**


ä½ å¯ä»¥å°†ä»¥ä¸Šå†…å®¹ä¿å­˜ä¸º `250703-BM25_hybridæ£€ç´¢è®¾è®¡æ–‡æ¡£.md`ï¼Œå¦‚éœ€åˆ†ç« èŠ‚ä¸‹è½½æˆ–æ‹†åˆ†ä¸ºå¤šæ–‡ä»¶ï¼Œä¹Ÿå¯å‘ŠçŸ¥ï¼


# 250703-hybridæ£€ç´¢è®¾è®¡æ–‡æ¡£

## 1. é¡¹ç›®æ¦‚è¿°

### 1.1 ç›®æ ‡
åœ¨ç°æœ‰çš„RAGç³»ç»Ÿä¸­é›†æˆBM25 sparse embeddingï¼Œå®ç°å®Œæ•´çš„hybridæ£€ç´¢åŠŸèƒ½ï¼Œæå‡æˆ˜é”¤40Kè§„åˆ™æ£€ç´¢çš„å¬å›ç‡å’Œå‡†ç¡®æ€§ã€‚

### 1.2 å®æ–½èŒƒå›´
- **æ•°æ®ä¸Šä¼ ç«¯**ï¼šä¿®æ”¹`DATAUPLOD/upsert.py`ï¼Œæ”¯æŒBM25 sparseå‘é‡ç”Ÿæˆå’Œä¸Šä¼ 
- **æ£€ç´¢ç«¯**ï¼šä¿®æ”¹`vector_search.py`ï¼Œæ”¯æŒBM25 sparseå‘é‡æ£€ç´¢
- **é…ç½®ç®¡ç†**ï¼šç»Ÿä¸€BM25å‚æ•°é…ç½®å’Œè¯æ±‡è¡¨ç®¡ç†
- **Pineconeç´¢å¼•**ï¼šåˆ›å»ºæ”¯æŒsparseå‘é‡çš„ç´¢å¼•é…ç½®

### 1.3 æŠ€æœ¯æ ˆ
- **BM25å®ç°**ï¼š`rank_bm25`åº“
- **ä¸­æ–‡åˆ†è¯**ï¼š`jieba`åº“ï¼ˆæ”¯æŒè‡ªå®šä¹‰è¯å…¸ï¼‰
- **å‘é‡å­˜å‚¨**ï¼šPineconeï¼ˆmetric=dotproductï¼Œæ”¯æŒsparseå‘é‡ï¼‰
- **é…ç½®ç®¡ç†**ï¼š`config.py` + `.env`

### 1.4 å…³é”®ä¿®æ­£ç‚¹
åŸºäºChatGPTçš„ä¸“ä¸šå»ºè®®ï¼Œæœ¬è®¾è®¡æ–‡æ¡£å·²ä¿®æ­£ä»¥ä¸‹å…³é”®é—®é¢˜ï¼š
- **BM25å‘é‡åŒ–é€»è¾‘**ï¼šä¿®æ­£tokenæƒé‡è®¡ç®—æ–¹å¼
- **è¯æ±‡è¡¨å‰ªæ**ï¼šæ·»åŠ é¢‘ç‡é˜ˆå€¼å’Œå¤§å°é™åˆ¶
- **é¢†åŸŸè¯å…¸**ï¼šæ”¯æŒæˆ˜é”¤40Kä¸“æœ‰åè¯ä¼˜åŒ–
- **å¢é‡æ›´æ–°**ï¼šæ”¯æŒæ¨¡å‹å’Œè¯æ±‡è¡¨çš„å¢é‡æ›´æ–°
- **Pineconeé…ç½®**ï¼šæ˜ç¡®sparseå‘é‡ç´¢å¼•åˆ›å»ºè¦æ±‚

## 2. ç³»ç»Ÿæ¶æ„è®¾è®¡

### 2.1 æ•´ä½“æ¶æ„
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   æ–‡æ¡£è¾“å…¥      â”‚    â”‚   åˆ‡ç‰‡å¤„ç†      â”‚    â”‚   å‘é‡ç”Ÿæˆ      â”‚
â”‚   (Markdown)    â”‚â”€â”€â”€â–¶â”‚   (Chunker)     â”‚â”€â”€â”€â–¶â”‚  Dense + Sparse â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                       â”‚
â”‚   æ£€ç´¢æŸ¥è¯¢      â”‚    â”‚   æŸ¥è¯¢å¤„ç†      â”‚    â”‚   æ··åˆæ£€ç´¢      â”‚
â”‚   (User Query)  â”‚â—€â”€â”€â”€â”‚   (Query Proc)  â”‚â—€â”€â”€â”€â”‚  Hybrid Search  â”‚

### 2.2 æ•°æ®æµè®¾è®¡
ä¸Šä¼ æµç¨‹ï¼š
æ–‡æ¡£ â†’ åˆ‡ç‰‡ â†’ é¢†åŸŸè¯å…¸åˆ†è¯ â†’ BM25è¯æ±‡è¡¨æ„å»º(å‰ªæ) â†’ Dense Embedding â†’ Sparse Embedding â†’ Pinecone

æ£€ç´¢æµç¨‹ï¼š
æŸ¥è¯¢ â†’ é¢†åŸŸè¯å…¸åˆ†è¯ â†’ BM25ç¨€ç–å‘é‡ â†’ Dense Embedding â†’ AlphaåŠ æƒ â†’ Hybridæ£€ç´¢

### 2.3 Pineconeç´¢å¼•é…ç½®è¦æ±‚
# åˆ›å»ºæ”¯æŒsparseå‘é‡çš„ç´¢å¼•
import pinecone

pinecone.create_index(
    name="40ktest-hybrid",
    dimension=1536,  # denseå‘é‡ç»´åº¦
    metric="dotproduct",
    pod_type="s1",
    sparse_vector_config={
        "dimension": 10000  # sparseå‘é‡ç»´åº¦ï¼Œæ ¹æ®è¯æ±‡è¡¨å¤§å°è°ƒæ•´
)

## 3. æ ¸å¿ƒæ¨¡å—è®¾è®¡

### 3.1 BM25Managerç±»è®¾è®¡

#### 3.1.1 ç±»ç»“æ„
    """BM25ç¨€ç–å‘é‡ç®¡ç†å™¨"""
    
        self.k1 = k1  # BM25å‚æ•°k1
        self.b = b    # BM25å‚æ•°b
        self.min_freq = min_freq  # æœ€å°è¯é¢‘é˜ˆå€¼
        self.max_vocab_size = max_vocab_size  # æœ€å¤§è¯æ±‡è¡¨å¤§å°
        self.vocabulary = {}  # è¯æ±‡è¡¨æ˜ å°„
        self.corpus_tokens = []  # è¯­æ–™åº“åˆ†è¯ç»“æœ
        
        # åŠ è½½è‡ªå®šä¹‰è¯å…¸
        
    def tokenize_chinese(self, text):
        """ä¸­æ–‡åˆ†è¯ï¼ˆæ”¯æŒé¢†åŸŸè¯å…¸ï¼‰"""
        
        """è®­ç»ƒBM25æ¨¡å‹"""
        
        """å¢é‡æ›´æ–°BM25æ¨¡å‹"""
        
    def get_sparse_vector(self, text):
        """ç”Ÿæˆç¨€ç–å‘é‡ï¼ˆä¿®æ­£åçš„å®ç°ï¼‰"""
        
    def save_model(self, model_path, vocab_path):
        """ä¿å­˜æ¨¡å‹å’Œè¯æ±‡è¡¨"""
        
    def load_model(self, model_path, vocab_path):
        """åŠ è½½æ¨¡å‹å’Œè¯æ±‡è¡¨"""
        
    def get_vocabulary_stats(self):
        """è·å–è¯æ±‡è¡¨ç»Ÿè®¡ä¿¡æ¯"""

#### 3.1.2 æ ¸å¿ƒæ–¹æ³•å®ç°ï¼ˆä¿®æ­£ç‰ˆï¼‰
def _build_vocabulary(self, corpus_texts: List[str]):
    """æ„å»ºå‰ªæåçš„è¯æ±‡è¡¨"""
    # åˆ†è¯å¤„ç†
    self.corpus_tokens = [self.tokenize_chinese(text) for text in corpus_texts]
    
    # ç»Ÿè®¡è¯é¢‘
    for tokens in self.corpus_tokens:
    
    # è¿‡æ»¤ä½é¢‘è¯
    filtered_tokens = {token: freq for token, freq in token_freq.items() 
                      if freq >= self.min_freq}
    
    # æŒ‰é¢‘ç‡æ’åºå¹¶é™åˆ¶å¤§å°
    sorted_tokens = sorted(filtered_tokens.items(), 
                          key=lambda x: x[1], reverse=True)[:self.max_vocab_size]
    
    self.vocabulary = {token: idx for idx, (token, _) in enumerate(sorted_tokens)}
    logger.info(f"è¯æ±‡è¡¨æ„å»ºå®Œæˆï¼Œå¤§å°: {len(self.vocabulary)}")

    """
    ç”Ÿæˆæ­£ç¡®çš„BM25ç¨€ç–å‘é‡
    
    Args:
        text: è¾“å…¥æ–‡æœ¬
        
    Returns:
        dict: {"indices": [int], "values": [float]}
    if not self.is_fitted:
        raise ValueError("BM25æ¨¡å‹å°šæœªè®­ç»ƒ")
    
    indices = []
    values = []
    
    # ç»Ÿè®¡å½“å‰æ–‡æœ¬çš„è¯é¢‘
    
    # è®¡ç®—æ¯ä¸ªtokençš„BM25æƒé‡
            # è·å–IDFå€¼
            # è®¡ç®—TF
            # è®¡ç®—BM25æƒé‡ (ç®€åŒ–ç‰ˆ)
            weight = idf * tf
    

def incremental_update(self, new_corpus_texts: List[str]):
    logger.info("å¼€å§‹å¢é‡æ›´æ–°BM25æ¨¡å‹")
    
    # æ›´æ–°è¯­æ–™åº“
    new_tokens = [self.tokenize_chinese(text) for text in new_corpus_texts]
    self.corpus_tokens.extend(new_tokens)
    
    # é‡æ–°è®­ç»ƒæ¨¡å‹
    
    # æ›´æ–°è¯æ±‡è¡¨
    self._build_vocabulary([text for tokens in self.corpus_tokens for text in tokens])
    
    logger.info("BM25æ¨¡å‹å¢é‡æ›´æ–°å®Œæˆ")

### 3.2 é…ç½®ç®¡ç†è®¾è®¡

#### 3.2.1 config.pyæ‰©å±•
# BM25é…ç½®

# Hybridæ£€ç´¢é…ç½®
HYBRID_ALPHA = float(os.getenv('HYBRID_ALPHA', '0.3'))
ENABLE_HYBRID_SEARCH = os.getenv('ENABLE_HYBRID_SEARCH', 'true').lower() == 'true'

# Pineconeé…ç½®

#### 3.2.2 .envæ¨¡æ¿
```bash
BM25_K1=1.5
BM25_B=0.75
BM25_MIN_FREQ=5
BM25_MAX_VOCAB_SIZE=10000
BM25_CUSTOM_DICT_PATH=dicts/warhammer40k.txt
BM25_MODEL_PATH=models/bm25_model.pkl
BM25_VOCAB_PATH=models/bm25_vocab.json

HYBRID_ALPHA=0.3
ENABLE_HYBRID_SEARCH=true

PINECONE_SPARSE_DIMENSION=10000

## 4. å®æ–½æ­¥éª¤

### 4.1 ç¬¬ä¸€é˜¶æ®µï¼šBM25Managerå®ç°

#### 4.1.1 åˆ›å»ºBM25Managerç±»ï¼ˆä¿®æ­£ç‰ˆï¼‰
**æ–‡ä»¶ä½ç½®**ï¼š`DATAUPLOD/bm25_manager.py`

import jieba
import json
import pickle
import os
from typing import List, Dict, Any
from rank_bm25 import BM25Okapi
import logging

logger = logging.getLogger(__name__)

    """BM25ç¨€ç–å‘é‡ç®¡ç†å™¨ï¼ˆä¿®æ­£ç‰ˆï¼‰"""
    
    def __init__(self, k1: float = 1.5, b: float = 0.75, 
                 min_freq: int = 5, max_vocab_size: int = 10000, 
                 custom_dict_path: str = None):
        
            logger.info(f"å·²åŠ è½½è‡ªå®šä¹‰è¯å…¸: {custom_dict_path}")
        
    def tokenize_chinese(self, text: str) -> List[str]:
        return list(jieba.cut(text))
    
        
        
        
        
    
    def fit(self, corpus_texts: List[str]):
        logger.info(f"å¼€å§‹è®­ç»ƒBM25æ¨¡å‹ï¼Œè¯­æ–™åº“å¤§å°: {len(corpus_texts)}")
        
        # æ„å»ºè¯æ±‡è¡¨
        self._build_vocabulary(corpus_texts)
        
        # è®­ç»ƒBM25æ¨¡å‹
        
        logger.info(f"BM25æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œè¯æ±‡è¡¨å¤§å°: {len(self.vocabulary)}")
    
        """ç”Ÿæˆæ­£ç¡®çš„BM25ç¨€ç–å‘é‡"""
            raise ValueError("BM25æ¨¡å‹å°šæœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨fit()æ–¹æ³•")
        
        
        
        
    
        
        
        
        
    
    def save_model(self, model_path: str, vocab_path: str):
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒ")
        
        # åˆ›å»ºç›®å½•
        os.makedirs(os.path.dirname(model_path), exist_ok=True)
        os.makedirs(os.path.dirname(vocab_path), exist_ok=True)
        
        # ä¿å­˜BM25æ¨¡å‹
        with open(model_path, 'wb') as f:
            pickle.dump(self.bm25_model, f)
        
        # ä¿å­˜è¯æ±‡è¡¨
        with open(vocab_path, 'w', encoding='utf-8') as f:
            json.dump(self.vocabulary, f, ensure_ascii=False, indent=2)
        
        logger.info(f"BM25æ¨¡å‹å·²ä¿å­˜: {model_path}, è¯æ±‡è¡¨: {vocab_path}")
    
    def load_model(self, model_path: str, vocab_path: str):
        # åŠ è½½BM25æ¨¡å‹
        with open(model_path, 'rb') as f:
            self.bm25_model = pickle.load(f)
        
        # åŠ è½½è¯æ±‡è¡¨
        with open(vocab_path, 'r', encoding='utf-8') as f:
            self.vocabulary = json.load(f)
        
        logger.info(f"BM25æ¨¡å‹å·²åŠ è½½: {model_path}, è¯æ±‡è¡¨å¤§å°: {len(self.vocabulary)}")
    
    def get_vocabulary_stats(self) -> Dict[str, Any]:
        return {
            "vocabulary_size": len(self.vocabulary),
            "min_freq": self.min_freq,
            "max_vocab_size": self.max_vocab_size,
            "is_fitted": self.is_fitted

#### 4.1.2 ä¾èµ–å®‰è£…
pip3 install rank-bm25 jieba

### 4.2 ç¬¬äºŒé˜¶æ®µï¼šä¿®æ”¹upsert.py

#### 4.2.1 é›†æˆBM25Manager
# åœ¨upsert.pyä¸­æ·»åŠ 
from bm25_manager import BM25Manager
from config import (BM25_K1, BM25_B, BM25_MIN_FREQ, BM25_MAX_VOCAB_SIZE, 
                   BM25_CUSTOM_DICT_PATH, BM25_MODEL_PATH, BM25_VOCAB_PATH)

class UpsertManager:
    def __init__(self, environment: str = "production", chunker_version: str = "v3"):
        # ... ç°æœ‰ä»£ç  ...
        self.bm25_manager = None
        
    def _initialize_services(self, enable_kg: bool, enable_pinecone: bool):
        
        if enable_pinecone and self.bm25_manager is None:
            self.bm25_manager = BM25Manager(
                k1=BM25_K1, 
                b=BM25_B,
                min_freq=BM25_MIN_FREQ,
                max_vocab_size=BM25_MAX_VOCAB_SIZE,
                custom_dict_path=BM25_CUSTOM_DICT_PATH
            
            # å°è¯•åŠ è½½å·²æœ‰æ¨¡å‹
            try:
                if os.path.exists(BM25_MODEL_PATH) and os.path.exists(BM25_VOCAB_PATH):
                    self.bm25_manager.load_model(BM25_MODEL_PATH, BM25_VOCAB_PATH)
                    logging.info("âœ… BM25æ¨¡å‹åŠ è½½å®Œæˆ")
                else:
                    logging.info("âš ï¸ BM25æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†åœ¨é¦–æ¬¡ä¸Šä¼ æ—¶è®­ç»ƒ")
            except Exception as e:
                logging.warning(f"âš ï¸ BM25æ¨¡å‹åŠ è½½å¤±è´¥: {e}")

#### 4.2.2 ä¿®æ”¹å‘é‡ä¸Šä¼ é€»è¾‘
def process_and_upsert_document(self, file_path: str, enable_kg: bool = True, enable_pinecone: bool = True, extra_metadata: dict = None):
    # ... ç°æœ‰åˆ‡ç‰‡ä»£ç  ...
    
    # 3. Pinecone å‘é‡ä¸Šä¼ 
    if enable_pinecone and self.pinecone_index and self.embedding_model:
        logging.info("Step 3: æ­£åœ¨è¿›è¡Œå‘é‡åŒ–å¹¶ä¸Šä¼ åˆ° Pinecone...")
        
        # è®­ç»ƒæˆ–æ›´æ–°BM25æ¨¡å‹
        if self.bm25_manager and not self.bm25_manager.is_fitted:
            logging.info("è®­ç»ƒBM25æ¨¡å‹...")
            corpus_texts = [chunk['text'] for chunk in chunks]
            self.bm25_manager.fit(corpus_texts)
            
            # ä¿å­˜æ¨¡å‹
            self.bm25_manager.save_model(BM25_MODEL_PATH, BM25_VOCAB_PATH)
        
        # æ„å»ºå¾…ä¸Šä¼ çš„æ•°æ®
        vectors_to_upsert = []
        for i, chunk in enumerate(chunks):
            chunk_id = f"{os.path.basename(file_path)}-{i}"
            
                # ç”Ÿæˆdense embedding
                dense_embedding = self.embedding_model.embed_query(chunk['text'])
                
                # ç”Ÿæˆsparse embedding
                sparse_embedding = None
                if self.bm25_manager and self.bm25_manager.is_fitted:
                    sparse_embedding = self.bm25_manager.get_sparse_vector(chunk['text'])
                
                # æ„å»ºmetadata
                pinecone_metadata = {
                    'text': chunk['text'],
                    'chunk_type': chunk.get('chunk_type', ''),
                    'content_type': chunk.get('content_type', ''),
                    'faction': chunk.get('faction', extra_metadata.get('faction', 'æœªçŸ¥')),
                    'section_heading': chunk.get('section_heading', ''),
                
                # æ·»åŠ å¤šçº§æ ‡é¢˜å­—æ®µ
                for j in range(1, 7):
                    pinecone_metadata[f'h{j}'] = chunk.get(f'h{j}', '')
                pinecone_metadata['chunk_id'] = str(i)
                pinecone_metadata['source_file'] = chunk.get('source_file', '')
                
                # æ„å»ºå‘é‡æ•°æ®
                vector_data = {
                    'id': chunk_id,
                    'values': dense_embedding,
                    'metadata': pinecone_metadata
                
                # æ·»åŠ sparseå‘é‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                if sparse_embedding:
                    vector_data['sparse_values'] = sparse_embedding
                
                vectors_to_upsert.append(vector_data)
                
                logging.error(f"Chunk {i} å‘é‡åŒ–å¤±è´¥: {e}")
                continue
        
        # åˆ†æ‰¹ä¸Šä¼ 
        # ... ç°æœ‰ä¸Šä¼ ä»£ç  ...

### 4.3 ç¬¬ä¸‰é˜¶æ®µï¼šä¿®æ”¹vector_search.py

#### 4.3.1 é›†æˆBM25Manager
# åœ¨vector_search.pyä¸­æ·»åŠ 
from DATAUPLOD.bm25_manager import BM25Manager
from config import (BM25_MODEL_PATH, BM25_VOCAB_PATH, BM25_K1, BM25_B, 
                   BM25_MIN_FREQ, BM25_MAX_VOCAB_SIZE, BM25_CUSTOM_DICT_PATH,
                   HYBRID_ALPHA, ENABLE_HYBRID_SEARCH)

class VectorSearch:
    def __init__(self, pinecone_api_key: str, index_name: str, openai_api_key=OPENAI_API_KEY):
        self._initialize_bm25()
    
    def _initialize_bm25(self):
        """åˆå§‹åŒ–BM25ç®¡ç†å™¨"""
        if ENABLE_HYBRID_SEARCH:
                
                    logger.info("âœ… BM25æ¨¡å‹åŠ è½½å®Œæˆ")
                    logger.warning("âš ï¸ BM25æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨hashå ä½å®ç°")
                logger.error(f"âŒ BM25æ¨¡å‹åŠ è½½å¤±è´¥: {e}")

#### 4.3.2 ä¿®æ”¹get_sparse_embeddingæ–¹æ³•
def get_sparse_embedding(self, text: str) -> Dict[str, Any]:
    """ç”Ÿæˆsparse embedding"""
    # ä¼˜å…ˆä½¿ç”¨BM25
            return self.bm25_manager.get_sparse_vector(text)
            logger.warning(f"BM25ç”Ÿæˆå¤±è´¥ï¼Œä½¿ç”¨hashå ä½: {e}")
    
    # é™çº§åˆ°hashå ä½å®ç°
    from collections import Counter
    import re
    tokens = re.findall(r"\w+", text.lower())
    counter = Counter(tokens)
    indices = [abs(hash(tok)) % (2**31) for tok in counter.keys()]
    values = list(counter.values())

#### 4.3.3 ä¿®æ”¹searchæ–¹æ³•
def search(self, query: str, top_k: int = 10, alpha: float = None) -> List[Dict[str, Any]]:
    æ‰§è¡Œhybridå‘é‡æœç´¢
    
        query: æŸ¥è¯¢æ–‡æœ¬
        top_k: è¿”å›ç»“æœæ•°é‡
        alpha: dense/sparseåŠ æƒå‚æ•°ï¼ŒNoneæ—¶ä½¿ç”¨é…ç½®é»˜è®¤å€¼
    if alpha is None:
        alpha = HYBRID_ALPHA
    
        # è·å–dense embedding
        query_embedding = self.get_embedding(query)
        
        # è·å–sparse embedding
        query_sparse = self.get_sparse_embedding(query)
        
        # æŒ‰alphaåŠ æƒ
        hdense, hsparse = self.hybrid_scale(query_embedding, query_sparse, alpha)
        
        # æ„å»ºæŸ¥è¯¢å‚æ•°
        query_params = {
            'vector': hdense,
            'top_k': top_k,
            'include_metadata': True
        
        if hsparse and hsparse.get('indices'):
            query_params['sparse_vector'] = hsparse
        
        # æ‰§è¡ŒæŸ¥è¯¢
        results = self.index.query(**query_params)
        
        # å¤„ç†ç»“æœ
        search_results = []
        for match in results.matches:
            text = match.metadata.get('text', '')
            if not text or len(text.strip()) < 10:
            search_results.append({
                'text': text,
                'score': match.score,
                'metadata': match.metadata
            })
        
        return search_results
        
        logger.error(f"æœç´¢æ—¶å‡ºé”™ï¼š{str(e)}")
        return []

### 4.4 ç¬¬å››é˜¶æ®µï¼šæµ‹è¯•å’ŒéªŒè¯

#### 4.4.1 åˆ›å»ºæµ‹è¯•è„šæœ¬ï¼ˆä¿®æ­£ç‰ˆï¼‰
**æ–‡ä»¶ä½ç½®**ï¼š`test/test_bm25_hybrid.py`

#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import sys
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from vector_search import VectorSearch
from config import (PINECONE_API_KEY, PINECONE_INDEX, BM25_MIN_FREQ, 
                   BM25_MAX_VOCAB_SIZE, BM25_CUSTOM_DICT_PATH)

def test_bm25_manager():
    """æµ‹è¯•BM25Manager"""
    print("ğŸ§ª æµ‹è¯•BM25Manager...")
    
    # æµ‹è¯•æ•°æ®
    corpus = [
        "æˆ˜é”¤40Kæ˜¯ä¸€æ¬¾æ¡Œé¢æˆ˜æ£‹æ¸¸æˆ",
        "é˜¿è‹ç„‰å°¼æ˜¯æˆ˜é”¤40Kä¸­çš„ä¸€ä¸ªç§æ—",
        "å‡¯æ©åŒ–èº«æ˜¯é˜¿è‹ç„‰å°¼çš„å¼ºåŠ›å•ä½",
        "çŒé¹°å¦å…‹å…·æœ‰å¼ºå¤§çš„ç«åŠ›æ”¯æ´èƒ½åŠ›"
    ]
    
    # åˆå§‹åŒ–å¹¶è®­ç»ƒï¼ˆä½¿ç”¨é…ç½®å‚æ•°ï¼‰
    bm25 = BM25Manager(
    bm25.fit(corpus)
    
    # æµ‹è¯•ç¨€ç–å‘é‡ç”Ÿæˆ
    test_text = "é˜¿è‹ç„‰å°¼å‡¯æ©åŒ–èº«"
    sparse_vec = bm25.get_sparse_vector(test_text)
    
    print(f"âœ… ç¨€ç–å‘é‡ç”ŸæˆæˆåŠŸ: {sparse_vec}")
    
    # æµ‹è¯•è¯æ±‡è¡¨ç»Ÿè®¡
    stats = bm25.get_vocabulary_stats()
    print(f"ğŸ“Š è¯æ±‡è¡¨ç»Ÿè®¡: {stats}")
    
    return bm25

def test_sparse_vector_correctness():
    """æµ‹è¯•ç¨€ç–å‘é‡ç”Ÿæˆæ­£ç¡®æ€§"""
    print("ğŸ§ª æµ‹è¯•ç¨€ç–å‘é‡æ­£ç¡®æ€§...")
    
    bm25 = BM25Manager()
    corpus = ["æµ‹è¯•æ–‡æœ¬åŒ…å«æˆ˜é”¤40Kç›¸å…³å†…å®¹"]
    
    test_text = "æˆ˜é”¤40Kæµ‹è¯•"
    
    # éªŒè¯indiceså’Œvaluesé•¿åº¦ä¸€è‡´
    assert len(sparse_vec['indices']) == len(sparse_vec['values']), "indiceså’Œvaluesé•¿åº¦ä¸ä¸€è‡´"
    
    # éªŒè¯valueséƒ½æ˜¯æ­£æ•°
    assert all(v > 0 for v in sparse_vec['values']), "å­˜åœ¨éæ­£å€¼"
    
    # éªŒè¯indicesåœ¨è¯æ±‡è¡¨èŒƒå›´å†…
    max_index = max(bm25.vocabulary.values()) if bm25.vocabulary else -1
    assert all(0 <= idx <= max_index for idx in sparse_vec['indices']), "ç´¢å¼•è¶…å‡ºèŒƒå›´"
    
    print("âœ… ç¨€ç–å‘é‡æ­£ç¡®æ€§éªŒè¯é€šè¿‡")

def test_incremental_update():
    """æµ‹è¯•å¢é‡æ›´æ–°"""
    print("ğŸ§ª æµ‹è¯•å¢é‡æ›´æ–°...")
    
    initial_corpus = ["åˆå§‹è¯­æ–™åº“å†…å®¹"]
    bm25.fit(initial_corpus)
    
    initial_size = len(bm25.vocabulary)
    
    # å¢é‡æ›´æ–°
    new_corpus = ["æ–°å¢è¯­æ–™åº“å†…å®¹åŒ…å«æ–°è¯æ±‡"]
    bm25.incremental_update(new_corpus)
    
    new_size = len(bm25.vocabulary)
    print(f"âœ… è¯æ±‡è¡¨å¤§å°å˜åŒ–: {initial_size} -> {new_size}")

def test_hybrid_search():
    """æµ‹è¯•hybridæ£€ç´¢"""
    print("ğŸ§ª æµ‹è¯•Hybridæ£€ç´¢...")
    
    vs = VectorSearch(PINECONE_API_KEY, PINECONE_INDEX)
    
    # æµ‹è¯•æŸ¥è¯¢
    query = "é˜¿è‹ç„‰å°¼å‡¯æ©åŒ–èº«"
    results = vs.search(query, top_k=5, alpha=0.3)
    
    print(f"âœ… æ‰¾åˆ° {len(results)} ä¸ªç»“æœ")
    for i, result in enumerate(results, 1):
        print(f"  {i}. åˆ†æ•°: {result['score']:.4f}")
        print(f"     å†…å®¹: {result['text'][:100]}...")
    
    return results

def test_error_handling():
    """æµ‹è¯•é”™è¯¯å¤„ç†"""
    print("ğŸ§ª æµ‹è¯•é”™è¯¯å¤„ç†...")
    
    
    # æµ‹è¯•æœªè®­ç»ƒæ¨¡å‹è°ƒç”¨get_sparse_vector
        bm25.get_sparse_vector("æµ‹è¯•æ–‡æœ¬")
        assert False, "åº”è¯¥æŠ›å‡ºå¼‚å¸¸"
    except ValueError as e:
        print(f"âœ… æ­£ç¡®æ•è·å¼‚å¸¸: {e}")
    
    # æµ‹è¯•ç©ºæ–‡æœ¬å¤„ç†
        bm25.fit([])
        print("âœ… ç©ºè¯­æ–™åº“å¤„ç†æ­£å¸¸")
        print(f"âš ï¸ ç©ºè¯­æ–™åº“å¤„ç†å¼‚å¸¸: {e}")

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹BM25 Hybridæ£€ç´¢æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•BM25Manager
    bm25 = test_bm25_manager()
    
    # æµ‹è¯•ç¨€ç–å‘é‡æ­£ç¡®æ€§
    test_sparse_vector_correctness()
    
    # æµ‹è¯•å¢é‡æ›´æ–°
    test_incremental_update()
    
    # æµ‹è¯•é”™è¯¯å¤„ç†
    test_error_handling()
    
    # æµ‹è¯•Hybridæ£€ç´¢
    results = test_hybrid_search()
    
    print("âœ… æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")

#### 4.4.2 è¿è¡Œæµ‹è¯•
python3 test/test_bm25_hybrid.py

## 5. éƒ¨ç½²å’Œé…ç½®

### 5.1 ç¯å¢ƒé…ç½®
# å®‰è£…ä¾èµ–

# åˆ›å»ºæ¨¡å‹ç›®å½•
mkdir -p models
mkdir -p dicts

# åˆ›å»ºæˆ˜é”¤40Kè¯å…¸æ–‡ä»¶
cat > dicts/warhammer40k.txt << EOF
é˜¿è‹ç„‰å°¼ n
å‡¯æ©åŒ–èº« n
çŒé¹°å¦å…‹ n
æˆ˜é”¤40K n
å¸æˆ˜ n
æ–¥å€™ n
ç«åŠ›æ”¯æ´ n
æ­»äº¡ä¹‹èˆ n
EOF

# é…ç½®ç¯å¢ƒå˜é‡
cp .env.template .env
# ç¼–è¾‘.envæ–‡ä»¶ï¼Œæ·»åŠ BM25é…ç½®

### 5.2 æ•°æ®è¿ç§»
# 1. æ¸…ç©ºç°æœ‰ç´¢å¼•ï¼ˆå¦‚æœéœ€è¦é‡å»ºï¼‰
python3 clear_pinecone_40ktest.py

# 2. é‡æ–°ä¸Šä¼ æ•°æ®ï¼ˆä¼šè‡ªåŠ¨è®­ç»ƒBM25æ¨¡å‹ï¼‰
python3 DATAUPLOD/upsert.py --file your_document.md

# 3. éªŒè¯hybridæ£€ç´¢æ•ˆæœ

## 6. ç›‘æ§å’Œä¼˜åŒ–

### 6.1 æ€§èƒ½ç›‘æ§
- **BM25æ¨¡å‹å¤§å°**ï¼šç›‘æ§è¯æ±‡è¡¨å¤§å°å’Œæ¨¡å‹æ–‡ä»¶å¤§å°
- **æ£€ç´¢å“åº”æ—¶é—´**ï¼šå¯¹æ¯”hybrid vs denseæ£€ç´¢çš„å“åº”æ—¶é—´
- **å¬å›æ•ˆæœ**ï¼šä½¿ç”¨è¯„ä¼°å·¥å…·å¯¹æ¯”æ£€ç´¢æ•ˆæœ

### 6.2 å‚æ•°è°ƒä¼˜
- **BM25å‚æ•°**ï¼šè°ƒæ•´k1å’Œbå‚æ•°
- **Alphaå‚æ•°**ï¼šè°ƒæ•´dense/sparseæƒé‡
- **è¯æ±‡è¡¨ä¼˜åŒ–**ï¼šå®šæœŸæ›´æ–°è¯æ±‡è¡¨

## 7. é£é™©è¯„ä¼°å’Œåº”å¯¹

### 7.1 æŠ€æœ¯é£é™©
- **BM25æ¨¡å‹åŠ è½½å¤±è´¥**ï¼šæœ‰hashå ä½é™çº§æ–¹æ¡ˆ
- **è¯æ±‡è¡¨è¿‡å¤§**ï¼šå¯ä»¥è®¾ç½®æœ€å°é¢‘ç‡é˜ˆå€¼
- **æ€§èƒ½å½±å“**ï¼šBM25è®¡ç®—ç›¸å¯¹è½»é‡ï¼Œå½±å“å¯æ§

### 7.2 ä¸šåŠ¡é£é™©
- **æ£€ç´¢æ•ˆæœä¸‹é™**ï¼šå¯ä»¥é€šè¿‡alphaå‚æ•°è°ƒæ•´
- **ç³»ç»Ÿå¤æ‚åº¦å¢åŠ **ï¼šæœ‰å®Œæ•´çš„é…ç½®å¼€å…³æ§åˆ¶

## 8. ChatGPTå»ºè®®ä¸ä¿®æ­£æ€»ç»“

### 8.1 å…³é”®é—®é¢˜ä¿®æ­£

#### 8.1.1 BM25å‘é‡åŒ–é€»è¾‘é”™è¯¯ â­â­â­â­â­
**é—®é¢˜**ï¼šåŸå®ç°ä½¿ç”¨`get_scores(tokens)`è¿”å›æ–‡æ¡£å¾—åˆ†ï¼Œè€Œétokenæƒé‡
**ä¿®æ­£**ï¼šä½¿ç”¨`bm25_model.idf[token] * tf`è®¡ç®—çœŸæ­£çš„tokenæƒé‡
**å½±å“**ï¼šç¡®ä¿sparseå‘é‡çš„è¯­ä¹‰æ­£ç¡®æ€§

#### 8.1.2 è¯æ±‡è¡¨è§„æ¨¡æ§åˆ¶ â­â­â­â­â­
**é—®é¢˜**ï¼šå…¨é‡è¯æ±‡è¡¨å¯¼è‡´ç»´åº¦çˆ†ç‚¸
**ä¿®æ­£**ï¼šæ·»åŠ `min_freq`å’Œ`max_vocab_size`å‚æ•°è¿›è¡Œå‰ªæ
**å½±å“**ï¼šæ˜¾è‘—é™ä½å­˜å‚¨å’Œè®¡ç®—æˆæœ¬

#### 8.1.3 é¢†åŸŸè¯å…¸æ”¯æŒ â­â­â­â­
**é—®é¢˜**ï¼šjiebaå¯¹ä¸“æœ‰åè¯åˆ†è¯ä¸ç†æƒ³
**ä¿®æ­£**ï¼šæ”¯æŒè‡ªå®šä¹‰è¯å…¸åŠ è½½
**å½±å“**ï¼šæå‡æˆ˜é”¤40Kä¸“æœ‰åè¯è¯†åˆ«å‡†ç¡®æ€§

#### 8.1.4 å¢é‡æ›´æ–°æœºåˆ¶ â­â­â­â­
**é—®é¢˜**ï¼šç¼ºå°‘æ¨¡å‹å¢é‡æ›´æ–°ç­–ç•¥
**ä¿®æ­£**ï¼šå®ç°`incremental_update`æ–¹æ³•
**å½±å“**ï¼šæ”¯æŒæ–°è¯­æ–™çš„åŠ¨æ€æ›´æ–°

#### 8.1.5 Pineconeé…ç½®æ˜ç¡®åŒ– â­â­â­â­â­
**é—®é¢˜**ï¼šç¼ºå°‘sparseå‘é‡ç´¢å¼•åˆ›å»ºè¯´æ˜
**ä¿®æ­£**ï¼šæ˜ç¡®ç´¢å¼•é…ç½®è¦æ±‚å’Œå‚æ•°
**å½±å“**ï¼šé¿å…è¿è¡Œæ—¶é…ç½®é”™è¯¯

### 8.2 æµ‹è¯•è¦†ç›–å®Œå–„

#### 8.2.1 ç¨€ç–å‘é‡æ­£ç¡®æ€§æµ‹è¯•
- éªŒè¯indiceså’Œvaluesé•¿åº¦ä¸€è‡´
- ç¡®ä¿valueséƒ½æ˜¯æ­£å€¼
- æ£€æŸ¥indicesåœ¨è¯æ±‡è¡¨èŒƒå›´å†…

#### 8.2.2 é”™è¯¯å¤„ç†æµ‹è¯•
- æœªè®­ç»ƒæ¨¡å‹è°ƒç”¨å¼‚å¸¸
- ç©ºè¯­æ–™åº“å¤„ç†
- é…ç½®å‚æ•°è¾¹ç•Œæµ‹è¯•

#### 8.2.3 å¢é‡æ›´æ–°æµ‹è¯•
- è¯æ±‡è¡¨å¤§å°å˜åŒ–éªŒè¯
- æ–°è¯æ±‡æ·»åŠ éªŒè¯
- æ¨¡å‹ä¸€è‡´æ€§éªŒè¯

### 8.3 æ€§èƒ½ä¼˜åŒ–å»ºè®®

#### 8.3.1 è¯æ±‡è¡¨ä¼˜åŒ–
- è®¾ç½®åˆç†çš„æœ€å°é¢‘ç‡é˜ˆå€¼ï¼ˆå»ºè®®5-10ï¼‰
- é™åˆ¶æœ€å¤§è¯æ±‡è¡¨å¤§å°ï¼ˆå»ºè®®5000-10000ï¼‰
- å®šæœŸæ¸…ç†ä½é¢‘è¯æ±‡

#### 8.3.2 è®¡ç®—ä¼˜åŒ–
- ç¼“å­˜å¸¸ç”¨è¯æ±‡çš„IDFå€¼
- æ‰¹é‡å¤„ç†ç¨€ç–å‘é‡ç”Ÿæˆ
- å¼‚æ­¥æ›´æ–°BM25æ¨¡å‹

#### 8.3.3 å­˜å‚¨ä¼˜åŒ–
- å‹ç¼©è¯æ±‡è¡¨å­˜å‚¨æ ¼å¼
- å¢é‡ä¿å­˜æ¨¡å‹å˜æ›´
- å®šæœŸå¤‡ä»½é‡è¦æ•°æ®

## 9. å®æ–½ä¼˜å…ˆçº§å»ºè®®

### 9.1 ç¬¬ä¸€é˜¶æ®µï¼ˆå¿…é¡»ï¼‰
1. **ä¿®æ­£BM25å‘é‡åŒ–é€»è¾‘**ï¼šç¡®ä¿sparseå‘é‡æ­£ç¡®æ€§
2. **æ·»åŠ è¯æ±‡è¡¨å‰ªæ**ï¼šæ§åˆ¶ç»´åº¦è§„æ¨¡
3. **æ˜ç¡®Pineconeé…ç½®**ï¼šé¿å…éƒ¨ç½²é”™è¯¯

### 9.2 ç¬¬äºŒé˜¶æ®µï¼ˆé‡è¦ï¼‰
1. **é›†æˆé¢†åŸŸè¯å…¸**ï¼šæå‡ä¸“æœ‰åè¯è¯†åˆ«
2. **å®ç°å¢é‡æ›´æ–°**ï¼šæ”¯æŒåŠ¨æ€æ•°æ®æ›´æ–°
3. **å®Œå–„æµ‹è¯•ç”¨ä¾‹**ï¼šç¡®ä¿ç³»ç»Ÿç¨³å®šæ€§

### 9.3 ç¬¬ä¸‰é˜¶æ®µï¼ˆå¯é€‰ï¼‰
1. **æ€§èƒ½ä¼˜åŒ–**ï¼šç¼“å­˜å’Œå¼‚æ­¥å¤„ç†
2. **ç›‘æ§å‘Šè­¦**ï¼šç³»ç»Ÿè¿è¡ŒçŠ¶æ€ç›‘æ§
3. **A/Bæµ‹è¯•**ï¼šæ•ˆæœå¯¹æ¯”éªŒè¯


æœ¬è®¾è®¡æ–‡æ¡£åŸºäºChatGPTçš„ä¸“ä¸šå»ºè®®è¿›è¡Œäº†å…¨é¢ä¿®æ­£ï¼Œè§£å†³äº†ä»¥ä¸‹å…³é”®é—®é¢˜ï¼š

1. **BM25Managerç±»**ï¼šä¿®æ­£äº†å‘é‡åŒ–é€»è¾‘ï¼Œæ·»åŠ äº†å‰ªæå’Œå¢é‡æ›´æ–°
2. **é…ç½®ç®¡ç†**ï¼šæ‰©å±•äº†å‚æ•°é…ç½®ï¼Œæ”¯æŒé¢†åŸŸè¯å…¸
3. **ä¸Šä¼ ç«¯é›†æˆ**ï¼šæ”¯æŒæ­£ç¡®çš„sparseå‘é‡ä¸Šä¼ 
4. **æ£€ç´¢ç«¯é›†æˆ**ï¼šæ”¯æŒä¿®æ­£åçš„hybridæ£€ç´¢
5. **æµ‹è¯•éªŒè¯**ï¼šå®Œå–„çš„æµ‹è¯•è¦†ç›–å’Œé”™è¯¯å¤„ç†
6. **éƒ¨ç½²æŒ‡å—**ï¼šæ˜ç¡®çš„Pineconeé…ç½®è¦æ±‚

# ã€2024-07-05å·¥ç¨‹å»ºè®®è¡¥å……ã€‘å‘é‡ä¸Šä¼ ä¸BM25å·¥ç¨‹å®è·µ

## 1. å‘é‡ä¸Šä¼ å¼‚å¸¸æ•è·ä¸æ§åˆ¶æµï¼ˆå»ºè®®å·²é‡‡çº³ï¼‰
### èƒŒæ™¯
- å•ä¸ªchunkå‘é‡åŒ–æˆ–ç»„è£…å¯èƒ½å› æ•°æ®å¼‚å¸¸ã€æ¨¡å‹bugç­‰å¤±è´¥ï¼Œè‹¥æœªå¦¥å–„æ•è·ï¼Œå¯èƒ½å¯¼è‡´æ•´ä¸ªæ‰¹æ¬¡æˆ–æµç¨‹ä¸­æ–­ã€‚
### å»ºè®®å†…å®¹
- forå¾ªç¯å†…æ¯ä¸ªchunkçš„å‘é‡åŒ–ã€ç»„è£…ã€appendå‡åº”åŒ…è£¹åœ¨try...exceptå—å†…ï¼Œå¼‚å¸¸åªå½±å“å½“å‰chunkï¼Œæ—¥å¿—è¯¦ç»†è®°å½•ã€‚
### è½åœ°æ–¹æ¡ˆ
- vectors_to_upsert.append(vector_data)å¿…é¡»æ”¾åœ¨tryå—å†…ï¼Œç¡®ä¿åªappendæˆåŠŸçš„å‘é‡ã€‚
- å¤±è´¥chunkè®°å½•æ—¥å¿—å¹¶continueï¼Œä¸»æµç¨‹ä¸ä¸­æ–­ã€‚

## 2. æ‰¹é‡ä¸å¹¶å‘ä¸Šä¼ ï¼ˆå»ºè®®é‡‡çº³ä¸­ï¼‰
### èƒŒæ™¯
- Pineconeç­‰å‘é‡åº“APIæœ‰é€Ÿç‡å’Œæ‰¹é‡é™åˆ¶ï¼Œå¤§è§„æ¨¡ä¸Šä¼ æ—¶éœ€åˆ†æ‰¹ã€å¹¶å‘æå‡ååé‡ã€‚
### å»ºè®®å†…å®¹
- upsertåº”åˆ†æ‰¹ï¼ˆ100-500æ¡ï¼‰ï¼Œå¯ç”¨å¼‚æ­¥/çº¿ç¨‹æ± æå‡å¹¶å‘ã€‚
- ä¸Šä¼ å‰è¿‡æ»¤æ‰denseä¸ºNoneæˆ–sparseç»´åº¦å¼‚å¸¸çš„æ¡ç›®ï¼Œä¿è¯æ‰¹æ¬¡æ•°æ®è´¨é‡ã€‚
### è½åœ°æ–¹æ¡ˆ
- é‡‡ç”¨æ‰¹é‡ä¸Šä¼ ï¼Œåç»­å¯å¼•å…¥å¹¶å‘ï¼ˆå¦‚concurrent.futures.ThreadPoolExecutorï¼‰ã€‚
- é¢„è¿‡æ»¤å¼‚å¸¸æ¡ç›®ï¼Œæå‡æ•´ä½“æˆåŠŸç‡ã€‚

## 3. æ¨¡å‹è®­ç»ƒä¸ä¿å­˜æ—¶æœºï¼ˆå»ºè®®é‡‡çº³ä¸­ï¼‰
### èƒŒæ™¯
- BM25Managerå¦‚æ¯æ¬¡å…¨é‡fitå’Œsave_modelï¼Œæ€§èƒ½å’Œä¸€è‡´æ€§å‡å—å½±å“ï¼Œå¢é‡åœºæ™¯ä¸‹éœ€ä¼˜åŒ–ã€‚
### å»ºè®®å†…å®¹
- å¯åŠ¨æ—¶ä¼˜å…ˆloadå·²æœ‰æ¨¡å‹ï¼Œæ–°å¢æ–‡æ¡£ç”¨incremental_updateï¼Œä¸è¦é¢‘ç¹å…¨é‡fitå’Œsave_modelã€‚
- å®šæœŸ/æ‰¹é‡save_modelï¼Œå‡å°‘ç£ç›˜IOã€‚
### è½åœ°æ–¹æ¡ˆ
- æ”¯æŒæ¨¡å‹å¢é‡æ›´æ–°å’Œå®šæœŸä¿å­˜ï¼Œæå‡æ•ˆç‡å’Œä¸€è‡´æ€§ã€‚

## 4. å†…å­˜ä¸çŠ¶æ€ç®¡ç†ï¼ˆå»ºè®®å¯é€‰ï¼‰
### èƒŒæ™¯
- é•¿æ—¶é—´è¿è¡Œæ—¶ï¼ŒBM25Managerçš„raw_textsç­‰çŠ¶æ€ä¼šæ— é™å¢é•¿ï¼Œå¯¼è‡´å†…å­˜é£é™©ã€‚
### å»ºè®®å†…å®¹
- corpus_for_bm25/raw_textsåº”å»é‡æˆ–æ»‘çª—ï¼Œé¿å…å†…å­˜æ— é™å¢é•¿ã€‚
- æä¾›æ¸…ç†æ¥å£ï¼Œæ”¯æŒæŒ‰æ—¥æœŸ/ç‰ˆæœ¬æ¸…ç†æ—§çŠ¶æ€ã€‚
### è½åœ°æ–¹æ¡ˆ
- å¯å®ç°æ»‘åŠ¨çª—å£æˆ–å®šæœŸæ¸…ç†ï¼Œä¿è¯å†…å­˜å¯æ§ã€‚

## 5. Metadataå’ŒIDè®¾è®¡ï¼ˆå»ºè®®é‡‡çº³ä¸­ï¼‰
### èƒŒæ™¯
- chunk_idå¦‚ä»…ç”¨æ–‡ä»¶å+ç´¢å¼•ï¼Œæ–‡ä»¶å˜åŠ¨ä¼šå¯¼è‡´IDæ¼‚ç§»ï¼Œæ— æ³•å¹‚ç­‰è¦†ç›–ã€‚
### å»ºè®®å†…å®¹
- chunk_idå»ºè®®åŠ å†…å®¹å“ˆå¸Œæˆ–ç‰ˆæœ¬å·ï¼Œä¿è¯å¹‚ç­‰upsertï¼Œé¿å…é‡å¤å’Œè„æ•°æ®ã€‚
### è½åœ°æ–¹æ¡ˆ
- æ¨èchunk_id = f"{basename}-{i}-{sha1(chunk['text'].encode()).hexdigest()[:8]}"ï¼Œå”¯ä¸€æ ‡è¯†å†…å®¹ã€‚

---


æœ¬è®¾è®¡æ–‡æ¡£åŸºäºChatGPTçš„ä¸“ä¸šå»ºè®®è¿›è¡Œäº†å…¨é¢ä¿®æ­£ï¼Œè§£å†³äº†ä»¥ä¸‹å…³é”®é—®é¢˜ï¼š

1. **BM25Managerç±»**ï¼šä¿®æ­£äº†å‘é‡åŒ–é€»è¾‘ï¼Œæ·»åŠ äº†å‰ªæå’Œå¢é‡æ›´æ–°
2. **é…ç½®ç®¡ç†**ï¼šæ‰©å±•äº†å‚æ•°é…ç½®ï¼Œæ”¯æŒé¢†åŸŸè¯å…¸
3. **ä¸Šä¼ ç«¯é›†æˆ**ï¼šæ”¯æŒæ­£ç¡®çš„sparseå‘é‡ä¸Šä¼ 
4. **æ£€ç´¢ç«¯é›†æˆ**ï¼šæ”¯æŒä¿®æ­£åçš„hybridæ£€ç´¢
5. **æµ‹è¯•éªŒè¯**ï¼šå®Œå–„çš„æµ‹è¯•è¦†ç›–å’Œé”™è¯¯å¤„ç†
6. **éƒ¨ç½²æŒ‡å—**ï¼šæ˜ç¡®çš„Pineconeé…ç½®è¦æ±‚

# 250702-BM25_hybridæ£€ç´¢å®æ–½è®¾è®¡æ–‡æ¡£


åœ¨ç°æœ‰çš„RAGç³»ç»Ÿä¸­é›†æˆBM25 sparse embeddingï¼Œå®ç°å®Œæ•´çš„hybridæ£€ç´¢èƒ½åŠ›ï¼Œæå‡æˆ˜é”¤40Kè§„åˆ™æ–‡æ¡£çš„æ£€ç´¢å¬å›æ•ˆæœã€‚

- **é…ç½®ç®¡ç†**ï¼šç»Ÿä¸€BM25å‚æ•°é…ç½®å’Œä¸­æ–‡åˆ†è¯è®¾ç½®

- **ä¸­æ–‡åˆ†è¯**ï¼š`jieba`åº“
- **å‘é‡æ•°æ®åº“**ï¼šPineconeï¼ˆéœ€ç¡®è®¤metric=dotproductï¼‰
- **Pythonç‰ˆæœ¬**ï¼š3.8+


â”‚   (User Query)  â”‚â”€â”€â”€â–¶â”‚  Dense + Sparse â”‚â”€â”€â”€â–¶â”‚  (Hybrid)       â”‚

æ–‡æ¡£ â†’ åˆ‡ç‰‡ â†’ Dense Embedding + BM25 Sparse â†’ Pinecone Upsert

æŸ¥è¯¢ â†’ Dense Embedding + BM25 Sparse â†’ AlphaåŠ æƒ â†’ Pinecone Query

## 3. BM25æ¨¡å—è®¾è®¡

    
    def __init__(self, corpus=None, k1=1.5, b=0.75):
        åˆå§‹åŒ–BM25ç®¡ç†å™¨
        
            corpus: æ–‡æ¡£é›†åˆï¼Œç”¨äºæ„å»ºè¯æ±‡è¡¨å’ŒIDF
            k1: BM25å‚æ•°k1ï¼ˆè¯é¢‘é¥±å’Œå‚æ•°ï¼‰
            b: BM25å‚æ•°bï¼ˆæ–‡æ¡£é•¿åº¦å½’ä¸€åŒ–å‚æ•°ï¼‰
        self.vocab = {}
        self.idf = {}
        self.avgdl = 0
        
        if corpus:
            self.fit(corpus)
    
    def fit(self, corpus):
        # ä¸­æ–‡åˆ†è¯å¤„ç†
        tokenized_corpus = [self._tokenize_chinese(doc) for doc in corpus]
        self.bm25_model = BM25Okapi(tokenized_corpus, k1=self.k1, b=self.b)
        
        # æ„å»ºè¯æ±‡è¡¨æ˜ å°„
        self._build_vocab_mapping()
    
    def _tokenize_chinese(self, text):
        """ä¸­æ–‡åˆ†è¯"""
    
    def _build_vocab_mapping(self):
        """æ„å»ºè¯æ±‡è¡¨åˆ°ç´¢å¼•çš„æ˜ å°„"""
        # å®ç°è¯æ±‡è¡¨æ˜ å°„é€»è¾‘
        pass
    
    def encode(self, text):
        å°†æ–‡æœ¬ç¼–ç ä¸ºsparseå‘é‡
        
            
            dict: {'indices': [int], 'values': [float]}
        # å®ç°BM25ç¼–ç é€»è¾‘

### 3.2 é…ç½®ç®¡ç†
# config.py æ–°å¢é…ç½®
BM25_CONFIG = {
    'k1': 1.5,           # BM25å‚æ•°k1
    'b': 0.75,           # BM25å‚æ•°b
    'min_idf': 0.1,      # æœ€å°IDFé˜ˆå€¼
    'max_features': 10000,  # æœ€å¤§ç‰¹å¾æ•°
    'chinese_tokenizer': 'jieba'  # ä¸­æ–‡åˆ†è¯å™¨

# ä¸­æ–‡åˆ†è¯é…ç½®
JIEBA_CONFIG = {
    'use_paddle': True,  # ä½¿ç”¨paddleæ¨¡å¼æé«˜å‡†ç¡®ç‡
    'cut_all': False,    # ç²¾ç¡®æ¨¡å¼
    'HMM': True         # ä½¿ç”¨HMMæ¨¡å‹

## 4. ä¸Šä¼ ç«¯å®æ–½è®¾è®¡

### 4.1 UpsertManagerä¿®æ”¹

#### 4.1.1 åˆå§‹åŒ–ä¿®æ”¹
        # ç°æœ‰åˆå§‹åŒ–ä»£ç ...
        
        # æ–°å¢BM25ç®¡ç†å™¨
        self.corpus_for_bm25 = []
        
        
    
        
        # æ”¶é›†æ‰€æœ‰chunkæ–‡æœ¬ç”¨äºè®­ç»ƒBM25
        if not self.corpus_for_bm25:
            logging.warning("BM25è®­ç»ƒè¯­æ–™ä¸ºç©ºï¼Œå°†ä½¿ç”¨é»˜è®¤é…ç½®")
            self.bm25_manager = BM25Manager()
            self.bm25_manager = BM25Manager(corpus=self.corpus_for_bm25)
            logging.info(f"BM25æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œè¯­æ–™å¤§å°: {len(self.corpus_for_bm25)}")

#### 4.1.2 å‘é‡ç”Ÿæˆä¿®æ”¹
def _generate_vectors_for_chunk(self, chunk: Dict[str, Any]) -> Dict[str, Any]:
    ä¸ºå•ä¸ªchunkç”Ÿæˆdenseå’Œsparseå‘é‡
    
        chunk: åˆ‡ç‰‡æ•°æ®
        
        åŒ…å«denseå’Œsparseå‘é‡çš„å­—å…¸
        # 1. ç”Ÿæˆdense embedding
        
        # 2. ç”Ÿæˆsparse embedding
        sparse_embedding = self.bm25_manager.encode(chunk['text'])
        
            'dense': dense_embedding,
            'sparse': sparse_embedding,
            'success': True
        logging.error(f"å‘é‡ç”Ÿæˆå¤±è´¥: {e}")
            'dense': None,
            'sparse': None,
            'success': False,
            'error': str(e)

#### 4.1.3 ä¸Šä¼ æ•°æ®ç»“æ„ä¿®æ”¹
def _build_upsert_data(self, chunk: Dict[str, Any], vectors: Dict[str, Any]) -> Dict[str, Any]:
    æ„å»ºPinecone upsertæ•°æ®ç»“æ„
    
        vectors: ç”Ÿæˆçš„å‘é‡æ•°æ®
        
        Pinecone upsertæ•°æ®
    chunk_id = f"{chunk.get('source_file', 'unknown')}-{chunk.get('chunk_id', '0')}"
    
    metadata = {
        'faction': chunk.get('faction', 'æœªçŸ¥'),
        'chunk_id': str(chunk.get('chunk_id', '0')),
        'source_file': chunk.get('source_file', '')
    
        metadata[f'h{j}'] = chunk.get(f'h{j}', '')
    
    # æ„å»ºupsertæ•°æ®
    upsert_data = {
        'values': vectors['dense'],
        'metadata': metadata
    
    # æ·»åŠ sparseå‘é‡ï¼ˆå¦‚æœç”ŸæˆæˆåŠŸï¼‰
    if vectors['sparse'] and vectors['success']:
        upsert_data['sparse_values'] = vectors['sparse']
    
    return upsert_data

### 4.2 æ‰¹é‡å¤„ç†ä¼˜åŒ–

#### 4.2.1 è¯­æ–™æ”¶é›†
def _collect_corpus_for_bm25(self, chunks: List[Dict[str, Any]]):
    """æ”¶é›†BM25è®­ç»ƒè¯­æ–™"""
    corpus = []
    for chunk in chunks:
        # æ·»åŠ chunkæ–‡æœ¬
        corpus.append(chunk['text'])
        
        # å¯é€‰ï¼šæ·»åŠ æ ‡é¢˜ä¿¡æ¯
        if chunk.get('section_heading'):
            corpus.append(chunk['section_heading'])
    
    self.corpus_for_bm25.extend(corpus)
    logging.info(f"æ”¶é›†BM25è¯­æ–™: {len(corpus)} ä¸ªæ–‡æ¡£ç‰‡æ®µ")

#### 4.2.2 æ‰¹é‡å‘é‡ç”Ÿæˆ
def _batch_generate_vectors(self, chunks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """æ‰¹é‡ç”Ÿæˆå‘é‡"""
    vectors_list = []
    
        logging.debug(f"ç”Ÿæˆå‘é‡ {i+1}/{len(chunks)}")
        vectors = self._generate_vectors_for_chunk(chunk)
        vectors_list.append(vectors)
        
        # è¿›åº¦æ˜¾ç¤º
        if (i + 1) % 10 == 0:
            logging.info(f"å‘é‡ç”Ÿæˆè¿›åº¦: {i+1}/{len(chunks)}")
    
    return vectors_list

## 5. æ£€ç´¢ç«¯å®æ–½è®¾è®¡

### 5.1 VectorSearchç±»ä¿®æ”¹

#### 5.1.1 åˆå§‹åŒ–ä¿®æ”¹
cl 