# RAG 检索引擎架构设计（20250707）

## 1. 背景与目标

### 1.1 设计目标
- 构建一个灵活、可插拔、成本可控、易于评估的RAG检索系统。

### 1.2 典型应用场景
- RAG（Retrieval-Augmented Generation）检索召回：面向大规模知识库的高效检索与答案生成。
- 当前面临的问题：
  - 检索召回率低，导致相关信息未能充分利用。
  - RAG答案准确率低，影响用户体验和业务效果。
- 目标：尝试多种方法提升检索召回率和答案准确率，包括但不限于词典优化、检索策略调整、模型融合等。

### 1.3 现有系统局限
1. 架构设计不合理，代码耦合度高，难以扩展和维护。
2. 缺乏每一步的过程性评估体系，只能从最终答案角度评估，过程不透明，难以定位和优化各环节。

---

## 2. 系统总体架构

![[Pasted image 20250707225818.png]]

### 2.1 流程调度器（Scheduler/Controller）设计

#### 2.1.1. 设计定位与职责
- 作为前端请求的统一入口，负责参数解析、流程分发、模块调度和最终结果汇总。
- 解耦前端与后端各检索/处理模块，便于灵活扩展和策略切换。
- 支持多种query处理、检索、融合策略的动态配置。

#### 2.1.2. 接口参数设计
| 参数名   | 类型    | 说明                                                                                   | 取值示例/约定 |
|----------|---------|----------------------------------------------------------------------------------------|---------------|
| --query  | str     | 用户检索关键词/问题                                                                    | "阿巴顿的黑色远征" |
| --qp     | str     | query processor类型：<br>origin（原始query）、expand（扩写）、cot（思维链）、if-kg（是否抽取KG实体） | origin/expand/cot/if-kg |
| --se     | str     | search engine类型：<br>dense（向量）、sparse（稀疏）、hybrid（多路混合，含KG）           | dense/sparse/hybrid |
| --other  | dict    | 预留参数，便于未来扩展（如答案融合策略、召回数量等）                                    | -             |

> 说明：  
> - --qp 支持多选（如"expand+if-kg"），可用逗号分隔或布尔参数。  
> - --se 决定主检索路径，hybrid时自动调度多路召回与融合。

#### 2.1.3. 典型流程伪代码
```python
def scheduler(request):
    # 1. 解析参数
    query = request['query']
    qp_type = request.get('qp', 'origin')
    se_type = request.get('se', 'hybrid')
    # 2. Query处理
    if qp_type == 'origin':
        processed_query = query
    elif qp_type == 'expand':
        processed_query = query_expansion(query)
    elif qp_type == 'cot':
        processed_query = chain_of_thought(query)
    # KG实体识别
    if 'if-kg' in qp_type:
        entities, relations = extract_entities_relations(processed_query)
    else:
        entities, relations = None, None
    # 3. 检索调度
    if se_type == 'dense':
        results = dense_search(processed_query)
    elif se_type == 'sparse':
        results = sparse_search(processed_query)
    elif se_type == 'hybrid':
        results = []
        if entities:
            results += kg_search(entities, relations)
        results += dense_search(processed_query)
        results += sparse_search(processed_query)
        results = aggregate_and_dedup(results)
    # 4. 答案生成（融合策略可扩展）
    answer = answer_generate(results)
    return answer
```

#### 2.1.4. 可扩展性建议
- **参数可扩展**：预留future参数（如答案融合策略、召回数量、评估开关等）。
- **模块可插拔**：query processor、search engine、KG召回、答案融合均可通过参数动态切换。
- **流程可追踪**：每步处理结果可选输出，便于调试和评估。
- **接口规范**：建议采用RESTful或gRPC接口，便于前后端解耦和多语言支持。

#### 2.1.5. 示例请求
```json
{
  "query": "阿巴顿的黑色远征有哪些关键事件？",
  "qp": "expand,if-kg",
  "se": "hybrid"
}
``` 
### 2.2 插拔式模块设计原则
### 2.3数据流与控制流简图
### 2.4 典型主流程伪代码与模块职责说明
-

---

## 3. 词典与稀疏检索子系统设计

- BM25词典格式与管理（支持weight、freq、df等字段，自动归档）
- 词典噪声评估与评分工具（DictionaryNoiseScorer，结构化输出、可视化、AI解读）
- 词典生成、归档、可视化与OpenAI Vision API自动解读
- 评估流程与主流程解耦，接口健壮，支持多种评估与优化建议输出

---

## 4. 检索主流程、参数设计与图数据库集成

- 主流程结构与各环节职责
- 多query批量召回与聚合策略
- 参数传递、边界与异常处理

### 4.1 图数据库词典的动态生成与检索融合设计

#### 4.1.1 动态生成图数据库词典
- 目标：实现从原始文档自动抽取实体、关系，动态构建/更新图数据库（如Neo4j）中的知识图谱，形成可用于检索的"图数据库词典"。
- 流程设计：
  1. 文档解析：对原始文档进行分句、分段、分块处理。
  2. 实体识别与关系抽取：利用NLP工具（如Spacy、LLM、正则等）自动识别实体及其关系。
  3. 节点与边构建：将抽取到的实体作为节点，关系作为边，构建知识图谱。
  4. 属性与权重：为节点和边分配属性（如出现频次、上下文、权重等），形成"图数据库词典"。
  5. 动态更新：支持增量更新，文档变更时自动同步到图数据库。
- 接口建议：
  - `build_graph_dict_from_docs(docs: List[str]) -> GraphDict`
  - `update_graph_dict_with_new_docs(graph_dict, new_docs) -> GraphDict`
  - 支持导出为标准格式（如json、csv、neo4j导入脚本等）

### 4.2. 检索召回中的融合策略
- 融合目标：在检索召回阶段，将图数据库检索与稠密（dense）/稀疏（sparse）检索有机结合，提升召回率和答案准确率。
- 典型融合方式：
  1. 前置过滤：先用图数据库进行实体/关系过滤，缩小检索范围，再用dense/sparse召回。
  2. 后置补充：dense/sparse召回后，利用图数据库补充相关实体、上下文，丰富候选答案。
  3. 联合打分：将图数据库的结构信息与dense/sparse的相似度分数联合，进行多模态排序。
  4. 多路召回聚合：分别用图数据库、dense、sparse检索召回候选集，去重后聚合，提升覆盖率。
- 接口建议：
  - `graph_search(query) -> List[Node/Edge]`
  - `hybrid_search(query) -> List[Doc]`（内部可配置融合策略）
  - `rerank_with_graph_features(candidates, graph_dict) -> List[Doc]`
- 可扩展性：
  - 支持灵活配置融合策略（如优先级、权重、阈值等）
  - 便于后续引入KRAG/Agentic RAG等更复杂的知识路由与推理机制

---

## 5. 工程与测试规范

- 单一职责、可测性、可维护性原则
- 测试驱动开发流程，单元测试覆盖接口、空数据、极端数据、异常case等
- 文档与报告自动归档，统一命名规范
- 评估与主流程所有边界、异常、兜底逻辑100%一致

---

## 6. 检索与生成评估体系设计

### 6.1. 评估目标
- 全流程可观测：不仅评估最终答案，还要对每一步（dense/sparse/hybrid召回）进行过程性分析。
- 量化各环节性能瓶颈，定位优化空间。
- 评估体系可扩展，支持新检索策略和生成模型。

### 6.2. 检索召回分析

#### 6.2.1 Dense检索召回分析

【向量检索评估体系概要设计】

1. 评估目标
- 全流程可观测：不仅评估最终答案，还要对每一步检索（dense/sparse/hybrid）进行过程性分析。
- 量化性能瓶颈：定位召回率、排序、聚合等各环节的优化空间。
- 可扩展性：支持新检索策略和生成模型的评估。

2. 评估指标体系

**需要统计的指标**

1. Recall@K（Top-K召回率）
   - 含义：对于每个query，前K个检索结果中是否包含标准答案的比例。
   - 算法：对于每个query，判断前K个检索结果中是否包含标准答案，统计所有query的平均值。
   - 输入：gold（标准答案字典），retrieved（检索结果字典），K值。
   - 作用：衡量检索系统能否把正确答案召回到前K名。

```python
     def recall_at_k(gold, retrieved, k=5):
         return sum(any(doc in gold[qid] for doc in retrieved[qid][:k]) for qid in gold) / len(gold)
```

2. MRR（Mean Reciprocal Rank）
   - 含义：标准答案首次出现在检索结果中的倒数均值。
   - 算法：对于每个query，找到标准答案首次出现的排名，取倒数，所有query取均值。
   - 输入：gold，retrieved，K值。
   - 作用：反映标准答案在检索结果中的排序靠前程度。
```python
        def mrr(gold, retrieved, k=10):
         mrr_total = 0
         for qid in gold:
             for rank, doc_id in enumerate(retrieved[qid][:k], 1):
                 if doc_id in gold[qid]:
                     mrr_total += 1 / rank
                     break
         return mrr_total / len(gold)
```
3. Precision@K
   - 含义：前K条检索结果中相关文档的比例。
   - 算法：前K条检索结果中相关文档的比例，所有query取均值
   - 输入: gold，retrieved，K值。
   - 作用：衡量前K结果的准确性。
```python
     def precision_at_k(gold, retrieved, k=5):
         total = 0
         for qid in gold:
             relevant = sum(doc in gold[qid] for doc in retrieved[qid][:k])
             total += relevant / k
         return total / len(gold)
```

4. 覆盖率（Coverage）
   - 含义：多路召回（如dense/sparse/graph）结果的并集覆盖率。
   - 算法: 算法：多路召回结果的并集与标准答案的覆盖比例。
   - 输入: gold，dense/sparse/graph等多路召回结果，K值。
   - 作用：衡量不同召回方式的互补性。
```python
     def hybrid_union_recall(gold, dense, sparse, graph, k=10):
         total = 0
         for qid in gold:
             hybrid_set = set(dense[qid][:k]) | set(sparse[qid][:k]) | set(graph[qid][:k])
             if any(doc in gold[qid] for doc in hybrid_set):
                 total += 1
         return total / len(gold)
```

5. Overlap/去重率
   - 含义：多路召回结果的交集与并集分析。
   - 算法：多路召回结果的交集与并集，统计重叠和去重效果。
   - 输入：dense/sparse/graph等多路召回结果，K值。
   - 作用：分析不同召回方式的重叠与互补。
```python
     def recall_overlap(dense, sparse, graph, k=10):
         overlap_stats = []
         for qid in dense:
             sets = [set(dense[qid][:k]), set(sparse[qid][:k]), set(graph[qid][:k])]
             overlap = len(set.intersection(*sets))
             union = len(set.union(*sets))
             overlap_stats.append({'qid': qid, 'overlap': overlap, 'union': union})
         return pd.DataFrame(overlap_stats)
```

6. Embedding分布可视化
   - 含义：如t-SNE、UMAP等降维展示向量空间结构。
   - 作用：辅助分析embedding空间结构和聚类效果。
7. 分数分布
   - 含义：dense相似度分数的直方图。
   - 算法：t-SNE/UMAP降维，matplotlib/seaborn绘图。
   - 作用：分析检索分数的分布特征。
   - 输入：embedding向量，标签（如query/doc类型）。

8. 召回指标分布
   - 含义：Recall、MRR等的箱线图、分布图。
   - 算法：统计dense检索分数，绘制直方图。
   - 作用：分析整体和分query的指标分布。
   - 输入：检索分数列表。
```python
     plt.hist(score_list, bins=50)
     plt.title('Dense Score Distribution')
     plt.xlabel('Score')
     plt.ylabel('Frequency')
     plt.show()
```

3. 评估流程设计
1) 数据准备：标准query-答案对，检索结果（含多路召回）。
2) 指标计算：按query批量计算Recall@K、MRR、Precision@K等。
3) 分布分析：统计各指标的均值、方差、分布形态。
4) 可视化：生成分布图、降维图、交互式分析报告。
5) 典型case溯源：自动筛选召回失败、排序异常、覆盖不足等典型case，便于人工分析。
6) 自动报告：输出结构化评估报告，归档到document目录。

**各指标的算法与输入**

1. Recall@K
   - 算法：对于每个query，判断前K个检索结果中是否包含标准答案，统计所有query的平均值。
   - 输入：gold（标准答案字典），retrieved（检索结果字典），K值。
   - 伪代码：
     ```python
     def recall_at_k(gold, retrieved, k=5):
         return sum(any(doc in gold[qid] for doc in retrieved[qid][:k]) for qid in gold) / len(gold)
     ```

2. MRR
   - 算法：对于每个query，找到标准答案首次出现的排名，取倒数，所有query取均值。
   - 输入：gold，retrieved，K值。
   - 伪代码：
     ```python
     def mrr(gold, retrieved, k=10):
         mrr_total = 0
         for qid in gold:
             for rank, doc_id in enumerate(retrieved[qid][:k], 1):
                 if doc_id in gold[qid]:
                     mrr_total += 1 / rank
                     break
         return mrr_total / len(gold)
     ```

3. Precision@K
   - 算法：前K条检索结果中相关文档的比例，所有query取均值。
   - 输入：gold，retrieved，K值。
   - 伪代码：
     ```python
     def precision_at_k(gold, retrieved, k=5):
         total = 0
         for qid in gold:
             relevant = sum(doc in gold[qid] for doc in retrieved[qid][:k])
             total += relevant / k
         return total / len(gold)
     ```

4. 覆盖率（Coverage）
   - 算法：多路召回结果的并集与标准答案的覆盖比例。
   - 输入：gold，dense/sparse/graph等多路召回结果，K值。
   - 伪代码：
     ```python
     def hybrid_union_recall(gold, dense, sparse, graph, k=10):
         total = 0
         for qid in gold:
             hybrid_set = set(dense[qid][:k]) | set(sparse[qid][:k]) | set(graph[qid][:k])
             if any(doc in gold[qid] for doc in hybrid_set):
                 total += 1
         return total / len(gold)
     ```

5. Overlap/去重率
   - 算法：多路召回结果的交集与并集，统计重叠和去重效果。
   - 输入：dense/sparse/graph等多路召回结果，K值。
   - 伪代码：
     ```python
     def recall_overlap(dense, sparse, graph, k=10):
         overlap_stats = []
         for qid in dense:
             sets = [set(dense[qid][:k]), set(sparse[qid][:k]), set(graph[qid][:k])]
             overlap = len(set.intersection(*sets))
             union = len(set.union(*sets))
             overlap_stats.append({'qid': qid, 'overlap': overlap, 'union': union})
         return pd.DataFrame(overlap_stats)
     ```

6. Embedding分布可视化
   - 算法：t-SNE/UMAP降维，matplotlib/seaborn绘图。
   - 输入：embedding向量，标签（如query/doc类型）。
   - 伪代码：略（需用sklearn/manifold/umap等库）

7. 分数分布
   - 算法：统计dense检索分数，绘制直方图。
   - 输入：检索分数列表。
   - 伪代码：
     ```python
     plt.hist(score_list, bins=50)
     plt.title('Dense Score Distribution')
     plt.xlabel('Score')
     plt.ylabel('Frequency')
     plt.show()
     ```

8. 召回指标分布
   - 算法：统计Recall、MRR等指标，绘制分布图/箱线图。
   - 输入：各query的指标值。
   - 伪代码：
     ```python
     sns.histplot(recall_list, bins=20, kde=True)
     plt.title('Recall Distribution')
     plt.xlabel('Recall@K')
     plt.ylabel('Query Count')
     plt.show()
     ```

#### 2.2 Sparse检索召回分析（BM25）
- 评估内容：
  - Top-K召回率、MRR、Precision@K等同dense
  - 词项覆盖率、BM25分数分布
  - 词典噪声对召回的影响分析
- 示意代码：
```python
import pandas as pd
import matplotlib.pyplot as plt

def bm25_score_distribution(df):
    plt.hist(df['bm25_score'], bins=50)
    plt.title('BM25 Score Distribution')
    plt.xlabel('BM25 Score')
    plt.ylabel('Frequency')
    plt.show()

def term_coverage(query_terms, retrieved_docs, doc_terms):
    coverage = []
    for qid, docs in retrieved_docs.items():
        for doc_id in docs:
            overlap = len(query_terms[qid] & doc_terms[doc_id])
            coverage.append(overlap / len(query_terms[qid]))
    return np.mean(coverage)
# 示例
bm25_score_distribution(bm25_df)
```

#### 2.3 Hybrid检索召回分析
- 评估内容：
  - 多路召回的覆盖率提升（与单一路径对比）
  - 召回结果去重、聚合效果
  - 融合策略（加权、重排序等）对最终召回的影响
- 示意代码：
```python
def hybrid_union_recall(gold, dense, sparse, graph, k=10):
    total = 0
    for qid in gold:
        hybrid_set = set(dense[qid][:k]) | set(sparse[qid][:k]) | set(graph[qid][:k])
        if any(doc in gold[qid] for doc in hybrid_set):
            total += 1
    return total / len(gold)

def recall_overlap(dense, sparse, graph, k=10):
    overlap_stats = []
    for qid in dense:
        sets = [set(dense[qid][:k]), set(sparse[qid][:k]), set(graph[qid][:k])]
        overlap = len(set.intersection(*sets))
        union = len(set.union(*sets))
        overlap_stats.append({'qid': qid, 'overlap': overlap, 'union': union})
    return pd.DataFrame(overlap_stats)
# 示例
hybrid_recall = hybrid_union_recall(gold, dense, sparse, graph, k=10)
print(f"Hybrid Recall@10: {hybrid_recall:.3f}")
```

---

### 3. 答案生成与比对分析
- 评估内容：
  - 生成答案与标准答案的相似度（如BLEU、ROUGE、BERTScore、EM/Partial Match等）
  - 人工评测（可选）：相关性、准确性、可读性
  - 生成答案的可解释性分析（如引用溯源、证据链）
- 示意代码：
```python
from bert_score import score as bert_score
from rouge import Rouge
import numpy as np

generated = ["生成的答案1", "生成的答案2", ...]
references = ["标准答案1", "标准答案2", ...]

# BERTScore
P, R, F1 = bert_score(generated, references, lang='zh')
print(f"BERTScore F1: {F1.mean():.3f}")

# ROUGE
rouge = Rouge()
scores = rouge.get_scores(generated, references, avg=True)
print(f"ROUGE-L: {scores['rouge-l']['f']:.3f}")

def exact_match(generated, references):
    return np.mean([g == r for g, r in zip(generated, references)])
em = exact_match(generated, references)
print(f"Exact Match: {em:.3f}")
```

---

### 4. 可视化与报告生成
- 召回率、MRR、Precision@K等指标的分布图、箱线图
- Embedding空间分布可视化
- 召回与生成结果的交互式分析报告
- 示意代码：
```python
import matplotlib.pyplot as plt
import seaborn as sns

def plot_recall_distribution(recall_list):
    sns.histplot(recall_list, bins=20, kde=True)
    plt.title('Recall Distribution')
    plt.xlabel('Recall@K')
    plt.ylabel('Query Count')
    plt.show()
```

---

### 5. 业界主流实践参考
- OpenAI RAG评估：强调过程可观测、自动化指标+人工评测结合
- Google/知乎/百度：多路召回、分步评估、可视化分析、典型case溯源
- 推荐工具：pytrec_eval、scikit-learn、seaborn/matplotlib、BERTScore、ROUGE等

---

## 7. 成本考量

- 云部署方案与资源消耗（如服务器、存储、带宽等）
- LLM模型调用频率与费用（如OpenAI API，gpt-4o等）
- 云上PaaS（如数据库、对象存储、归档等）费用估算
- 降本增效建议：
  - 批量处理、缓存机制、异步任务等方式减少API调用
  - 评估本地化模型与云端模型的性价比
  - 自动归档与冷数据分层存储

---

## 8. 未来扩展与架构重构建议

- 兼容KRAG（Knowledge Routing-Augmented Generation）和Agentic RAG（具备自主决策与多步推理能力的RAG）等新型检索与生成范式
- 预留模块化接口，便于集成知识路由、Agent调度、复杂推理等能力
- 支持多策略、多模型协同检索与答案生成，满足更复杂的业务需求
- 评估体系需同步升级，覆盖KRAG/Agentic RAG的中间过程与最终结果，保证系统可观测性和可优化性

---

## 9. 其它注意事项

- 环境变量加载、API兼容性、错误兜底
- 评估与主流程边界一致性要求
- 归档与版本管理建议 